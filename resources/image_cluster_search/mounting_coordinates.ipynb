{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import strawb\n",
    "import shapely.geometry\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import strawb\n",
    "import scipy.ndimage\n",
    "import scipy.spatial\n",
    "import scipy.interpolate\n",
    "\n",
    "path = os.path.join(strawb.Config.repository_home, 'resources/image_cluster_search')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mounting_mod_dict = {\n",
    "    'TUMPMTSPECTROMETER001': cv2.imread('TUMPMTSPECTROMETER001_mounting_mod.png')[:,:,::-1],\n",
    "    'TUMPMTSPECTROMETER002': cv2.imread('TUMPMTSPECTROMETER002_mounting_mod.png')[:,:,::-1],\n",
    "}\n",
    "\n",
    "# gen. masked array for all devices\n",
    "devices = list(mounting_mod_dict.keys())\n",
    "\n",
    "for i in devices:\n",
    "    img = np.ma.array(mounting_mod_dict[i],\n",
    "                      mask=np.zeros_like(mounting_mod_dict[i])\n",
    "                     )   \n",
    "\n",
    "    # define the color threshold\n",
    "    m = img[:,:,0] > 200\n",
    "    m &= img[:,:,1] < 50\n",
    "    m &= img[:,:,2] < 50\n",
    "\n",
    "    img.mask |= m.reshape((*m.shape, 1))\n",
    "    mounting_mod_dict[i] = img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=len(mounting_mod_dict), squeeze=False, sharex='row', sharey='row')\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i, dev_i in enumerate(mounting_mod_dict):\n",
    "    ax[2*i].imshow(img)\n",
    "    ax[2*i+1].imshow(img.filled((0,0,0)))\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the mask\n",
    "strawb takes the mounting_mask.npz for the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the mask in separate file\n",
    "file_name = os.path.abspath(os.path.join(strawb.Config.repository_home,\n",
    "                                         'src/strawb/sensors/camera/mounting_mask.npz'))\n",
    "np.savez(file_name, **{i: np.any(~mounting_mod_dict[i].mask, axis=-1) for i in mounting_mod_dict})\n",
    "\n",
    "# for testing if written\n",
    "file_test = np.load(file_name)\n",
    "file_test.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_fov(image, points, axis=0):\n",
    "    min_xy = points.min(axis=0).astype(int)\n",
    "    max_xy = points.max(axis=0).astype(int)\n",
    "    slicer = (*[None]*axis, slice(min_xy[0], max_xy[0]), slice(min_xy[1], max_xy[1]))\n",
    "    return image[slicer]\n",
    "\n",
    "def equalization(image):\n",
    "    # convert from RGB color-space to YCrCb\n",
    "    ycrcb_img = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
    "    \n",
    "    if isinstance(ycrcb_img.dtype, np.float_):\n",
    "        ycrcb_img = (ycrcb_img * 2**8).astype(np.uint8) \n",
    "    elif isinstance(ycrcb_img.dtype, np.uint8):\n",
    "        pass\n",
    "    elif isinstance(ycrcb_img.dtype, np.uint16):\n",
    "        ycrcb_img = (ycrcb_img / 2).astype(np.uint8)\n",
    "    \n",
    "    # equalize the histogram of the Y channel\n",
    "#     ycrcb_img[:, :, 0] = cv2.equalizeHist(ycrcb_img[:, :, 0])\n",
    "    \n",
    "    # create a CLAHE object (Arguments are optional).\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=tuple([8]*2))\n",
    "    ycrcb_img[:, :, 0] = clahe.apply(ycrcb_img[:, :, 0])\n",
    "\n",
    "    # convert back to RGB color-space from YCrCb\n",
    "    return cv2.cvtColor(ycrcb_img, cv2.COLOR_YCrCb2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "ncols = 4\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=len(mounting_mod_dict), squeeze=False, \n",
    "                       #sharex='row', sharey='row'\n",
    "                      )\n",
    "ax = ax.flatten()\n",
    "\n",
    "c = 255//2\n",
    "\n",
    "for i, dev_i in enumerate(mounting_mod_dict):\n",
    "    cam_conf = strawb.camera.Config(dev_i)\n",
    "    box = cv2.minAreaRect(np.argwhere(cam_conf.mask_mounting))\n",
    "    points = cv2.boxPoints(box)\n",
    "    print(dev_i, ' ', box)\n",
    "\n",
    "    img = mounting_mod_dict[dev_i]\n",
    "    ax[ncols*i].set_ylabel(dev_i.replace('TUM', ''))\n",
    "    ax[ncols*i].imshow(img)\n",
    "    ax[ncols*i+1].imshow(img.filled((c,c,c)))\n",
    "    \n",
    "    cs = ax[ncols*i+1].contourf(~img.mask.any(axis=-1), 1, hatches=['xxx', ''], alpha=1, )\n",
    "    # ------------------------------\n",
    "    # New bit here that handles changing the color of hatches\n",
    "    colors = ['maroon', 'red', 'darkorange', 'gold', 'forestgreen',\n",
    "              'darkturquoise', 'dodgerblue', 'darkviolet']\n",
    "    # For each level, we set the color of its hatch \n",
    "    for j, collection in enumerate(cs.collections):\n",
    "    #     collection.set_edgecolor(colors[j % len(colors)])\n",
    "        collection.set_edgecolor('C0')\n",
    "        collection.set_facecolor('none')#(0,0,0,0))\n",
    "\n",
    "    # Doing this also colors in the box around each level\n",
    "    # We can remove the colored line around the levels by setting the linewidth to 0\n",
    "    for collection in cs.collections:\n",
    "        collection.set_linewidth(1.)\n",
    "    \n",
    "    img_cut = cut_fov(img, points)\n",
    "    ax[ncols*i+2].imshow(img_cut.filled((c,c,c)))\n",
    "    ax[ncols*i+3].imshow(equalization(img_cut.filled((c,c,c))))\n",
    "    \n",
    "ax[0].set_title('Modified')\n",
    "ax[1].set_title('masked red')\n",
    "ax[2].set_title('+ cropped')\n",
    "ax[3].set_title('+ equalization')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely.geometry\n",
    "\n",
    "def get_contours(mask):\n",
    "    # get contours, cv2 need uint, here uint8\n",
    "    contours, hierarchy = cv2.findContours(mask.astype(np.uint8), cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    contours = [i.reshape((-1, 2)) for i in contours]\n",
    "    return contours, hierarchy\n",
    "\n",
    "def simplify_contours(contours, simplify_tolerance = 1):\n",
    "    # simplify contours with shapely\n",
    "    contours_s = []\n",
    "    for i in contours:\n",
    "        poly = shapely.geometry.Polygon(i)\n",
    "        poly_s = poly.simplify(tolerance=simplify_tolerance)\n",
    "        contours_s.append(np.array(poly_s.boundary.coords[:]))\n",
    "    return contours_s\n",
    "\n",
    "def get_contours_simplify(mask, simplify_tolerance = 1):\n",
    "    # get contours, cv2 need uint, here uint8\n",
    "    contours, hierarchy = get_contours(mask)\n",
    "    contours = simplify_contours(contours, simplify_tolerance=simplify_tolerance)\n",
    "    return contours, hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all contours for all devices. There should be only one contour per device\n",
    "plt.figure()\n",
    "for i, dev_i in enumerate(mounting_mod_dict):\n",
    "    cam_conf = strawb.camera.Config(dev_i)\n",
    "    contours, hierarchy = get_contours_simplify(cam_conf.mask_mounting)\n",
    "\n",
    "    if len(contours) != 1:\n",
    "        print(f\"WARNING: {dev_i} doesn't has exacly 1 contour. Got: {len(contours)}\")\n",
    "    for j, c_j in enumerate(contours):\n",
    "        plt.plot(*c_j.T, label=f'{dev_i.replace(\"TUM\",\"\")}_contour_{j}')\n",
    "        \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [OLD] Load images with turned on LED lights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifiy picture by hand to mask mounting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('LED_images.npz') as f:\n",
    "        images = f['images']\n",
    "        \n",
    "# select one bright image\n",
    "image = images[-1]\n",
    "        \n",
    "if False:\n",
    "    # Write image as png to modify it that the mounting is red ([255,0,0]) e.g. with photoshop\n",
    "    # imwrite needs 16bit uint and BGR instead of RGB <-> [:,:,::-1]\n",
    "    cv2.imwrite('mounting.png', (image * 2**16).astype(np.uint16)[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_list = list(images.astype(np.float32))\n",
    "\n",
    "images_list_hdr = [images_list[1], images_list[3], images_list[-1]]\n",
    "fig, ax = plt.subplots(figsize=(10,5), ncols=len(images_list_hdr), sharex=True, sharey=True, squeeze=False)\n",
    "ax = ax.flatten()\n",
    "for i, img_i in enumerate(images_list_hdr):\n",
    "    ax[i].imshow(strawb.camera.tools.equalization(img_i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3dbe8948e6ba6f7b500cbad156adccce2d4d02afc71091580e98904bda0c5804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
