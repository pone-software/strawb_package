{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68306d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import sys\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "import io\n",
    "\n",
    "import dateutil\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import strawb\n",
    "\n",
    "import pandas\n",
    "\n",
    "import logging\n",
    "import gc\n",
    "\n",
    "import threading\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15343878",
   "metadata": {},
   "source": [
    "# Define path to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc472d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(strawb.Config.proc_data_dir, 'image_cluster_search')\n",
    "if not os.path.exists(path):\n",
    "    print(f'Create path: {path}')\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6838c9",
   "metadata": {},
   "source": [
    "# Logger set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd84b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter_list = ['%(asctime)s',\n",
    "                  '%(levelname)s',\n",
    "                  # Text logging level for the message ('DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL').\n",
    "                  '%(processName)s', # Process name (if available).\n",
    "                  '%(threadName)s',  # Thread name (if available).\n",
    "                  # '%(thread)d',  # Thread ID (if available).\n",
    "                  #'%(name)s',  # Name of the logger (logging channel).\n",
    "                  '%(funcName)s',  # Name of function containing the logging call.\n",
    "                  #'%(lineno)d',  # Source line number where the logging call was issued (if available).\n",
    "                  '%(message)s'  # The logged message, computed as msg % args.\n",
    "                  ]\n",
    "\n",
    "log_level = logging.DEBUG\n",
    "\n",
    "# add SHUTDOWN level\n",
    "logging.captureWarnings(True)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(log_level)\n",
    "\n",
    "# create file handler which logs to a file. The files are rotated and kept for 10 rotations.\n",
    "# E.g.: 'W0' once per week on Monday (or Sunday?) a new file is started\n",
    "file_name = os.path.join(path, 'scan_images.log')\n",
    "fh = logging.FileHandler(file_name)\n",
    "fh.setLevel(log_level)\n",
    "\n",
    "formatter = logging.Formatter(\";\".join(formatter_list))\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# Test\n",
    "for i in ['debug', 'info', 'warning', 'critical']:\n",
    "    logger.__getattribute__(i)(f'Test level: {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81212095",
   "metadata": {},
   "source": [
    "# Load synced files DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bd7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DB\n",
    "db = strawb.SyncDBHandler(file_name='Default')  # loads the db\n",
    "db.load_onc_db_update(save_db=True)  # update the DB, could take some time if it has to load info. from ONC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d64037",
   "metadata": {},
   "source": [
    "# Define functions to scan images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cluster(dataframe, min_n_images=5, mean_std_start=None, mean_std_stop=None, *args, **kwargs):\n",
    "    logger.debug(f\"Find_cluster files: {len(dataframe)}\")\n",
    "    temp_file = strawb.virtual_hdf5.HDF5TempFile(dataframe, module=strawb.Camera)\n",
    "\n",
    "    if min_n_images <= len(temp_file.module.file_handler.raw):\n",
    "        print()\n",
    "        df = temp_file.module.find_cluster.df_all(*args, **kwargs)\n",
    "    else:\n",
    "        df = pandas.DataFrame({'label': [-1]})\n",
    "\n",
    "    # add some parameters to track things\n",
    "    # df['deviceCode'] = dataframe.deviceCode.iloc[0]\n",
    "    df['mean_std_n'] = len(temp_file.module.file_handler.raw)\n",
    "\n",
    "    if mean_std_start is None:\n",
    "        df['mean_std_start'] = temp_file.module.file_handler.time.asdatetime()[0]\n",
    "    else:\n",
    "        df['mean_std_start'] = mean_std_start\n",
    "\n",
    "    if mean_std_stop is None:\n",
    "        df['mean_std_stop'] = temp_file.module.file_handler.time.asdatetime()[-1]\n",
    "    else:\n",
    "        df['mean_std_stop'] = mean_std_stop\n",
    "\n",
    "    del temp_file\n",
    "\n",
    "    gc.get_count(), gc.collect(), gc.get_count()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def wrap_iter_find_cluster(t_i, dt, dataframe, min_size_cluster=7, *args, **kwargs):\n",
    "    t_i_end = t_i + dt - pandas.Timedelta('00:00:00.000001')\n",
    "    mask_time = strawb.tools.pd_timestamp_mask_between(\n",
    "        dataframe.dateFrom,\n",
    "        dataframe.dateTo,\n",
    "        t_i,\n",
    "        t_i_end,\n",
    "    )\n",
    "    logger.info(f\"Iter find cluster: {t_i}; {dataframe.deviceCode.iloc[0]}; files: {len(dataframe[mask_time])}\")\n",
    "\n",
    "    if len(dataframe[mask_time]) == 0:\n",
    "        return pandas.DataFrame(\n",
    "            {  # 'deviceCode': [dataframe.deviceCode.iloc[0]],\n",
    "                'mean_std_n': [0],\n",
    "                'mean_std_start': [t_i],\n",
    "                'mean_std_stop': [t_i_end]})\n",
    "\n",
    "    return find_cluster(dataframe[mask_time],\n",
    "                        min_size_cluster=min_size_cluster,\n",
    "                        tqdm_kwargs={'desc': str(t_i)},\n",
    "                        mean_std_start=t_i,\n",
    "                        mean_std_stop=t_i_end,\n",
    "                        )\n",
    "\n",
    "\n",
    "class ClusterWrapper:\n",
    "    def __init__(self, ):\n",
    "        self.mpi = None\n",
    "        self.file_name = None\n",
    "\n",
    "    def wrap_intervals(self, t_start, dt, dataframe, dt_iter=pandas.offsets.Hour(8), *args, **kwargs):\n",
    "        \"\"\"\n",
    "        PARAMETER\n",
    "        ---------\n",
    "        t_start: start time of the iterration\n",
    "        dt: pandas.offsets, optional\n",
    "            define the interval for the file\n",
    "        dt_iter: pandas.offsets, optional\n",
    "            define the interval of iterrations, Candidates for the interval -> pandas.date_range(..., freq=)\n",
    "        \"\"\"\n",
    "        # define the interval per file\n",
    "        # Candidates for the interval -> pandas.date_range(..., freq=)\n",
    "        t_end = t_start + dt\n",
    "\n",
    "        # normalize=True -> Normalize start/end dates to midnight before generating date range.\n",
    "        # --> t_end+pandas.offsets.Day(1) add one day to cover the range\n",
    "        # --> cut the last entries: [dr<t_end]\n",
    "        dr = pandas.date_range(start=t_start,  # normalize=True - goes to midnight\n",
    "                               end=t_end,  # normalize=True - goes to midnight\n",
    "                               freq=dt_iter,\n",
    "                               normalize=True\n",
    "                               )\n",
    "        dr = dr[dr<t_end]\n",
    "        logger.info(f'dr: {dr.min()} - {dr.max() - pandas.Timedelta(\"00:00:00.000001\")}')\n",
    "\n",
    "        # gen filename\n",
    "        str_formater = '{dev_code}_{t_start:%Y%m%dT%H%M%S}_{t_end:%Y%m%dT%H%M%S}_image_cluster.gz'\n",
    "        formater_dict = {'dev_code': dataframe.deviceCode.iloc[0],\n",
    "                         't_start': t_start,\n",
    "                         't_end': t_end}\n",
    "        \n",
    "        global path\n",
    "        self.file_name = str_formater.format(**formater_dict)\n",
    "        self.file_name = os.path.join(path, self.file_name)\n",
    "\n",
    "        if os.path.exists(self.file_name):\n",
    "            logger.info(f'Skipp as DB exists: {self.file_name}')\n",
    "            return\n",
    "\n",
    "        logger.info(f'Iter range: {t_start:%Y%m%dT%H%M%S}-{t_end:%Y%m%dT%H%M%S}')\n",
    "\n",
    "        # do cluster search multiprocessing\n",
    "        run_kwargs = {'dt': dt_iter, 'dataframe': dataframe}\n",
    "        pbar_kwargs = {'desc': f'{dataframe.deviceCode.iloc[0]} - {t_start:%Y%m%dT%H%M%S}'}\n",
    "        self.mpi = strawb.MProcessIterator(processes=4, progress_bar=tqdm.notebook.tqdm, with_sys_log=False)\n",
    "        self.mpi.run(wrap_iter_find_cluster, dr, pbar_kwargs=pbar_kwargs, **run_kwargs)\n",
    "\n",
    "        logger.info(f'Done iter range: {t_start:%Y%m%dT%H%M%S}-{t_end:%Y%m%dT%H%M%S}')\n",
    "\n",
    "        # collect result\n",
    "        image_cluster_db = strawb.sync_db_handler.ImageClusterDB(file_name=self.file_name,\n",
    "                                                                 load_db=False)\n",
    "\n",
    "        success_dict = self.mpi.success_dict.copy()\n",
    "        for i in success_dict:\n",
    "            if image_cluster_db.dataframe is None:\n",
    "                image_cluster_db.dataframe = self.mpi.result_dict.pop(i)\n",
    "            else:\n",
    "                image_cluster_db.dataframe = image_cluster_db.dataframe.append(\n",
    "                    self.mpi.result_dict.pop(i),\n",
    "                    ignore_index=True)\n",
    "\n",
    "        if 'time' in image_cluster_db.dataframe.keys():\n",
    "            image_cluster_db.dataframe.time = pandas.to_datetime(image_cluster_db.dataframe.time, utc=True)\n",
    "\n",
    "        logger.info(f'Save DB: {self.file_name}')\n",
    "        image_cluster_db.save_db()\n",
    "        logger.info(f'Done save DB')\n",
    "        logger.info(f'self.mpi.error_dict: {self.mpi.error_dict}')\n",
    "        image_cluster_db.dataframe = None\n",
    "        del image_cluster_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f69f95",
   "metadata": {},
   "source": [
    "# Start the cluster search for all modules and periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9cca06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_w_list = []\n",
    "\n",
    "def iter_all(dataframe, dt_month=pandas.offsets.MonthBegin(1)):\n",
    "    mask = dataframe.dataProductCode == 'MSSCD'\n",
    "    mask &= dataframe.file_version > 0\n",
    "\n",
    "    for dev_i in dataframe.deviceCode[mask].unique():\n",
    "        logger.info(f'---- Start {dev_i} ----')\n",
    "        #         if dev_i == 'TUMPMTSPECTROMETER001':\n",
    "        #             continue\n",
    "\n",
    "        mask_i = mask & (dataframe.deviceCode == dev_i)\n",
    "        dataframe_i = dataframe[mask_i]\n",
    "\n",
    "        t_start = dataframe_i.dateFrom.min()\n",
    "        t_end = dataframe_i.dateFrom.max()\n",
    "\n",
    "        dr_month = pandas.date_range(start=t_start - dt_month,  # normalize=True - goes to midnight\n",
    "                                     end=t_end,  # normalize=True - goes to midnight\n",
    "                                     freq=dt_month,\n",
    "                                     normalize=True\n",
    "                                     )\n",
    "\n",
    "        for dr_i in tqdm.notebook.tqdm(dr_month, desc=dev_i):\n",
    "            cluster_w_list.append(ClusterWrapper())\n",
    "            print()\n",
    "            cluster_w_list[-1].wrap_intervals(dr_i, dt_month, dataframe_i)\n",
    "            \n",
    "cluster_thread = threading.Thread(target=iter_all, \n",
    "                                  kwargs=dict(dataframe=db.dataframe))\n",
    "cluster_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacec79a",
   "metadata": {},
   "source": [
    "# Monitor the progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dae3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print state of last item\n",
    "mpi = cluster_w_list[-1].mpi\n",
    "\n",
    "# Get the list of iterrations and if the multiprocessing is still active or not\n",
    "# Only the last item should be active\n",
    "print('Runs: ', [i.mpi.active for i in cluster_w_list if i.mpi is not None])\n",
    "print()\n",
    "\n",
    "if mpi is not None:\n",
    "    print('_active_jobs_dict_: ', mpi._active_jobs_dict_.keys())\n",
    "    print('_ready_dict_: ', mpi._ready_dict_.keys())\n",
    "    print('result_dict: ', mpi.result_dict.keys())\n",
    "    print('error_dict: ', mpi.error_dict.keys())\n",
    "    print('success_dict: ', mpi.success_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c73089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
