{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403820c3",
   "metadata": {},
   "source": [
    "# This examples shows how to interact with the ONC API and additional features from `strawb`\n",
    "The methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb81925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import dateutil\n",
    "import utm\n",
    "\n",
    "import pandas\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.signal\n",
    "\n",
    "import h5py\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import strawb\n",
    "import strawb.tools\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad8954e",
   "metadata": {},
   "source": [
    "# Load ONC file DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32798324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case execute db.load_entire_db_from_ONC() to load the entire db\n",
    "if os.path.exists(strawb.Config.pandas_file_sync_db):\n",
    "    db = strawb.SyncDBHandler()  # loads the db from disc\n",
    "else:\n",
    "    db = strawb.SyncDBHandler(load_db=False)  # doesn't load from disc\n",
    "db.load_onc_db_update(output=True, save_db=True)  # get updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cda345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case something got wrong with the strawb.SyncDBHandler(), there is a backup \n",
    "# which keeps the data_product files. They aren't listed in the ONC DB as they are generated on the fly.\n",
    "# For simplification, the files stored localy are added to the strawb.SyncDBHandler()\n",
    "onc_db = strawb.SyncDBHandler(strawb.Config.onc_data_product_backup)\n",
    "onc_db.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f78401",
   "metadata": {},
   "source": [
    "## Load the DB with devices and locations\n",
    "First execution needs some time to retrieve the informations from ONC. Afterwards the DB is stored localy and loaded directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DB with devices and locations\n",
    "if not os.path.exists(strawb.Config.onc_device_db):\n",
    "    device_db = strawb.ONCDeviceDB(load_db=False)\n",
    "    device_db.load_positions_for_devices()\n",
    "    device_db.save_db()\n",
    "else:\n",
    "    device_db = strawb.ONCDeviceDB()\n",
    "    \n",
    "# Cal. distance of devices to STRAWb\n",
    "device_db.dataframe['dis'] = np.sqrt(device_db.dataframe.pos_x**2 + device_db.dataframe.pos_y**2)\n",
    "device_db.dataframe['dis'] = np.sqrt(device_db.dataframe.pos_x**2 + device_db.dataframe.pos_y**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f210b85b",
   "metadata": {},
   "source": [
    "### Filter devices of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290d2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out locations which are located at 'Cascadia' Basin\n",
    "device_db.dataframe['deviceGroups'] = ''\n",
    "\n",
    "mask = device_db.dataframe.deviceCode.str.contains('TUM')\n",
    "mask |= device_db.dataframe.deviceCode.str.contains('WOM')\n",
    "device_db.dataframe.loc[mask, 'deviceGroups'] = 'STRAWb'\n",
    "\n",
    "mask_g = device_db.dataframe.deviceCategoryCode.str.contains('ADCP')\n",
    "device_db.dataframe.loc[mask_g, 'deviceGroups'] = 'ADCP'\n",
    "mask |= mask_g\n",
    "\n",
    "mask_g = device_db.dataframe.deviceCategoryCode.str.contains('CURRENTMETER')\n",
    "device_db.dataframe.loc[mask_g, 'deviceGroups'] = 'CURRENTMETER'\n",
    "mask |= mask_g\n",
    "\n",
    "mask_g = device_db.dataframe.deviceCategoryCode == 'JB'\n",
    "device_db.dataframe.loc[mask_g, 'deviceGroups'] = 'JB'\n",
    "mask |= mask_g\n",
    "\n",
    "mask_g = device_db.dataframe.deviceCode.str.contains('SDOM')\n",
    "mask_g |= device_db.dataframe.deviceCode.str.contains('POCAM')\n",
    "device_db.dataframe.loc[mask_g, 'deviceGroups'] = 'STRAW'\n",
    "mask |= mask_g\n",
    "\n",
    "mask &= ~device_db.dataframe.deviceCode.isnull()\n",
    "mask &= ~device_db.dataframe.deviceCategoryCode.isnull()\n",
    "\n",
    "# # show the dataframe\n",
    "# device_db.dataframe[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473586e3",
   "metadata": {},
   "source": [
    "# Location\n",
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529dbca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_column = 'deviceGroups' #'deviceCategoryCode' #'locationName'\n",
    "df = device_db.dataframe[mask].sort_values(color_column)  # sort the df based on the group\n",
    "df[df.deviceGroups.isin(['STRAW', 'STRAWb', 'ADCP', 'CURRENTMETER'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdab9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Plot Map\n",
    "# Select the column to group on = some color on plot\n",
    "color_column = 'deviceGroups' #'deviceCategoryCode' #'locationName'\n",
    "df = device_db.dataframe[mask].sort_values(color_column)  # sort the df based on the group\n",
    "\n",
    "# select the devices of interest\n",
    "# mask_i = df.deviceGroups.isin(['STRAW', 'STRAWb', 'ADCP', 'CURRENTMETER'])\n",
    "# df = df[mask_i]\n",
    "\n",
    "# # In case, to add size of the scatter points, for size=... in px.scatter(...)\n",
    "# uni, ind_inv = np.unique(df[color_column], return_inverse=True)\n",
    "\n",
    "fig = px.scatter_mapbox(df,\n",
    "                        lat='lat',\n",
    "                        lon='lon',\n",
    "                        zoom=2,\n",
    "#                         size=(ind_inv.max()-ind_inv+1)*2, size_max=7.,\n",
    "#                         labels={'deviceGroups': 'Device Type'},\n",
    "                        labels={'deviceGroups': ''},\n",
    "                        color=color_column,\n",
    "                        color_discrete_sequence=px.colors.qualitative.G10,\n",
    "                        hover_data=[\"deviceCode\", 'deviceCategoryCode', 'locationCode', 'locationName', 'depth', 'dis', 'deviceLink'])\n",
    "\n",
    "# Load external maps from map server like\n",
    "# https://basemap.nationalmap.gov/arcgis/rest/services/... or\n",
    "# https://services.arcgisonline.com/arcgis/rest/services/Ocean...\n",
    "fig.update_layout(\n",
    "#     mapbox_style=\"white-bg\", #\"carto-positron\",mapbox_style=\"white-bg\",\n",
    "    mapbox_style=\"white-bg\",\n",
    "    mapbox_layers=[\n",
    "        # The base map\n",
    "        {\"below\": 'traces',\n",
    "         \"sourcetype\": \"raster\",\n",
    "         \"source\": [\n",
    "#                 \"https://basemap.nationalmap.gov/arcgis/rest/services/USGSImageryOnly/MapServer/tile/{z}/{y}/{x}\"\n",
    "#                 \"https://basemap.nationalmap.gov/arcgis/rest/services/USGSHydroCached/MapServer/tile/{z}/{y}/{x}\"\n",
    "             \"https://services.arcgisonline.com/arcgis/rest/services/Ocean/World_Ocean_Base/MapServer/tile/{z}/{y}/{x}\"\n",
    "            ]},\n",
    "        # Labels on the map\n",
    "        {\n",
    "            \"sourcetype\": \"raster\",\n",
    "            \"source\": [\n",
    "                \"https://services.arcgisonline.com/arcgis/rest/services/Ocean/World_Ocean_Reference/MapServer/tile/{z}/{y}/{x}\"],\n",
    "        }\n",
    "      ])\n",
    "\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "# fig.update_layout(legend=dict(\n",
    "#     yanchor=\"top\",\n",
    "#     y=0.99,\n",
    "#     xanchor=\"left\",\n",
    "#     x=0.01))\n",
    "\n",
    "fig.update_layout(legend=dict(\n",
    "                    orientation=\"h\",\n",
    "                    yanchor=\"bottom\",\n",
    "                    y=1.02,\n",
    "                    xanchor=\"right\",\n",
    "                    x=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77232693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annot_dir(r, phi, r_shift):\n",
    "    sin = np.sin(np.deg2rad(phi))\n",
    "    cos = np.cos(np.deg2rad(phi))\n",
    "    return {'ax': np.round(r * sin, 1), \n",
    "            'ay': -np.round(r * cos, 1),\n",
    "            'xshift': np.round(r_shift * sin, 1),\n",
    "            'yshift': np.round(r_shift * cos, 1)}\n",
    "annot_dir(80, 200, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3398b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, _,_ = utm.from_latlon(df_mask.lat.to_numpy(), df_mask.lon.to_numpy())\n",
    "# df = device_db.dataframe[mask].sort_values('deviceGroups')\n",
    "df = device_db.dataframe[mask & (device_db.dataframe['dis'] < 5e3)]\n",
    "fig = px.scatter(df,\n",
    "                 y='pos_y',\n",
    "                 x='pos_x',\n",
    "                 color='deviceGroups',\n",
    "#                  text='deviceGroups',\n",
    "                 labels={'pos_y': 'Direction North [m]', 'pos_x': 'Direction East [m]', 'deviceGroups': ''},\n",
    "                        color_discrete_sequence=px.colors.qualitative.G10,\n",
    "                 hover_data=[\"deviceCode\", 'locationCode', 'locationName', \n",
    "                             'depth', 'dis', 'pos_x', 'pos_y'])\n",
    "fig.update_yaxes(\n",
    "    scaleanchor = \"x\",\n",
    "    scaleratio = 1,\n",
    "  )\n",
    "# fig.update_traces(textposition='top center')\n",
    "fig.update_xaxes(showgrid=True, zeroline=False, mirror=True)\n",
    "fig.update_yaxes(showgrid=True, zeroline=False, mirror=True)\n",
    "annot_dict = dict(showarrow=True, arrowhead=1)\n",
    "\n",
    "fig.update_layout(template=\"simple_white\",\n",
    "                  margin=dict(b=50, t=50, l=50, r=50),\n",
    "                  legend=dict(\n",
    "                    orientation=\"h\",\n",
    "                    yanchor=\"bottom\",\n",
    "                    y=1.02,\n",
    "                    xanchor=\"right\",\n",
    "                    x=1),\n",
    "                  annotations=[dict(text=\"STRAWb\", x=0, y=0, **annot_dir(40, 160, 5),**annot_dict),\n",
    "                               dict(text=\"STRAW-2 (Blue)\", x=-86.66, y=27.7, **annot_dir(70, 270, 5),**annot_dict),\n",
    "                               dict(text=\"STRAW-1 (Yellow)\", x=-54.74, y=0.77, **annot_dir(70, 250, 5),**annot_dict),\n",
    "                               dict(text=\"ADCP\", x=-2033.26, y=677.95, **annot_dir(40, 180, 5),**annot_dict),\n",
    "                               dict(text=\"Currentmeter\", x=-2027.66, y=679.26, **annot_dir(40, 45, 5),**annot_dict),\n",
    "                               dict(text=\"Junction Box (JB)\", x=27.65, y=32.25, **annot_dir(30, 20, 5),**annot_dict),\n",
    "                              ],\n",
    "                 )\n",
    "\n",
    "fig.show(width=5.35*200, height=3.*200)\n",
    "fig.write_image(os.path.expanduser('~/Downloads/cascadia_basin.pdf'), format='pdf', \n",
    "                width=5.35*125, height=3*125, scale=1\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502a0a8f",
   "metadata": {},
   "source": [
    "# Currentmeter\n",
    "Use getDirectScalar to get data of the CURENTMETER.\n",
    "\n",
    "## Get the device info with deviceCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef72c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask devices close to STRAW(b)\n",
    "df = device_db.dataframe[mask & (device_db.dataframe['dis'] < 5e3)]\n",
    "\n",
    "df[df.deviceCategoryCode=='CURRENTMETER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5fb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask devices close to STRAW(b)\n",
    "df = device_db.dataframe[mask & (device_db.dataframe['dis'] < 5e3)]\n",
    "\n",
    "# get the device\n",
    "mask_currentmeter = df.deviceCategoryCode=='CURRENTMETER'\n",
    "device_code_currentmeter = df[mask_currentmeter].deviceCode.iloc[0]\n",
    "print(f'Currentmeter deviceCode: {device_code_currentmeter}')\n",
    "\n",
    "ps_currentmeter = df[mask_currentmeter].iloc[0]\n",
    "ps_currentmeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef639c7",
   "metadata": {},
   "source": [
    "## Download Current-meter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e5218f",
   "metadata": {},
   "source": [
    "## Extract the Data\n",
    "Extract the data to proper format, here a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5408db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(res):\n",
    "    df_cur = pandas.DataFrame(columns=['time'])\n",
    "    for i in res['sensorData']:\n",
    "        if 'sampleTimes' not in i['data']:\n",
    "            print(i['data'])\n",
    "        df_i = pandas.DataFrame(i['data'])\n",
    "        df_i.rename(inplace=True, columns={\n",
    "            'sampleTimes': 'time',\n",
    "            'values': i['sensorCategoryCode']})\n",
    "        df_i.time = df_i.time.astype('datetime64')\n",
    "        # df_i.set_index('time', drop=False, inplace=True)\n",
    "        df_i.drop('qaqcFlags', axis='columns', inplace=True)\n",
    "\n",
    "        df_cur = df_cur.merge(df_i, on='time', how='outer')\n",
    "    return df_cur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba14f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pandas.offsets.Day(5)  #MonthBegin(1)\n",
    "date_range = pandas.date_range(\n",
    "    start='2023-01-01T00:00:00.000Z', \n",
    "    end='2023-06-21T00:00:00.000Z', \n",
    "    freq=freq)\n",
    "\n",
    "res_dfs = []\n",
    "error_list = []\n",
    "for i in tqdm.notebook.tqdm(date_range):\n",
    "    # ONC Docs\n",
    "    # https://wiki.oceannetworks.ca/display/O2A/scalardata+service#scalardataservice-getByDevice\n",
    "    # ONC API works with a filter dict to configure parameters\n",
    "    filters={\n",
    "        'dateFrom': f\"{i.strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]}Z\", \n",
    "        'dateTo': f\"{(i+freq).strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]}Z\",\n",
    "        'qualityControl': 'clean', # one of: 'raw' or 'clean'\n",
    "        'rowLimit': 10000,  # don't get crazy here ;)\n",
    "        # 'fillGaps': True, # one of; True, False\n",
    "\n",
    "        # # To resample the data, include the resample parameters. \n",
    "        # # Its recomended to access the raw data and do the resampling offline.\n",
    "        # 'resampleType': 'avgMinMax' # one of: 'avg', 'avgMinMax', 'minMax'\n",
    "        # 'resamplePeriod': 60, # [seconds] one of: 60, 600, 900, 3600, 86400\n",
    "        }\n",
    "\n",
    "    # with getDirectByDevice\n",
    "    with_get_direct = True\n",
    "    if with_get_direct:\n",
    "        try:\n",
    "            res = device_db.onc_downloader.getDirectByDevice(\n",
    "                allPages=True,\n",
    "                filters={'deviceCode': ps_currentmeter.deviceCode,\n",
    "                         **filters})\n",
    "        except Exception as a:\n",
    "            res = {}\n",
    "            error_list.append({i: a})\n",
    "            continue\n",
    "\n",
    "    # with getDirectByLocation\n",
    "    else:\n",
    "        try:\n",
    "            # getDirectScalar and getDirectByLocation, both methods are similar, linked internaly\\\n",
    "            res = device_db.onc_downloader.getDirectByLocation(\n",
    "                allPages=True, \n",
    "                filters={'locationCode': ps_currentmeter.locationCode,\n",
    "                         'deviceCategoryCode': ps_currentmeter.deviceCategoryCode,\n",
    "                         **filters})\n",
    "        except Exception as a:\n",
    "            res = {}\n",
    "            error_list.append({i: a})\n",
    "            continue\n",
    "\n",
    "#     pandas.DataFrame(res['sensorData'])\n",
    "    if 'sensorData' in res and res['sensorData'] is not None:\n",
    "        res_dfs.append(extract_data(res))\n",
    "        \n",
    "df_current = pandas.concat(res_dfs)\n",
    "df_current.sort_values('time', inplace=True)\n",
    "\n",
    "df_current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d53b36c",
   "metadata": {},
   "source": [
    "## store the data for each year individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b88757",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pandas.offsets.YearBegin()\n",
    "date_range = pandas.date_range(f'{df_current.time.min():%Y}', f'{df_current.time.max():%Y}', freq=freq)\n",
    "\n",
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f84ad61",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pandas.offsets.YearBegin()\n",
    "date_range = pandas.date_range(f'{df_current.time.min():%Y}', f'{df_current.time.max():%Y}', freq=freq)\n",
    "for date_min in tqdm.notebook.tqdm(date_range):\n",
    "    date_max = date_min+freq-pandas.Timedelta('1ns')\n",
    "    file_name = f\"currentmeter_{date_min:%Y-%m-%d}_{date_max:%Y-%m-%d}.parquet\"\n",
    "    df_i = df_current[(df_current.time>=date_min) & (df_current.time<=date_max)]\n",
    "    if len(df_i) > 0:\n",
    "        df_i.to_parquet(file_name)\n",
    "        print(file_name, os.path.getsize(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55638d68",
   "metadata": {},
   "source": [
    "# Load the currentmeter files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148298d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas\n",
    "\n",
    "df_current = pandas.concat([pandas.read_parquet(i) for i in glob.glob('currentmeter_*.parquet')])\n",
    "df_current = df_current[~df_current.current_speed_calculated.isna()]\n",
    "df_current.sort_values('time', inplace=True)\n",
    "\n",
    "# it seems the unit changed around '2014-05-18' from [m] to [dm]=.1[m] \n",
    "# df_current.loc[df_current.time < '2014-05-18', 'current_speed_calculated'] /= 10\n",
    "df_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707235fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_current.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356bc8f4",
   "metadata": {},
   "source": [
    "## Plot the data\n",
    "### Plotly\n",
    "good to explore pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bf88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df_current[(df_current.time>='2017') & (df_current.time<='2018')],\n",
    "        x='time', \n",
    "        y='current_speed_calculated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09a080",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bdf081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_smoothn(x, y, core_len, mode='valid', downsample=False, *args, **kwargs):\n",
    "    core = np.ones(len_core)\n",
    "    dtype_convert_x = None\n",
    "    if np.issubdtype(x.dtype, np.timedelta64) or np.issubdtype(x.dtype, np.datetime64):\n",
    "        dtype_convert_x = x.dtype\n",
    "        x = x.astype(float)\n",
    "        \n",
    "    x = np.convolve(x, core, mode=mode, *args, **kwargs)/np.sum(core)\n",
    "    y = np.convolve(y, core, mode=mode, *args, **kwargs)/np.sum(core)\n",
    "    \n",
    "    if downsample:\n",
    "        x=x[::len_core//2]\n",
    "        y=y[::len_core//2]\n",
    "    \n",
    "    \n",
    "    if dtype_convert_x is not None:\n",
    "        x = x.astype(dtype_convert_x)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b489a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the smoothen window\n",
    "len_core_seconds = 1200.\n",
    "\n",
    "dt = strawb.tools.datetime2float(df_current.time.to_numpy())\n",
    "len_core = int(len_core_seconds//np.mean(np.diff(dt)))\n",
    "core = np.ones(len_core)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10,6), nrows=2, squeeze=False, sharex=True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "# data can have nan's; exclude them here\n",
    "mask_valid = ~df_current.current_direction.isnull()\n",
    "ax[0].plot(*convolve_smoothn(df_current.time[mask_valid].to_numpy(), \n",
    "                                df_current.current_speed_calculated[mask_valid], \n",
    "                                len_core),\n",
    "           label='2660m Curentmeter', alpha=1, color='black')\n",
    "\n",
    "# data can have nan's; exclude them here\n",
    "mask_valid = ~df_current.current_direction.isnull()\n",
    "ax[1].plot(*strawb.tools.periodic2plot(*convolve_smoothn(df_current.time[mask_valid].to_numpy(),  \n",
    "                                               np.unwrap(df_current.current_direction[mask_valid], period=360), \n",
    "                                               len_core),\n",
    "                           period=360), \n",
    "           label='Curentmeter', alpha=1, color='black')\n",
    "\n",
    "for axi in ax:\n",
    "    axi.grid()\n",
    "    \n",
    "ax[0].legend(ncol=5, loc='lower center', bbox_to_anchor=(.5, 1))\n",
    "# ax[0].legend(loc='upper left')\n",
    "ax[0].set_ylabel('Absolute Speed [m/s]')\n",
    "ax[1].set_ylabel('Phi [$^\\circ$]')\n",
    "ax[1].set_ylim(0, 360)  # limit to one rotation\n",
    "ax[1].set_yticks(np.arange(0, 361, 90))  # set ticks manualy\n",
    "\n",
    "# get a proper date format\n",
    "ax[-1].xaxis.set_major_formatter(\n",
    "    mdates.ConciseDateFormatter(ax[1].xaxis.get_major_locator()))\n",
    "\n",
    "# fit the plot to the data range in x (time)\n",
    "ax[-1].autoscale(enable=True, axis='x', tight=True)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bc77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the smoothen window\n",
    "len_core_seconds = 1200.\n",
    "\n",
    "# data can have nan's; exclude them here\n",
    "mask_valid = ~df_current.current_direction.isnull()\n",
    "\n",
    "dt = strawb.tools.datetime2float(df_current.time.to_numpy())\n",
    "len_core = int(len_core_seconds//np.mean(np.diff(dt)))\n",
    "core = np.ones(len_core)\n",
    "\n",
    "t, cur = convolve_smoothn(df_current.time[mask_valid].to_numpy(), \n",
    "                                df_current.current_speed_calculated[mask_valid], \n",
    "                                len_core)\n",
    "\n",
    "t, phi = convolve_smoothn(df_current.time[mask_valid].to_numpy(),\n",
    "                          np.unwrap(df_current.current_direction[mask_valid], period=360), \n",
    "                          len_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data can have nan's; exclude them here\n",
    "mask_valid = ~df_current.current_direction.isnull()\n",
    "\n",
    "t = df_current.time[mask_valid].to_numpy()\n",
    "cur = df_current.current_speed_calculated[mask_valid].to_numpy()\n",
    "phi = df_current.current_direction[mask_valid].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915dbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.projections\n",
    "\n",
    "def update_projection(ax, projection='polar', fig=None, ax_array=None):\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    rows, cols, start, stop = ax.get_subplotspec().get_geometry()\n",
    "    ax.remove()\n",
    "    ax = fig.add_subplot(rows, cols, start+1, projection=projection)\n",
    "    if ax_array is not None:\n",
    "        ax_array.flat[start] = ax\n",
    "    return ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b2e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker\n",
    "import matplotlib.colors\n",
    "import matplotlib.projections\n",
    "\n",
    "def update_projection(ax, projection='polar', fig=None, ax_array=None):\n",
    "    if fig is None:\n",
    "        fig = plt.gcf()\n",
    "    rows, cols, start, stop = ax.get_subplotspec().get_geometry()\n",
    "    ax.remove()\n",
    "    ax = fig.add_subplot(rows, cols, start+1, projection=projection)\n",
    "    if ax_array is not None:\n",
    "        ax_array.flat[start] = ax\n",
    "    return ax\n",
    "\n",
    "def polar_append(x):\n",
    "    return np.append(np.append(x[:1], x, axis=0), x[:1], axis=0)\n",
    "    \n",
    "def polar_plot(dataframe, n_phi=25, n_current=40, current_max=.08, \n",
    "               log=False, ax=None, fig=None, ax_array=None, v_min=None, v_max=None, levels=10):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(ncols=1, subplot_kw=dict(projection='polar'))\n",
    "    else:\n",
    "        ax = update_projection(ax, projection='polar', fig=fig, ax_array=ax_array)\n",
    "\n",
    "    values, (e_phi, e_cur) = np.histogramdd(\n",
    "        np.array([np.deg2rad(dataframe.current_direction%360), \n",
    "                  dataframe.current_speed_calculated]).T, \n",
    "        bins=[np.linspace(0, np.pi*2, n_phi),\n",
    "              np.linspace(0, current_max, n_current)])\n",
    "\n",
    "    r, theta = np.meshgrid(strawb.tools.cal_middle(e_cur),\n",
    "                           strawb.tools.cal_middle(e_phi))\n",
    "    values_norm = values/values.sum() # to pdf\n",
    "    # normalize with the area: r*dr*dPhi\n",
    "    values_norm /= (r*1e3 * np.diff(np.deg2rad(e_phi)).reshape(-1,1) * np.diff(e_cur*1e3))\n",
    "\n",
    "    # workaround for polar and contourf\n",
    "    # close the arrays in theta - append values accordingly\n",
    "    theta = polar_append(theta)\n",
    "    theta[[0,-1]] = [[0],[np.pi*2.]]\n",
    "    r = polar_append(r)\n",
    "    values = polar_append(values)\n",
    "    values_norm = polar_append(values_norm)\n",
    "\n",
    "    # interpolate to the mean on the boundary to correct the added values\n",
    "    values_norm[[0,-1]] = [(values_norm[0]+values_norm[-1])/2.]*2\n",
    "\n",
    "    v_min = values_norm[values_norm>0].min() if v_min is None else v_min\n",
    "    v_max = values_norm[values_norm>0].max() if v_max is None else v_max\n",
    "\n",
    "    cmap = matplotlib.cm.get_cmap('Blues').copy()\n",
    "    cmap.set_under('white')\n",
    "\n",
    "    cm = ax.contourf(theta,r, values_norm+v_min*.5, #np.ma.array(values_norm, mask=values==0), \n",
    "                     vmin=values_norm[values_norm>0].min() if log else v_min,\n",
    "                     vmax=v_max,\n",
    "                     levels=np.geomspace(v_min, v_max, levels) if log else np.linspace(0, v_max, levels), #[1e-7,1e-5, 1e-3, 1e-1, 1e1], \n",
    "                     norm=matplotlib.colors.LogNorm() if log else None,\n",
    "                     cmap=cmap, extend='max')\n",
    "\n",
    "    plt.colorbar(cm, ax=ax, label='pdf', anchor=(1.2,0.5), shrink=.75)\n",
    "\n",
    "    ax.set_rticks([.04, .08])#[0.05, .1, .15, .2])  # Less radial ticks\n",
    "    ax.set_rlim([0, .08])#[0.05, .1, .15, .2])  # Less radial ticks\n",
    "    ax.set_theta_zero_location('N')\n",
    "    ax.set_theta_direction(-1)   \n",
    "    ax.set_rlabel_position(2.5)  # Move radial labels away from plotted line\n",
    "    ax.grid(ls='--', alpha=.5)\n",
    "\n",
    "    ax.yaxis.set_major_formatter(matplotlib.ticker.EngFormatter(unit='m/s'))\n",
    "    \n",
    "polar_plot(df_current, v_min =.001, v_max=.01, levels=11)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8338ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq=pandas.offsets.MonthBegin()\n",
    "date_range = pandas.date_range(df_current.time[mask_valid].min(), \n",
    "                  df_current.time[mask_valid].max(),\n",
    "                  freq=freq, normalize=True)\n",
    "\n",
    "date_range_data = []\n",
    "for i, t_min in enumerate(date_range):\n",
    "    mask_i = (df_current.time>=t_min) & (df_current.time<t_min+freq) & mask_valid\n",
    "    \n",
    "    if mask_i.sum()>0:\n",
    "        date_range_data.append(df_current[mask_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe68189",
   "metadata": {},
   "outputs": [],
   "source": [
    "f'Year: {df_i.time.min().strftime(}; Uptime: {df_i.time.diff().sum()}'[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1dbbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfMerger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1947f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = df_current\n",
    "bins=500\n",
    "time_format='%Y'\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(squeeze=False, nrows=1, ncols=3, sharex='col', sharey='col', \n",
    "                       figsize=(9, 3))\n",
    "i =0\n",
    "h, e = np.histogram(df_i.current_speed_calculated.to_numpy()*1e3, \n",
    "                    bins=np.linspace(0, 100, bins), density=True)\n",
    "if bins > 100:\n",
    "    ax[i, 0].plot(strawb.tools.cal_middle(e), h)\n",
    "else:\n",
    "    ax[i, 0].stairs(h, e, zorder=10)\n",
    "\n",
    "h, e = np.histogram(df_i.current_direction.to_numpy()%360, \n",
    "                    bins=np.linspace(0, 360, bins), density=True)\n",
    "if bins > 100:\n",
    "    ax[i, 1].plot(strawb.tools.cal_middle(e), h)\n",
    "else:\n",
    "    ax[i, 1].stairs(h, e, zorder=10)\n",
    "\n",
    "#     ax[i, 1].set_title(\n",
    "fig.suptitle(\n",
    "    f'Period: {df_i.time.min().strftime(time_format)} - {df_i.time.max().strftime(time_format)}; Uptime: {df_i.time.diff().sum()}'[:-16])\n",
    "#         f'{df_i.time.min():%Y-%m-%d} - {df_i.time.max():%Y-%m-%d}')\n",
    "#         loc='center left', bbox_to_anchor=(1., .5), ncol=1, handlelength=.5, frameon=False)\n",
    "\n",
    "polar_plot(df_i, ax=ax[i, 2], ax_array=ax, fig=fig, \n",
    "           n_phi=20, n_current=30,  v_min=0, v_max=.010, levels=11)\n",
    "\n",
    "ax[-1,0].set_xlim(0, 100)\n",
    "ax[-1,0].set_ylim(0, .03)\n",
    "ax[-1,0].set_xlabel('current speed [mm/s]')\n",
    "ax[-1,1].set_xlim(0, 360)\n",
    "ax[-1,1].set_ylim(0, .006)\n",
    "ax[-1,1].set_xlabel('current direction [$^\\circ$]')\n",
    "\n",
    "for axi in ax[:, :2].flat:\n",
    "    axi.set_ylim(0)\n",
    "    axi.grid()\n",
    "    axi.set_ylabel('pdf')\n",
    "\n",
    "plt.tight_layout(pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85938dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PyPDF2 import PdfMerger\n",
    "\n",
    "bins = 500\n",
    "\n",
    "# data can have nan's; exclude them here\n",
    "mask_valid = ~df_current.current_direction.isnull()\n",
    "\n",
    "# generate periods with data\n",
    "freq, time_format = [\n",
    "    [pandas.offsets.YearBegin(), '%Y'],\n",
    "    [pandas.offsets.MonthBegin(), '%Y-%m']][1]\n",
    "date_range = pandas.date_range(df_current.time[mask_valid].min(), \n",
    "                  df_current.time[mask_valid].max(),\n",
    "                  freq=freq, normalize=True)\n",
    "\n",
    "date_range_data = []\n",
    "for i, t_min in enumerate(date_range):\n",
    "    mask_i = (df_current.time>=t_min) & (df_current.time<t_min+freq) & mask_valid\n",
    "    \n",
    "    if mask_i.sum()>0:\n",
    "        date_range_data.append(df_current[mask_i])\n",
    "        \n",
    "\n",
    "# plot\n",
    "# fig, ax = plt.subplots(nrows=len(date_range_data), ncols=3, sharex='col', sharey='col',\n",
    "#                        figsize=(9, 1+2.5*len(date_range_data)))\n",
    "\n",
    "files = []\n",
    "for i, df_i in enumerate(tqdm.notebook.tqdm(date_range_data)):\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(squeeze=False, nrows=1, ncols=3, sharex='col', sharey='col', \n",
    "                           figsize=(9, 3))\n",
    "    i =0\n",
    "    h, e = np.histogram(df_i.current_speed_calculated.to_numpy()*1e3, \n",
    "                        bins=np.linspace(0, 100, bins), density=True)\n",
    "    if bins > 100:\n",
    "        ax[i, 0].plot(strawb.tools.cal_middle(e), h)\n",
    "    else:\n",
    "        ax[i, 0].stairs(h, e, zorder=10)\n",
    "\n",
    "    h, e = np.histogram(df_i.current_direction.to_numpy()%360, \n",
    "                        bins=np.linspace(0, 360, bins), density=True)\n",
    "    if bins > 100:\n",
    "        ax[i, 1].plot(strawb.tools.cal_middle(e), h)\n",
    "    else:\n",
    "        ax[i, 1].stairs(h, e, zorder=10)\n",
    "    \n",
    "#     ax[i, 1].set_title(\n",
    "    fig.suptitle(\n",
    "        f'Year: {df_i.time.min().strftime(time_format)}; Uptime: {df_i.time.diff().sum()}'[:-7])\n",
    "#         f'{df_i.time.min():%Y-%m-%d} - {df_i.time.max():%Y-%m-%d}')\n",
    "#         loc='center left', bbox_to_anchor=(1., .5), ncol=1, handlelength=.5, frameon=False)\n",
    "    \n",
    "    polar_plot(df_i, ax=ax[i, 2], ax_array=ax, fig=fig, \n",
    "               n_phi=20, n_current=30,  v_min=0, v_max=.025, levels=11)\n",
    "\n",
    "    ax[-1,0].set_xlim(0, 100)\n",
    "    ax[-1,0].set_ylim(0, .04)\n",
    "    ax[-1,0].set_xlabel('current speed [mm/s]')\n",
    "    ax[-1,1].set_xlim(0, 360)\n",
    "    ax[-1,1].set_ylim(0, .02)\n",
    "    ax[-1,1].set_xlabel('current direction [$^\\circ$]')\n",
    "\n",
    "    for axi in ax[:, :2].flat:\n",
    "        axi.set_ylim(0)\n",
    "        axi.grid()\n",
    "        axi.set_ylabel('pdf')\n",
    "\n",
    "    plt.tight_layout(pad=1)\n",
    "    file_name = f'currentmeter_pdfs_{df_i.time.min().strftime(time_format)}.pdf'\n",
    "    fig.savefig(file_name)\n",
    "    files.append(file_name)\n",
    "    \n",
    "\n",
    "merger = PyPDF2.PdfFileMerger()\n",
    "\n",
    "for pdf in files:\n",
    "    merger.append(pdf)\n",
    "\n",
    "str_min = date_range_data[0].time.min().strftime(time_format)\n",
    "str_max = date_range_data[-1].time.max().strftime(time_format)\n",
    "file_name = f'currentmeter_pdfs_{str_min}_{str_max}.pdf'\n",
    "merger.write(file_name)\n",
    "merger.close()\n",
    "\n",
    "for pdf in files:\n",
    "    os.remove(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba11c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib._api\n",
    "import datetime\n",
    "class LogTimedeltaLocator(matplotlib.ticker.FixedLocator):\n",
    "    \"\"\"\n",
    "    Tick locations are fixed at *locs*.  If *nbins* is not None,\n",
    "    the *locs* array of possible positions will be subsampled to\n",
    "    keep the number of ticks <= *nbins* +1.\n",
    "    The subsampling will be done to include the smallest\n",
    "    absolute value; for example, if zero is included in the\n",
    "    array of possibilities, then it is guaranteed to be one of\n",
    "    the chosen ticks.\n",
    "    \"\"\"\n",
    "    def __init__(self, which='major', unit='s', nbins=None):\n",
    "        self.which = 'major'\n",
    "        self.unit='s'\n",
    "        \n",
    "        self.locs = self.gen_log_times(which=which, dtype=f'timedelta64[{unit}]')\n",
    "        matplotlib._api.check_shape((None,), locs=self.locs)\n",
    "        self.nbins = max(nbins, 2) if nbins is not None else None\n",
    "        \n",
    "    @staticmethod\n",
    "    def gen_log_times(which='major', dtype='timedelta64[s]'):\n",
    "        x = pandas.to_timedelta([\n",
    "            '1ns', '10ns', '100ns', \n",
    "            '1us', '10us', '100us', \n",
    "            '1ms', '10ms', '100ms', \n",
    "            '1s', '10s', \n",
    "            '1m', '10m', \n",
    "            '1h', '6h', \n",
    "            '1d', '10d', '100d', '365d'])\n",
    "        if which == 'major':\n",
    "            # unique removes doublicates, i.e. 0 for 'x<dtype'\n",
    "            return np.unique(x.to_numpy().astype(dtype).astype(int))\n",
    "\n",
    "        x_minor = [pandas.timedelta_range(start=x[i], \n",
    "                                          end=x[i+1], \n",
    "                                          freq=x[i]).to_numpy() for i in range(len(x)-1)]\n",
    "        # unique removes doublicates, i.e. 0 for 'x<dtype'\n",
    "        return np.unique(np.hstack(x_minor).astype(dtype).astype(int))\n",
    "    \n",
    "def log_time_formatter(x, pos):\n",
    "    d = datetime.timedelta(seconds=int(x))\n",
    "    return str(d).replace(', 0:00:00','')\n",
    "    \n",
    "ltl = LogTimedeltaLocator(which='major')\n",
    "ltl.gen_log_times()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "# scipy.signal.periodogram(cur, (t[5]-t[4]).astype(float)*1e-9)\n",
    "\n",
    "# set up the smoothen window\n",
    "len_core_seconds = 120.\n",
    "\n",
    "dt = strawb.tools.datetime2float(df_cur.time.to_numpy())\n",
    "len_core = int(len_core_seconds//np.mean(np.diff(dt)))\n",
    "core = np.ones(len_core)\n",
    "\n",
    "t, cur = convolve_smoothn(df_cur.time[mask_valid].to_numpy(), \n",
    "                                df_cur.current_speed_calculated[mask_valid], \n",
    "                                len_core)\n",
    "\n",
    "t, phi = convolve_smoothn(df_cur.time[mask_valid].to_numpy(),\n",
    "                          np.unwrap(df_cur.current_direction[mask_valid], period=360), \n",
    "                          len_core)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "label, _ = scipy.ndimage.label(mask_diff)\n",
    "label_unique, count = np.unique(label, return_counts=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(label_unique, count)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0006e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage\n",
    "label, _ = scipy.ndimage.label(df_current.time[mask_valid].diff() < '7d')\n",
    "label_unique, count = np.unique(label, return_counts=True)\n",
    "\n",
    "label_list = []\n",
    "t_0 = df_current.time[mask_valid]\n",
    "for i in tqdm.notebook.tqdm(label_unique[1:]):  # [1:] dont use label 0 - all false points\n",
    "    t_i = t_0[i == label]\n",
    "    label_list.append({'period': i, 'dateFrom': t_i.min(), 'dateTo':t_i.max()})\n",
    "    \n",
    "df_label = pandas.DataFrame.from_records(label_list)\n",
    "df_label['duration'] = df_label.dateTo - df_label.dateFrom\n",
    "del label_list\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_periodogram(ax, t, x, scaling='density', label=None, fmt='o-'):\n",
    "    f, Pxx = scipy.signal.periodogram(x=x, #rates.filled(rates.mean()), \n",
    "                                      fs=1./((t[1]-t[0]).astype(float)*1e-9),\n",
    "                                              window=['flattop', 'hanning', ('gaussian', 20000.), \n",
    "                                                      ('exponential', 2e6), ('kaiser', 2.5)][0],\n",
    "    #                                     nperseg=2**12,\n",
    "                                     return_onesided=True,\n",
    "                                      scaling=scaling,\n",
    "                                     )\n",
    "    scipy.signal.lombscargle()\n",
    "\n",
    "    ax.plot(1./f[f!=0],\n",
    "               Pxx[f!=0],\n",
    "    #               (Pxx[f!=0]-Pxx[f!=0].min())/(Pxx[f!=0].max()-Pxx[f!=0].min()),\n",
    "               fmt, ms=1.5, label=label\n",
    "    #               label = key_j\n",
    "              )\n",
    "\n",
    "#     ax[i].text(0.03,.9, ha=\"left\", va=\"top\",\n",
    "# #                0.97,.9, ha=\"right\", va=\"top\",\n",
    "#                s=f'{ch[\"label\"]}', \n",
    "#        transform=ax[i].transAxes,\n",
    "#        multialignment='left',\n",
    "#        bbox=dict(boxstyle=\"round,pad=.5,rounding_size=0.2\", \n",
    "#                  fc=\"white\", ec=\"gray\", lw=1, alpha=.95),\n",
    "#       )\n",
    "\n",
    "# ax[0].legend(#title=f'{ch[\"label\"]}',\n",
    "# #              loc='center left', bbox_to_anchor=(1., .5), \n",
    "#              loc='lower center', bbox_to_anchor=(.5, 1.), \n",
    "#              ncol=6, handlelength=1,\n",
    "#              frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb5ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = df_label.duration.argsort().iloc[-9:][::-1]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(indexes), \n",
    "                       ncols=1, sharex='col', sharey='row', \n",
    "                       squeeze=False, figsize=[9,15])\n",
    "ax = ax.flatten()\n",
    "scaling_dict = {'density': 'power spectral density [v**2/Hz]',\n",
    "                'spectrum': 'power spectral density [v**2]',}\n",
    "scaling=['density', 'spectrum'][0]\n",
    "\n",
    "for i, index_i in enumerate(indexes):\n",
    "    period_i = df_label.loc[index_i]\n",
    "    df_i = df_current[(df_current.time>=period_i.dateFrom) & (df_current.time<=period_i.dateTo) & mask_valid]\n",
    "    d = df_i.time.max()-df_i.time.min()\n",
    "    cur_i = df_i.current_speed_calculated.to_numpy()\n",
    "    t_i = df_i.time.to_numpy()\n",
    "    plot_periodogram(ax.flat[i], t_i, cur_i, fmt='o',\n",
    "                     label=f'{df_i.time.min():%Y-%m-%d} - {df_i.time.max():%Y-%m-%d}\\n$\\Delta$t: {log_time_formatter(d.value*1e-9, None)}')\n",
    "    ax.flat[i].legend(loc='center left', \n",
    "             bbox_to_anchor=(1., .5), ncol=1, handlelength=.5, frameon=False)\n",
    "\n",
    "def timeTicks(x, pos):\n",
    "    d = datetime.timedelta(seconds=x)\n",
    "    return str(d)\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "for axi in ax.flatten():\n",
    "    axi.autoscale(axis='x', tight=True)\n",
    "    \n",
    "    axi.xaxis.set_major_locator(LogTimedeltaLocator(which='major'))\n",
    "    axi.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(log_time_formatter))\n",
    "    axi.tick_params(axis='x', labelrotation=30)\n",
    "\n",
    "    axi.xaxis.set_minor_locator(LogTimedeltaLocator(which='minor'))\n",
    "    axi.xaxis.set_minor_formatter(matplotlib.ticker.NullFormatter())\n",
    "\n",
    "#     axi.set_ylim(0, 50)\n",
    "#     axi.set_yscale('log')\n",
    "#     axi.set_ylim(.1)\n",
    "    axi.grid()\n",
    "    \n",
    "ax[-1].set_xlim(3600)\n",
    "fig.supylabel(scaling_dict[scaling])\n",
    "# ax[0].set_title(f'Period: {df_i.time.min():%Y-%m-%d} - {df_i.time.max():%Y-%m-%d}')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = df_label.duration.argsort().iloc[-9:][::-1]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=len(indexes), \n",
    "                       ncols=1, sharex='col', sharey='row', \n",
    "                       squeeze=False, figsize=[9,15])\n",
    "ax = ax.flatten()\n",
    "scaling_dict = {'density': 'power spectral density [$\\Phi$**2/Hz]',\n",
    "                'spectrum': 'power spectral density [$\\Phi$**2]',}\n",
    "scaling=['density', 'spectrum'][0]\n",
    "\n",
    "for i, index_i in enumerate(indexes):\n",
    "    period_i = df_label.loc[index_i]\n",
    "    df_i = df_current[(df_current.time>=period_i.dateFrom) & (df_current.time<=period_i.dateTo) & mask_valid]\n",
    "    d = df_i.time.max()-df_i.time.min()\n",
    "    phi_i = df_i.current_direction.to_numpy()\n",
    "    t_i = df_i.time.to_numpy()\n",
    "    plot_periodogram(ax.flat[i], t_i, phi_i,\n",
    "                     label=f'{df_i.time.min():%Y-%m-%d} - {df_i.time.max():%Y-%m-%d}\\n$\\Delta$t: {log_time_formatter(d.value*1e-9, None)}')\n",
    "    ax.flat[i].legend(loc='center left', \n",
    "             bbox_to_anchor=(1., .5), ncol=1, handlelength=.5, frameon=False)\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "for axi in ax.flatten():\n",
    "    axi.autoscale(axis='x', tight=True)\n",
    "    \n",
    "    axi.xaxis.set_major_locator(LogTimedeltaLocator(which='major'))\n",
    "    axi.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(log_time_formatter))\n",
    "    axi.tick_params(axis='x', labelrotation=30)\n",
    "\n",
    "    axi.xaxis.set_minor_locator(LogTimedeltaLocator(which='minor'))\n",
    "    axi.xaxis.set_minor_formatter(matplotlib.ticker.NullFormatter())\n",
    "\n",
    "    axi.set_ylim(0, 4e9)\n",
    "#     axi.set_yscale('log')\n",
    "#     axi.set_ylim(.1)\n",
    "    axi.grid()\n",
    "    \n",
    "ax[-1].set_xlim(3600)\n",
    "fig.supylabel(scaling_dict[scaling])\n",
    "# ax[0].set_title(f'Period: {df_i.time.min():%Y-%m-%d} - {df_i.time.max():%Y-%m-%d}')\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec3e7e",
   "metadata": {},
   "source": [
    "# ADCP - !!!work in progress!!!!\n",
    "you have to download `nc` files first. ADCP data can be accessed via getDirectScalar. Data product delivery has to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask ADCP close to STRAW(b)\n",
    "device_code = 'RDIADCP75WH17575'\n",
    "adcp_mask = db.dataframe.fullPath.str.endswith('.nc')\n",
    "adcp_mask &= db.dataframe.deviceCode == device_code\n",
    "db.dataframe[adcp_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c803578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if adcp_mask.sum():\n",
    "    adcp = strawb.ADCP(db.dataframe[adcp_mask].iloc[0].fullPath)\n",
    "    adcp.file_handler.file_attributes.update({'deviceCode': device_code})\n",
    "else:\n",
    "    print('No ADCP Data available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show parameters of the file\n",
    "dict(adcp.file_handler.file_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_statistic_time_depth(t, depth, values, n_bins=100, step_bins=None, bins_t=None, **kwargs):\n",
    "    \"\"\"Does a binned_statistic over the time for each depth. E.g.\n",
    "    - statistic='mean'\n",
    "    - statistic='std'\n",
    "    - statistic='count'\n",
    "    \n",
    "    PARAMETER\n",
    "    ---------\n",
    "    t: (N,) array_like\n",
    "        values of the time axis\n",
    "    depth: (M,) array_like\n",
    "        values of the depth axis\n",
    "    values: (N,M) array_like\n",
    "        a 2D array where the first axis coresbonds with the time (N,) and the second with thee depth (M,)\n",
    "    n_bins: int, optional\n",
    "        number of bins for the time axis, applies if `step_bins=None` and `bins_t=None`\n",
    "    step_bins: float, optional\n",
    "        step of bins for the time axis, applies if bins_t=None. `n_bins` is ignored if `step_bins!=None`\n",
    "    bins_t: ndarray, optional\n",
    "        bins for the time axis. `n_bins` and `step_bins` are ignored if `bins_t!=None`\n",
    "    **kwars: dict, optional\n",
    "        parsed to scipy.stats.binned_statistic_2d(..., **kwargs). \n",
    "    \"\"\"\n",
    "    depth_2d, time_2d = np.meshgrid(depth, t)\n",
    "    if bins_t is not None:\n",
    "        bins_t = bins_t\n",
    "    elif step_bins is not None:\n",
    "        bins_t = np.arange(t.min(), t.max(), step_bins)\n",
    "    else:\n",
    "        bins_t = np.linspace(t.min(), t.max(), n_bins)\n",
    "    \n",
    "    # bins must be increasing! -> np.sort(depth)\n",
    "    depth = np.sort(depth)\n",
    "    # don't re-bin depth -> add an edge as last item and shift them by a half step\n",
    "    steps_depth = np.mean(np.diff(depth))\n",
    "    bins_d = np.append(depth, [depth[-1]+steps_depth]) - steps_depth/2.\n",
    "\n",
    "    if isinstance(values, np.ma.core.MaskedArray):\n",
    "        mask = ~values.mask\n",
    "    else:\n",
    "        mask = ~np.isnan(values)\n",
    "\n",
    "    statistic, x_edge, y_edge, i = scipy.stats.binned_statistic_2d(x=time_2d[mask], \n",
    "                                    y=depth_2d[mask], \n",
    "                                    values=values[mask], \n",
    "                                    bins=[bins_t, bins_d],  # bins must be increasing!\n",
    "                                    **kwargs\n",
    "                                   )\n",
    "    return statistic, x_edge, y_edge\n",
    "\n",
    "def cal_middle(x):\n",
    "    return (x[1:]+x[:-1])*.5\n",
    "\n",
    "def connect_polar(x):\n",
    "    if isinstance(x, np.ma.MaskedArray):\n",
    "        return np.ma.append(x, x[0])\n",
    "    else:\n",
    "        return np.append(x, x[0])\n",
    "    \n",
    "class Current:\n",
    "    def __init__(self, timestamp, depth, \n",
    "                 velocity_east=None, velocity_north=None, velocity_up=None, \n",
    "                 velocity_abs=None, theta=None, phi=None):\n",
    "        \"\"\"Class to sotre ADCP current data. The data are stored in 2d arrays, where the \n",
    "        first axis is the time and the second the depth. The values itself can be set either by\n",
    "        velocity_east, velocity_north, velocity_up or velocity_abs, theta, phi \n",
    "        (all are 2d arrays with the discribed axis)\"\"\"\n",
    "        self.timestamp = timestamp\n",
    "        self.depth = depth\n",
    "        \n",
    "        self._phi = None\n",
    "        self._theta = None\n",
    "        self._velocity_abs = None\n",
    "        \n",
    "        if all([velocity_east is not None, velocity_north is not None, velocity_up is not None]):\n",
    "            self.set_velocities(velocity_east=velocity_east, velocity_north=velocity_north, velocity_up=velocity_up)\n",
    "        elif any([velocity_abs is None, theta is None, phi is None]):\n",
    "            raise KeyError(f'Either all of [velocity_east, velocity_north, velocity_up] or \\\n",
    "                             all of [velocity_abs, theta, phi] must be set.')\n",
    "        else:\n",
    "            self.set_polar(velocity_abs=velocity_abs, theta=theta, phi=phi)\n",
    "            \n",
    "        \n",
    "    def set_velocities(self, velocity_east, velocity_north, velocity_up):\n",
    "        \"\"\"Set the currents with cartesian data: velocity_east, velocity_north, velocity_up.\"\"\"\n",
    "        self._phi = np.ma.arctan2(velocity_east, velocity_north)\n",
    "        self._phi[self._phi < 0] += 2 * np.pi\n",
    "        \n",
    "        self._velocity_abs = np.ma.sqrt(np.ma.sum([velocity_east[:] ** 2,\n",
    "                                              velocity_north[:] ** 2,\n",
    "                                              velocity_up[:] ** 2], axis=0))\n",
    "        \n",
    "        self._theta = np.zeros_like(velocity_up)\n",
    "        mask = self._velocity_abs != 0\n",
    "        self._theta[mask] = np.ma.arccos(velocity_up[mask] / self._velocity_abs[mask])\n",
    "        self._theta[~mask] = 0\n",
    "        \n",
    "    def set_polar(self, velocity_abs, theta, phi):\n",
    "        \"\"\"Set the currents with polar data: velocity_abs, theta, phi.\"\"\"\n",
    "        self._phi = phi\n",
    "        self._theta = theta\n",
    "        self._vel_abs = velocity_abs\n",
    "        self.del_velocities()\n",
    "        \n",
    "    @property\n",
    "    def time(self):\n",
    "        return strawb.tools.asdatetime(self.timestamp)\n",
    "      \n",
    "    @property\n",
    "    def phi(self):\n",
    "        return self._phi\n",
    "\n",
    "    @property\n",
    "    def theta(self, ):\n",
    "        \"\"\"Theta of velocity. Theta=0 -> upwards, Theta=np.pi=downwards.\"\"\"\n",
    "        return self._theta\n",
    "\n",
    "    @property\n",
    "    def velocity_abs(self, ):\n",
    "        \"\"\"Absolute velocity\"\"\"\n",
    "        return self._velocity_abs\n",
    "    \n",
    "    @property\n",
    "    def velocity_east(self):\n",
    "        return np.ma.sin(self.phi) * np.ma.sin(self.theta) * self.velocity_abs\n",
    "    \n",
    "    @property\n",
    "    def velocity_north(self):\n",
    "        return np.ma.cos(self.phi) * np.ma.sin(self.theta) * self.velocity_abs\n",
    "    \n",
    "    @property\n",
    "    def velocity_up(self):\n",
    "        return np.ma.cos(self.theta) * self.velocity_abs\n",
    "    \n",
    "current = Current(adcp.current.timestamp, adcp.file_handler.depth[:], \n",
    "        velocity_east=adcp.file_handler.velocity_east[:], \n",
    "        velocity_north=adcp.file_handler.velocity_north[:], \n",
    "        velocity_up=adcp.file_handler.velocity_up[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_convolve2d(in1, in2, correct_missing=True, norm=True, valid_ratio=1./3, *args, **kwargs):\n",
    "    \"\"\"A workaround for np.ma.MaskedArray in scipy.signal.convolve2d. \n",
    "    It converts the masked values to complex values=1j. The complex space allows to set a limit\n",
    "    for the imaginary convolution. The function use a ratio `valid_ratio` of np.sum(in2) to set a lower limit\n",
    "    on the imaginary part to mask the values.\n",
    "    I.e. in1=[[1.,1.,--,--]] in2=[[1.,1.]] -> imaginary_part/sum(in2): [[1., 1., .5, 0.]]\n",
    "    -> valid_ratio=.5 -> out:[[1., 1., .5, --]].\n",
    "    PARAMETERS\n",
    "    ---------\n",
    "    in1 : array_like\n",
    "        First input.\n",
    "    in2 : array_like\n",
    "        Second input. Should have the same number of dimensions as `in1`.\n",
    "    correct_missing : bool, optional\n",
    "        correct the value of the convolution as a sum over valid data only, \n",
    "        as masked values account 0 in the real space of the convolution.\n",
    "    norm : bool, optional\n",
    "        if the output should be normalized to np.sum(in2).\n",
    "    valid_ratio: float, optional\n",
    "        the upper limit of the imaginary convolution to mask values. Defined by the ratio of np.sum(in2).\n",
    "    *args, **kwargs: optional\n",
    "        parsed to scipy.signal.convolve(..., *args, **kwargs)\n",
    "    \"\"\"\n",
    "    if not isinstance(in1, np.ma.MaskedArray):\n",
    "        in1 = np.ma.array(in1)\n",
    "    \n",
    "    # np.complex128 -> stores real as np.float64\n",
    "    con = scipy.signal.convolve2d(in1.astype(np.complex128).filled(fill_value=1j), \n",
    "                                  in2.astype(np.complex128), \n",
    "                                  *args, **kwargs\n",
    "                                 )\n",
    "    \n",
    "    # split complex128 to two float64s\n",
    "    con_imag = con.imag\n",
    "    con = con.real\n",
    "    mask = np.abs(con_imag/np.sum(in2)) > valid_ratio\n",
    "    \n",
    "    # con_east.real / (1. - con_east.imag): correction, to get the mean over all valid values\n",
    "    # con_east.imag > percent: how many percent of the single convolution value have to be from valid values\n",
    "    if correct_missing:\n",
    "        correction = np.sum(in2) - con_imag\n",
    "        con[correction!=0] *= np.sum(in2)/correction[correction!=0]\n",
    "        \n",
    "    if norm:\n",
    "        con /= np.sum(in2)\n",
    "        \n",
    "    return np.ma.array(con, mask=mask)\n",
    "\n",
    "# Test\n",
    "in1 = np.ones((1,6))\n",
    "in1[:, 4:] = 0\n",
    "in1 = np.ma.masked_equal(in1, 0)\n",
    "\n",
    "in2 = np.ones((1,3))\n",
    "\n",
    "b = masked_convolve2d(in1, in2, correct_missing=True, mode='valid', norm=True)\n",
    "c = masked_convolve2d(in1, in2, correct_missing=False, mode='valid', norm=True)\n",
    "    \n",
    "in1, b, c.filled(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b89654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "\n",
    "step_bins = 480.  # [seconds]\n",
    "\n",
    "def current_convolve(core_len_depth, core_len_t, adcp,\n",
    "                     speed_limits = 10, downsample=True, weigth=False, error_min=.005, error_max=15.):\n",
    "    \"\"\"\n",
    "    PARAMETER\n",
    "    ---------\n",
    "    core_len_depth, core_len_t: float\n",
    "        defines the 2D-core size for convolution\n",
    "    adcp: list, dict, adcp\n",
    "        input data. It must match one of the following \n",
    "        - list with entries in that order: [timestamp, depth, velocity_east, velocity_north, velocity_up]\n",
    "        - dict with keys: [timestamp, depth, velocity_east, velocity_north, velocity_up]\n",
    "        - a instance of strawb.ADCP\n",
    "    speed_limits: float, optional\n",
    "        in m/s. Values abouve the limit are masked.\n",
    "    downsample: bool, optional\n",
    "        if the resulting data should be downsampled to the half of the core length, i.e. x[::core_len_t//2].\n",
    "        Default, True.\n",
    "    weigth: bool, optional\n",
    "        if the reported errors should be taken into account as weigths. The weights are `1./errors`.\n",
    "        Works only if `adcp` is an instance of `strawb.ADCP(...)`.\n",
    "    error_min, error_max: floats, optional\n",
    "        the limits of the errors. Values over `error_max` are masked (excluded). Values below `error_min`\n",
    "        are set to `error_min`. Otherwise, the weigths can get very high for low errors as weights are\n",
    "        `1./errors`.\n",
    "    RETURN\n",
    "    ------\n",
    "    current: Current\n",
    "    \"\"\"\n",
    "    if isinstance(adcp, list):\n",
    "        timestamp, depth, velocity_east, velocity_north, velocity_up = adcp\n",
    "        velocity_error = None\n",
    "    elif isinstance(adcp, dict):\n",
    "        timestamp = adcp['timestamp']\n",
    "        depth = adcp['depth']\n",
    "        velocity_east  = adcp['velocity_east']\n",
    "        velocity_north = adcp['velocity_north']\n",
    "        velocity_up = adcp['velocity_up']\n",
    "        velocity_error = None\n",
    "    else:\n",
    "        timestamp = adcp.current.timestamp\n",
    "        depth = adcp.file_handler.depth[:80]\n",
    "        velocity_east = adcp.file_handler.velocity_east\n",
    "        velocity_north = adcp.file_handler.velocity_north\n",
    "        velocity_up = adcp.file_handler.velocity_up\n",
    "        velocity_error = adcp.file_handler.velocityError\n",
    "        \n",
    "    core = np.ones((core_len_t, core_len_depth))\n",
    "\n",
    "    con_time = np.convolve(timestamp,\n",
    "                           np.ones(core_len_t)/core_len_t, \n",
    "                           mode='valid')\n",
    "\n",
    "    con_depth = np.convolve(depth,\n",
    "                            np.ones(core_len_depth)/core_len_depth, \n",
    "                            mode='valid')\n",
    "    \n",
    "    velocity_east = np.ma.masked_outside(velocity_east, -speed_limits, speed_limits) \n",
    "    velocity_north = np.ma.masked_outside(velocity_north, -speed_limits, speed_limits) \n",
    "    velocity_up = np.ma.masked_outside(velocity_up, -speed_limits, speed_limits) \n",
    "    \n",
    "    if weigth and velocity_error is not None:\n",
    "        velocity_error = np.ma.masked_outside(velocity_error, -error_max, error_max)\n",
    "        velocity_error.data[velocity_error<error_min] = error_min\n",
    "        con_weigths = masked_convolve2d(1./np.abs(velocity_error), \n",
    "                                   np.ones((core_len_t, core_len_depth)), \n",
    "                                   mode='valid', norm=True, correct_missing=True)\n",
    "        velocity_east /= np.ma.abs(velocity_error)\n",
    "        velocity_north /= np.ma.abs(velocity_error)\n",
    "        velocity_up /= np.ma.abs(velocity_error)\n",
    "        \n",
    "    con_east = masked_convolve2d(velocity_east, core, mode='valid', norm=True, correct_missing=True)\n",
    "    con_north = masked_convolve2d(velocity_north, core, mode='valid', norm=True, correct_missing=True)\n",
    "    con_up = masked_convolve2d(velocity_up, core, mode='valid', norm=True, correct_missing=True)\n",
    "        \n",
    "    if weigth and velocity_error is not None:\n",
    "        con_east /= con_weigths\n",
    "        con_north /= con_weigths\n",
    "        con_up /= con_weigths\n",
    "    \n",
    "    if downsample:\n",
    "        return strawb.adcp.current.Current(timestamp=con_time[::core_len_t//2],\n",
    "                       depth=con_depth,\n",
    "                       velocity_east=con_east[::core_len_t//2],\n",
    "                       velocity_north=con_north[::core_len_t//2],\n",
    "                       velocity_up=con_up[::core_len_t//2],\n",
    "                       )\n",
    "    else:\n",
    "        return strawb.adcp.current.Current(timestamp=con_time, \n",
    "                       velocity_east=con_east,\n",
    "                       velocity_north=con_north,\n",
    "                       velocity_up=con_up,\n",
    "                       depth=con_depth)\n",
    "    \n",
    "# dt = np.diff(adcp.current.timestamp[:2])\n",
    "# core_len_depth = int(9)\n",
    "# core_len_t = int(step_bins/core_len_depth/dt)\n",
    "# con_cur = current_convolve(core_len_depth=5, core_len_t=int(step_bins/dt), speed_limits=5, adcp=adcp)\n",
    "\n",
    "# con_cur6 = current_convolve(core_len_depth=3, core_len_t=int(step_bins/dt), speed_limits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7742352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.diff(adcp.current.timestamp[:2])\n",
    "core_len_depth = int(3)\n",
    "core_len_t = int(step_bins/core_len_depth/dt)\n",
    "con_cur_w = current_convolve(core_len_t=120, core_len_depth = 3, downsample=False,\n",
    "                           speed_limits=15, \n",
    "                           adcp=adcp, weigth=True, error_min=.01, error_max=15.\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f02611",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cur = current_convolve(core_len_t=120, core_len_depth = 3,downsample=False,\n",
    "                           speed_limits=15, \n",
    "                           adcp=adcp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4516cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "strawb.tools.asdatetime(con_cur.timestamp[:440:439])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=con_cur.timestamp[:l]\n",
    "t.max()+l/(t[1]-t[0]) , t.min()-(t[1]-t[0]), t.min(), l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4871457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "scale = core_len_t//2\n",
    "l = 120\n",
    "\n",
    "d_i = 5\n",
    "dd_i = np.argmin(np.abs(con_cur.depth[d_i]-adcp.file_handler.depth[:80]))\n",
    "print(f'Depth: {adcp.file_handler.depth[:][dd_i]:.1f}m')\n",
    "t=con_cur.timestamp[:l+1]\n",
    "\n",
    "m = adcp.current.timestamp <= t.max()+(t[scale]-t[0])\n",
    "m &= adcp.current.timestamp >= t.min()-(t[scale]-t[0])\n",
    "# ax.plot(adcp.current.time[m], adcp.file_handler.velocity_east[:, dd_i][m], 'o', \n",
    "#          label=f'Raw data', alpha=.75, ms=2,)  # ; depth={adcp.file_handler.depth[:][dd_i]:.0f}m\n",
    "ax.errorbar(adcp.current.time[m], adcp.file_handler.velocity_east[:, dd_i][m], \n",
    "            yerr=adcp.file_handler.velocityError[:, dd_i][m],\n",
    "            fmt='o', \n",
    "            label=f'Raw data', alpha=.75, ms=2,)\n",
    "\n",
    "ax.scatter(adcp.current.time[m], adcp.file_handler.velocity_east[:, dd_i][m], \n",
    "            yerr=adcp.file_handler.velocityError[:, dd_i][m],\n",
    "            fmt='o', \n",
    "            label=f'Raw data', alpha=.75, ms=2,)\n",
    "    \n",
    "ax.plot(strawb.tools.asdatetime(t), con_cur.velocity_east[:l+1, d_i], 'o', \n",
    "         label=f'2D convolve data', alpha=.75, ms=5,)  # ; depth={con_depth[d_i]:.0f}m\n",
    "\n",
    "ax.plot(strawb.tools.asdatetime(t), con_cur_w.velocity_east[:l+1, d_i], 'o', \n",
    "         label=f'2D convolve data', alpha=.75, ms=5,)  # ; depth={con_depth[d_i]:.0f}m\n",
    "\n",
    "ax.plot(strawb.tools.asdatetime(t[:l:core_len_t//2]), \n",
    "        con_cur.velocity_east[:l:core_len_t//2, d_i], 'o',ms=7, \n",
    "         label=f'Reduced 2D convolve data')  # ; depth={con_depth[d_i]:.0f}m\n",
    "\n",
    "ax.plot(strawb.tools.asdatetime(t[::core_len_t//2]), \n",
    "        con_cur_w.velocity_east[:(l+1):core_len_t//2, d_i], 'o',ms=7, \n",
    "         label=f'Reduced 2D convolve data')  # ; depth={con_depth[d_i]:.0f}m\n",
    "\n",
    "# # ax = plt.gca()\n",
    "# ax.fill_between(strawb.tools.asdatetime((t[1:4]+t[0:3])*.5), 1, where=[1,1,0],\n",
    "#                 color='gray', alpha=0.5, transform=ax.get_xaxis_transform())\n",
    "\n",
    "\n",
    "ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Velocity East [m/s]')\n",
    "plt.xlabel('Time')\n",
    "plt.grid()\n",
    "# plt.xlim(adcp.current.time[m][0], adcp.current.time[m][-1])\n",
    "# plt.autoscale(enable=True, axis='y')\n",
    "# plt.autoscale(enable=True, axis='x', tight=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2fe98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t[:(l+60):core_len_t//2].shape, core_len_t//2, l, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f27e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cur_w.velocity_east[:5, 0], con_cur.velocity_east[:5, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afcf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "cs = plt.scatter(adcp.file_handler.velocity_east[:, dd_i][m], \n",
    "            adcp.file_handler.velocityError[:, dd_i][m],\n",
    "            c=strawb.tools.datetime2float(adcp.current.time[m]-adcp.current.time[m][0])/60.,\n",
    "           )\n",
    "plt.colorbar(cs, label='Time [min]')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da20bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(adcp.file_handler.velocity_east[:, dd_i][m], bins=20)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3af8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(np.abs(adcp.file_handler.velocityError[:, dd_i][m]), bins=20, )\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9809585",
   "metadata": {},
   "outputs": [],
   "source": [
    "strawb.tools.datetime2float(adcp.current.time[m]-adcp.current.time[m][0])/60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_limits = 15.\n",
    "ve = np.ma.masked_outside(adcp.file_handler.velocity_east[:, :][m], -speed_limits, speed_limits)\n",
    "verr = np.ma.masked_outside(adcp.file_handler.velocityError[:, :][m], -100, 100)\n",
    "# verr.mask = verr.mask | (np.abs(verr.data) < 0.005)\n",
    "min_error = 0.005\n",
    "verr.data[np.abs(verr.data) < min_error] = min_error\n",
    "t = adcp.current.timestamp[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "verr_r = verr[:, dd_i]\n",
    "np.abs(verr[:, dd_i]).min(),\n",
    "verr_r.data[~verr_r.mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0254de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "verr[16761,    76], adcp.file_handler.velocity_east[16761,    76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c13ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "v=con_east[:l, d_i]\n",
    "t=con_time[:l]\n",
    "\n",
    "plt.plot(adcp.current.time[m], ve[:, dd_i], 'o', \n",
    "         label=f'Raw data', alpha=.75, ms=2,)  # ; depth={adcp.file_handler.depth[:][dd_i]:.0f}m\n",
    "\n",
    "# plt.errorbar(adcp.current.time[m], ve[:, dd_i], \n",
    "#             yerr=adcp.file_handler.velocityError[:, dd_i][m],\n",
    "#             fmt='o', \n",
    "#             label=f'Raw data', alpha=.75, ms=2,)\n",
    "\n",
    "lin, = plt.plot(strawb.tools.asdatetime(t), v, '-',ms=7, \n",
    "         label=f'Reduced 2D convolve data')  # ; depth={con_depth[d_i]:.0f}m\n",
    "\n",
    "t = con_time[::core_len_t//2][:l//scale+1]\n",
    "v=con_east[::core_len_t//2, d_i][:l//scale+1]\n",
    "plt.plot(strawb.tools.asdatetime(t), v, 'o',ms=7, \n",
    "         label=f'Reduced 2D convolve data', color=lin.get_color())  # ; depth={con_depth[d_i]:.0f}m\n",
    "\n",
    "v=con_east_w[:l, d_i]\n",
    "t=con_time[:l]\n",
    "lin, = plt.plot(strawb.tools.asdatetime(t), v, '-',ms=7, \n",
    "         label=f'Reduced 2D convolve data')  # ; depth={con_depth[d_i]:.0f}m\n",
    "\n",
    "t = con_time[::core_len_t//2][:l//scale+1]\n",
    "v=con_east_w[::core_len_t//2, d_i][:l//scale+1]\n",
    "plt.plot(strawb.tools.asdatetime(t), v, 'o',ms=7, \n",
    "         label=f'Reduced 2D convolve data', color=lin.get_color())  # ; depth={con_depth[d_i]:.0f}m\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aaa55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_hist(cur):\n",
    "    fig, ax = plt.subplots(sharey=True, ncols=3)\n",
    "\n",
    "    bins = np.linspace(cur.vel_east.min(), cur.vel_east.max(), 100)\n",
    "    for i in range(cur.vel_east.shape[1]):\n",
    "        hist, bin_edges = np.histogram(cur.vel_east[:,i], bins=bins)\n",
    "        ax[0].plot(cal_middle(bin_edges), \n",
    "                 hist, \n",
    "                 color=plt.get_cmap('viridis_r')(i/cur.vel_east.shape[1]), \n",
    "                 alpha=.5)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(cur.vel_north[:,i], bins=bins)\n",
    "        ax[1].plot(cal_middle(bin_edges), \n",
    "                 hist, \n",
    "                 color=plt.get_cmap('viridis_r')(i/cur.vel_east.shape[1]), \n",
    "                 alpha=.5)\n",
    "        \n",
    "        hist, bin_edges = np.histogram(cur.vel_up[:,i], bins=bins)\n",
    "        ax[2].plot(cal_middle(bin_edges), \n",
    "                 hist, \n",
    "                 color=plt.get_cmap('viridis_r')(i/cur.vel_east.shape[1]), \n",
    "                 alpha=.5)\n",
    "        \n",
    "    for axi in ax:\n",
    "        axi.grid()    \n",
    "        axi.set_yscale('log')\n",
    "    \n",
    "speed_hist(statistic_cur)\n",
    "speed_hist(con_cur)\n",
    "speed_hist(con_cur6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35becb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_bins = 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adcp_cur = Current(adcp.current.time, \n",
    "                   adcp.file_handler.velocity_east[:],\n",
    "                   adcp.file_handler.velocity_north[:],\n",
    "                   adcp.file_handler.velocity_up[:],\n",
    "                   adcp.file_handler.depth[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0109a82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.stats.binned_statistic_dd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17507e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_statistic_ma(adcp, velocity, speed_limits = 10, step_bins = 120.):\n",
    "    velocity = np.ma.masked_outside(velocity, -speed_limits, speed_limits)\n",
    "    statistic_sum, t_edge, d_edge = binned_statistic_time_depth(adcp.current.timestamp, \n",
    "                                                            adcp.file_handler.depth[:80], \n",
    "                                                            velocity.filled(0), \n",
    "                                                            step_bins=step_bins, \n",
    "                                                            statistic='sum')\n",
    "\n",
    "    statistic_counts, t_edge, d_edge = binned_statistic_time_depth(adcp.current.timestamp, \n",
    "                                                            adcp.file_handler.depth[:80], \n",
    "                                                            ~velocity.mask, \n",
    "                                                            step_bins=step_bins, \n",
    "                                                            statistic='sum')\n",
    "\n",
    "    statistic_sum[statistic_counts!=0] /= statistic_counts[statistic_counts!=0]\n",
    "    return np.ma.array(statistic_sum, mask=statistic==0)[::-1], t_edge, d_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a74297",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic_east, t_edge, d_edge = binned_statistic_ma(adcp, \n",
    "                                                     adcp.file_handler.velocity_east, \n",
    "                                                     step_bins=step_bins)\n",
    "\n",
    "statistic_north, t_edge, d_edge = binned_statistic_ma(adcp, \n",
    "                                                        adcp.file_handler.velocity_north[:], \n",
    "                                                        step_bins=step_bins)\n",
    "\n",
    "statistic_up, t_edge, d_edge = binned_statistic_ma(adcp,\n",
    "                                                        adcp.file_handler.velocity_up[:], \n",
    "                                                        step_bins=step_bins)\n",
    "\n",
    "# # withotu masked arrays\n",
    "# statistic_east, t_edge, d_edge = binned_statistic_time_depth(adcp.current.timestamp, \n",
    "#                                                         adcp.file_handler.depth[:80], \n",
    "#                                                         adcp.file_handler.velocity_east[:].astype(np.complex64), \n",
    "#                                                         step_bins=step_bins, \n",
    "#                                                         statistic='mean')\n",
    "\n",
    "# statistic_north, t_edge, d_edge = binned_statistic_time_depth(adcp.current.timestamp, \n",
    "#                                                         adcp.file_handler.depth[:80], \n",
    "#                                                         adcp.file_handler.velocity_north[:], \n",
    "#                                                         step_bins=step_bins, \n",
    "#                                                         statistic='mean')\n",
    "\n",
    "# statistic_up, t_edge, d_edge = binned_statistic_time_depth(adcp.current.timestamp, \n",
    "#                                                         adcp.file_handler.depth[:80], \n",
    "#                                                         adcp.file_handler.velocity_up[:], \n",
    "#                                                         step_bins=step_bins, \n",
    "#                                                         statistic='mean')\n",
    "\n",
    "statistic_cur = Current(strawb.tools.asdatetime(cal_middle(t_edge)), \n",
    "                        statistic_east[:,::-1],\n",
    "                        statistic_north[:,::-1],\n",
    "                        statistic_up[:,::-1],\n",
    "                        adcp.file_handler.depth[:80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d4c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(sharex=True, nrows=5)\n",
    "\n",
    "n_max = 1000\n",
    "ax[0].plot(adcp.current.time, adcp.current.phi[:, 40])\n",
    "ax[0].plot(statistic_time, _phi[:, 40])\n",
    "ax[0].plot(con_time, _phi_con[:, 40])\n",
    "\n",
    "# ax[1].plot(adcp.current.time, np.unwrap(adcp.current.phi[:, 40]))\n",
    "ax[1].plot(statistic_time, np.unwrap(_phi[:, 40]))\n",
    "ax[1].plot(con_time, np.unwrap(_phi_con[:, 40]))\n",
    "\n",
    "ax[2].plot(adcp.current.time, adcp.file_handler.velocity_east[:, 40], alpha=.5)\n",
    "ax[2].plot(adcp.current.time, adcp.file_handler.velocity_east[:, 41], alpha=.5)\n",
    "ax[2].plot(statistic_time, statistic_east[:, 40], alpha=.5)\n",
    "ax[2].plot(con_time, con_east[:, 40], alpha=.5)\n",
    "\n",
    "ax[3].plot(adcp.current.time, adcp.file_handler.velocity_north[:, 40], alpha=.5)\n",
    "ax[3].plot(adcp.current.time, adcp.file_handler.velocity_north[:, 41], alpha=.5)\n",
    "ax[3].plot(statistic_time, statistic_north[:, 40], alpha=.5)\n",
    "ax[3].plot(con_time, con_north[:, 40], alpha=.5)\n",
    "\n",
    "ax[4].plot(adcp.current.time, adcp.current.velocity_abs[:, 40], alpha=.5)\n",
    "ax[4].plot(statistic_time, vel_abs[:, 40], alpha=.5)\n",
    "ax[4].plot(con_time, vel_abs_con[:, 40], alpha=.5)\n",
    "\n",
    "ax[-1].xaxis.set_major_formatter(\n",
    "    mdates.ConciseDateFormatter(ax[1].xaxis.get_major_locator()))\n",
    "\n",
    "for axi in ax:\n",
    "    axi.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3057ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cur.depth = -con_cur.depth\n",
    "con_cur6.depth = -con_cur6.depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b07cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ma.masked_equal([0,1,2,3,4],2).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_depth_percentiles(cur, ax=None):\n",
    "    plt.rcParams.update({'mathtext.default':  'regular' })\n",
    "    def ordinal(n):\n",
    "        ordinal_str = {1:\"st\",2:\"nd\",3:\"rd\"}.get(int(str(n)[-1]), \"th\")\n",
    "        return f'{str(n)}${{}}^{{{ordinal_str}}}$'\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10,4), nrows=1, ncols=1)\n",
    "        \n",
    "\n",
    "#     velocity_abs = np.ma.masked_equal(cur.velocity_abs, 0)\n",
    "\n",
    "    mask_depth = con_cur.velocity_abs.count(axis=0) > 0\n",
    "    vel_abs = np.ma.filled(cur.velocity_abs[:, mask_depth], np.nan)\n",
    "        \n",
    "    percentile = np.array([[2, 98], [16, 84]])\n",
    "    for i, p_i in enumerate(np.sort([50, *percentile.flatten()])[::-1]):\n",
    "    #     if p_i==50:\n",
    "    #         plt.plot(adcp.file_handler.depth[:80],\n",
    "    #                  np.ma.mean(velocity_abs, axis=0), \n",
    "    #                  label='mean',\n",
    "    #         )\n",
    "    #     else:\n",
    "        \n",
    "        ax.plot(cur.depth[mask_depth], \n",
    "                np.nanpercentile(vel_abs, p_i, axis=0), \n",
    "                 color='black' if p_i!=50 else None,\n",
    "                 alpha=.2+.1*i if p_i!=50 else 1,\n",
    "                 label=f'{ordinal(p_i)} percentile')\n",
    "\n",
    "        for i, p_i in enumerate(percentile):\n",
    "            per_low = np.nanpercentile(vel_abs, p_i[0], axis=0)\n",
    "            per_hig = np.nanpercentile(vel_abs, p_i[1], axis=0)\n",
    "            ax.fill_between(cur.depth[mask_depth], per_low, per_hig,\n",
    "                 color='gray',\n",
    "                 alpha=.15,#+.02*i,\n",
    "                )\n",
    "\n",
    "        pass\n",
    "    ax.grid()\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Water Depth [m]')\n",
    "    ax.set_ylabel('Velocity [m/s]')\n",
    "#     plt.xlim(cur.depth.min(), -2080.)#cur.depth.max())\n",
    "    ax.set_ylim(0)\n",
    "    ax.autoscale(enable=True, axis='x', tight=True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,4), nrows=2, ncols=1, sharex=True, \n",
    "#                        sharey=True\n",
    "                      )\n",
    "\n",
    "# speed_depth_percentiles(adcp_cur)\n",
    "# speed_depth_percentiles(statistic_cur)\n",
    "speed_depth_percentiles(con_cur, ax=ax[0])\n",
    "# speed_depth_percentiles(con_cur6)\n",
    "speed_depth_percentiles(con_cur_w, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def direction_hist(cur):\n",
    "    fig, ax = plt.subplots(subplot_kw={'projection': 'polar'}, ncols=2, squeeze=False)\n",
    "    ax = ax.flatten()\n",
    "\n",
    "#     for d_i in [2600, 2350, 2100]:\n",
    "#         i = np.argmin(np.abs(cur.depth-d_i))\n",
    "    for i, d_i in enumerate(cur.depth):\n",
    "        mask = cur.velocity_abs[:,i] != 0\n",
    "        hist, bin_edges = np.histogram(cur.phi[mask, i], bins=np.linspace(0, np.pi*2, 50), #density=True,\n",
    "    #                                    weights=velocity_abs[mask, i],\n",
    "                                      )\n",
    "\n",
    "        ax[0].plot(connect_polar(cal_middle(bin_edges)),\n",
    "                   connect_polar(hist/np.sum(hist)), # [*x, x[0]] to connect plot at 0deg\n",
    "                   color=plt.get_cmap('viridis_r')(i/80.), alpha=.5,\n",
    "#                    label=f'{cur.depth[i]:.0f}m',\n",
    "                  )\n",
    "\n",
    "        hist, bin_edges = np.histogram(cur.theta[mask,i], bins=np.linspace(0, np.pi, 100), #density=True,\n",
    "        #                                weights=adcp.current.velocity_abs,\n",
    "                                      )\n",
    "        middle = cal_middle(bin_edges)\n",
    "        ax[1].plot(connect_polar(cal_middle(bin_edges)),\n",
    "                   connect_polar(hist/np.sum(hist)), # [*x, x[0]] to connect plot at 0deg\n",
    "                   color=plt.get_cmap('viridis_r')(i/80.), alpha=.5,\n",
    "#                   label=f'{cur.depth[i]:.0f}m',\n",
    "                  )\n",
    "\n",
    "    for ax_i in ax:\n",
    "        ax_i.set_theta_zero_location(\"N\")\n",
    "        ax_i.yaxis.set_major_locator(ticker.MaxNLocator(1)) # Less radial ticks\n",
    "        ax_i.yaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "#         ax_i.yaxis.set_major_formatter(ticker.FormatStrFormatter('%g m/s'))\n",
    "    #     ax_i.set_rmax(.5)\n",
    "        ax_i.grid(which='minor', linestyle='--', linewidth='0.15', color='black')\n",
    "\n",
    "    ax[0].set_theta_direction('clockwise')\n",
    "    ax[0].set_rlabel_position(22.5*0.5)  # Move radial labels away from plotted line\n",
    "\n",
    "    ax[1].set_thetamin(0)\n",
    "    ax[1].set_thetamax(180)\n",
    "    ax[1].xaxis.set_major_locator(ticker.MultipleLocator(np.pi/4.))\n",
    "    \n",
    "    # ax.set_rmax(2)\n",
    "    # ax[1].set_rticks([0, .05,.1])  # Less radial ticks\n",
    "    # ax[0].grid(which='both')\n",
    "#     ax[1].legend(title='Water Depth', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax[1].set_title('Theta')\n",
    "    ax[0].set_title('Phi')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# direction_hist(adcp_cur)\n",
    "# direction_hist(statistic_cur)\n",
    "direction_hist(con_cur)\n",
    "direction_hist(con_cur6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfe0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_depth(cur):\n",
    "    for i, d_i in enumerate(cur.depth):\n",
    "        mask = cur.velocity_abs[:,i] != 0\n",
    "        hist, bin_edges = np.histogram(cur.phi[mask, i], bins=np.linspace(0, np.pi*2, 50), #density=True,\n",
    "    #                                    weights=velocity_abs[mask, i],\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, x_edge, y_edge, j = scipy.stats.binned_statistic_2d(\n",
    "    cur.velocity_abs[mask, i],\n",
    "    cur.phi[mask, i],\n",
    "    cur.velocity_abs[mask, i],\n",
    "    'count',\n",
    "    bins=[50, np.linspace(0, np.pi*2, 50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ff378",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cur6.phi.shape, con_cur6.depth.shape, con_cur6.velocity_abs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0ab42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cur6.velocity_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros((*con_cur6.phi.shape, 3))\n",
    "# vec = np.array([con_cur6.velocity_abs, con_cur6.phi])\n",
    "vec[:,:,0] = con_cur6.depth.reshape(1,-1)\n",
    "vec[:,:,1] = con_cur6.velocity_abs\n",
    "vec[:,:,2] = con_cur6.phi\n",
    "\n",
    "\n",
    "vec = vec.reshape(-1,3)[~con_cur6.velocity_abs.mask.reshape(-1)]\n",
    "print(len(vec))\n",
    "mask = vec[:,1] >= 1e-2\n",
    "print(np.sum(~mask), np.sum(~mask)/vec[:,1].size)\n",
    "\n",
    "steps_depth = np.mean(np.diff(con_cur6.depth))\n",
    "bins_d = np.append(con_cur6.depth, [con_cur6.depth[-1]+steps_depth]) - steps_depth/2.\n",
    "\n",
    "bins_phi = np.linspace(0, np.pi*2, 100)\n",
    "\n",
    "bins_v = np.linspace(con_cur6.velocity_abs.min(), con_cur6.velocity_abs.max(), 100)\n",
    "    \n",
    "res_vel_mean = scipy.stats.binned_statistic_dd(vec[mask], \n",
    "                                vec[mask, 1],\n",
    "                                'mean',\n",
    "                                bins=[bins_d[::-1], bins_v, bins_phi],\n",
    "                               )\n",
    "res_vel_std = scipy.stats.binned_statistic_dd(vec[mask], \n",
    "                                vec[mask, 1],\n",
    "                                'max',\n",
    "                                bins=[bins_d[::-1], bins_v, bins_phi],\n",
    "                               )\n",
    "\n",
    "res_pro = scipy.stats.binned_statistic_dd(vec[mask], \n",
    "                                vec[mask, 1],\n",
    "                                'count',\n",
    "                                bins=[bins_d[::-1], bins_v, bins_phi],\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d95a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw=dict(projection='polar'), ncols=3)\n",
    "# ax.contour(middle(y_edge), middle(x_edge), statistic)\n",
    "\n",
    "depths = cal_middle(res_vel_mean.bin_edges[0])\n",
    "for i in np.arange(len(depths))[::-1]:\n",
    "    ax[0].plot(connect_polar(cal_middle(res_vel_mean.bin_edges[2])),\n",
    "            connect_polar(np.nanmean(res_vel_mean.statistic[i, :, :], axis=0)),\n",
    "            color=plt.get_cmap('viridis')(i/(len(depths)+1)), alpha=.5)\n",
    "    \n",
    "depths = cal_middle(res_vel_std.bin_edges[0])\n",
    "for i in np.arange(len(depths))[::-1]:\n",
    "    ax[1].plot(connect_polar(cal_middle(res_vel_std.bin_edges[2])),\n",
    "            connect_polar(np.nanmax(res_vel_std.statistic[i, :, :], axis=0)),\n",
    "            color=plt.get_cmap('viridis')(i/(len(depths)+1)), alpha=.5)\n",
    "\n",
    "depths = cal_middle(res_pro.bin_edges[0])\n",
    "for i in np.arange(len(depths))[::-1]:\n",
    "    norm = np.nansum(res_pro.statistic[i, :, :])\n",
    "    norm *= np.diff(res_pro.bin_edges[2])[0]\n",
    "    if norm!=0:\n",
    "        ax[2].plot(connect_polar(cal_middle(res_pro.bin_edges[2])),\n",
    "                connect_polar(np.nanmean(res_pro.statistic[i, :, :], axis=0)/ norm),\n",
    "                color=plt.get_cmap('viridis')(i/(len(depths)+1)), alpha=.5)\n",
    "\n",
    "for ax_i in ax:\n",
    "    ax_i.set_theta_zero_location(\"N\")\n",
    "    ax_i.yaxis.set_major_locator(ticker.MaxNLocator(4)) # Less radial ticks\n",
    "    ax_i.yaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "    ax_i.set_theta_direction('clockwise')\n",
    "#     ax_i.yaxis.set_major_formatter(ticker.FormatStrFormatter('%g m/s'))\n",
    "#     ax_i.set_rmax(.5)\n",
    "    ax_i.grid(which='minor', linestyle='--', linewidth='0.15', color='black')\n",
    "\n",
    "ax[0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%g m/s'))\n",
    "ax[1].yaxis.set_major_formatter(ticker.FormatStrFormatter('%g m/s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ab6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw=dict(projection='polar'), ncols=2)\n",
    "# ax.contour(middle(y_edge), middle(x_edge), statistic)\n",
    "\n",
    "depths = cal_middle(res_vel.bin_edges[0])\n",
    "for i in np.arange(len(depths))[::-1]:\n",
    "    ax[0].plot(connect_polar(cal_middle(res_vel.bin_edges[2])),\n",
    "            connect_polar(np.nanmean(res_vel.statistic[i, :, :], axis=0)),\n",
    "            color=plt.get_cmap('viridis')(i/(len(depths)+1)), alpha=.5)\n",
    "\n",
    "depths = cal_middle(res_pro.bin_edges[0])\n",
    "for i in np.arange(len(depths))[::-1]:\n",
    "    norm = np.nansum(res_pro.statistic[i, :, :])\n",
    "    norm *= np.diff(res_pro.bin_edges[2])[0]\n",
    "    ax[1].plot(connect_polar(cal_middle(res_pro.bin_edges[2])),\n",
    "            connect_polar(np.nanmean(res_pro.statistic[i, :, :], axis=0)/ norm),\n",
    "            color=plt.get_cmap('viridis')(i/(len(depths)+1)), alpha=.5)\n",
    "\n",
    "for ax_i in ax:\n",
    "    ax_i.set_theta_zero_location(\"N\")\n",
    "    ax_i.yaxis.set_major_locator(ticker.MaxNLocator(3)) # Less radial ticks\n",
    "    ax_i.yaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "    ax_i.set_theta_direction('clockwise')\n",
    "#     ax_i.yaxis.set_major_formatter(ticker.FormatStrFormatter('%g m/s'))\n",
    "#     ax_i.set_rmax(.5)\n",
    "    ax_i.grid(which='minor', linestyle='--', linewidth='0.15', color='black')\n",
    "\n",
    "ax[0].yaxis.set_major_formatter(ticker.FormatStrFormatter('%g m/s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12505dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.tri as mtri\n",
    "\n",
    "vel_mean = res_vel_mean.statistic #np.nanmean(res_vel_mean.statistic, axis=1)\n",
    "plot_vec = np.zeros((4, *vel_mean.shape))\n",
    "plot_vec[2] = cal_middle(bins_d).reshape(-1, 1, 1)\n",
    "plot_vec[0] = np.cos(cal_middle(bins_phi)).reshape(1, 1, -1) * vel_mean\n",
    "plot_vec[1] = np.sin(cal_middle(bins_phi)).reshape(1, 1, -1) * vel_mean\n",
    "plot_vec[3] = cal_middle(bins_phi).reshape(1, 1, -1)\n",
    "\n",
    "plot_vec = np.nanmean(plot_vec, axis=2)\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Make data.\n",
    "X, Y = np.meshgrid(cal_middle(bins_phi), cal_middle(bins_d))\n",
    "\n",
    "# Plot the surface.\n",
    "# plot_vec[2].flatten()\n",
    "\n",
    "# tri = mtri.Triangulation(plot_vec[3].flatten(),\n",
    "#                          plot_vec[2].flatten())\n",
    "\n",
    "# surf = ax.plot_trisurf(plot_vec[0].flatten(), \n",
    "#                        plot_vec[1].flatten(), \n",
    "#                        plot_vec[2].flatten(), \n",
    "#                        triangles=tri.triangles,\n",
    "#                        cmap=plt.get_cmap('viridis_r'),\n",
    "#                        linewidth=0, \n",
    "#                        antialiased=False)\n",
    "print(plot_vec[2].shape)\n",
    "surf = ax.plot_surface(plot_vec[0], \n",
    "                       plot_vec[1], \n",
    "                       plot_vec[2], \n",
    "                       cmap=plt.get_cmap('viridis_r'),\n",
    "                       linewidth=0, \n",
    "                       antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "# ax.set_zlim(-1.01, 1.01)\n",
    "# ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# A StrMethodFormatter is used automatically\n",
    "# ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "range_xy = np.diff([ax.get_xbound(), ax.get_ybound()])#, ax.get_zbound()\n",
    "range_xy *= 4./range_xy.max()\n",
    "ax.set_box_aspect((*range_xy, 3) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f618d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Make data.\n",
    "X, Y = np.meshgrid(cal_middle(bins_phi), cal_middle(bins_d))\n",
    "\n",
    "# Plot the surface.\n",
    "surf = ax.plot_trisurf(X.flatten(), Y.flatten(), np.nanmean(res_vel_mean.statistic, axis=1).flatten(), \n",
    "                       cmap=plt.get_cmap('viridis_r'),\n",
    "                       linewidth=0, antialiased=False)\n",
    "\n",
    "# Customize the z axis.\n",
    "# ax.set_zlim(-1.01, 1.01)\n",
    "# ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "# A StrMethodFormatter is used automatically\n",
    "# ax.zaxis.set_major_formatter('{x:.02f}')\n",
    "\n",
    "# Add a color bar which maps values to colors.\n",
    "fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffe805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_depth_polar(cur):\n",
    "    fig, ax = plt.subplots(subplot_kw=dict(projection='polar'))\n",
    "    # ax.contour(middle(y_edge), middle(x_edge), statistic)\n",
    "\n",
    "    for i, d_i in enumerate(cur.depth):\n",
    "        mask = ~cur.velocity_abs.mask[:,i] #>= 1e-2\n",
    "        \n",
    "        if np.sum(mask) != 0:\n",
    "            statistic, x_edge, y_edge, j = scipy.stats.binned_statistic_2d(\n",
    "                cur.velocity_abs[mask, i].data,\n",
    "                cur.phi[mask, i],\n",
    "                None,\n",
    "                'count',\n",
    "                bins=[50, np.linspace(0, np.pi*2, 50)])\n",
    "\n",
    "            mean_v = np.ma.average(cal_middle(x_edge).reshape(-1,1)*np.ones(statistic.shape[1]),\n",
    "                   weights=statistic,\n",
    "                   axis=0)\n",
    "\n",
    "            ax.plot(connect_polar(cal_middle(y_edge)),\n",
    "                    connect_polar(mean_v),\n",
    "                    color=plt.get_cmap('viridis_r')(i/80.), alpha=.5)\n",
    "\n",
    "    for ax_i in [ax]:\n",
    "        ax_i.set_theta_zero_location(\"N\")\n",
    "        ax_i.yaxis.set_major_locator(ticker.MaxNLocator(3)) # Less radial ticks\n",
    "        ax_i.yaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "        ax_i.yaxis.set_major_formatter(ticker.FormatStrFormatter('%g m/s'))\n",
    "    #     ax_i.set_rmax(.5)\n",
    "        ax_i.grid(which='minor', linestyle='--', linewidth='0.15', color='black')\n",
    "\n",
    "    ax.set_theta_direction('clockwise')\n",
    "\n",
    "# sc = ax.scatter(phi, velocity_abs, # [*x, x[0]] to connect plot at 0deg\n",
    "# #               label=f'{adcp.file_handler.depth[i]:.0f}m',\n",
    "#                    alpha=1, s=2,\n",
    "#               c=adcp.file_handler.depth[:80].reshape(1,-1)*np.ones_like(phi))\n",
    "\n",
    "# mean_depth_polar(adcp_cur)\n",
    "# mean_depth_polar(statistic_cur)\n",
    "mean_depth_polar(con_cur)\n",
    "mean_depth_polar(con_cur6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cbd4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_depth_polar(con):\n",
    "    fig, ax = plt.subplots(#figsize=(9,4),\n",
    "                           subplot_kw={'projection': 'polar'}, ncols=2, squeeze=False)\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    # mask = velocity_abs[:, i] > .0001\n",
    "    # middle = (bin_edges[1:]+bin_edges[:-1])*.5\n",
    "    sc = ax[0].scatter(con.phi, con.velocity_abs, # [*x, x[0]] to connect plot at 0deg\n",
    "    #               label=f'{adcp.file_handler.depth[i]:.0f}m',\n",
    "                       alpha=.2, s=2,\n",
    "                  c=con.depth.reshape(1,-1)*np.ones_like(con.phi))\n",
    "    ax[1].scatter(con.theta, con.velocity_abs, # [*x, x[0]] to connect plot at 0deg\n",
    "    #               label=f'{adcp.file_handler.depth[i]:.0f}m',\n",
    "                  alpha=.2, s=2,\n",
    "                  c=con.depth.reshape(1,-1)*np.ones_like(con.phi))\n",
    "\n",
    "    sc.set_alpha(1)\n",
    "    cb = fig.colorbar(sc, ax=ax[1],\n",
    "                 shrink=.75, label='Water Depth [m]')\n",
    "\n",
    "\n",
    "\n",
    "    # ax[0].contour(middle(y_edge), middle(x_edge), statistic)\n",
    "\n",
    "    # for i in [10, 45, 79]:\n",
    "    #     mask = velocity_abs[:, i] > .0001\n",
    "    #     middle = (bin_edges[1:]+bin_edges[:-1])*.5\n",
    "    #     ax[0].scatter(phi[mask, i], velocity_abs[mask, i], # [*x, x[0]] to connect plot at 0deg\n",
    "    #                   label=f'{adcp.file_handler.depth[i]:.0f}m', alpha=.2, s=1,\n",
    "    #                   c=adcp.file_handler.depth[:80].reshape(-1,1))\n",
    "\n",
    "    #     ax[1].scatter(theta[mask, i], velocity_abs[mask, i], # [*x, x[0]] to connect plot at 0deg\n",
    "    #               label=f'{adcp.file_handler.depth[i]:.0f}m', alpha=.2, s=1)\n",
    "\n",
    "    for ax_i in ax:\n",
    "        ax_i.set_theta_zero_location(\"N\")\n",
    "        ax_i.yaxis.set_major_locator(ticker.MaxNLocator(1)) # Less radial ticks\n",
    "        ax_i.yaxis.set_minor_locator(ticker.AutoMinorLocator(2))\n",
    "        ax_i.yaxis.set_major_formatter(ticker.FormatStrFormatter('%g m/s'))\n",
    "    #     ax_i.set_rmax(.5)\n",
    "        ax_i.grid(which='minor', linestyle='--', linewidth='0.15', color='black')\n",
    "\n",
    "    ax[0].set_theta_direction('clockwise')\n",
    "    ax[0].set_rlabel_position(22.5*0.5)  # Move radial labels away from plotted line\n",
    "\n",
    "    ax[1].set_thetamin(0)\n",
    "    ax[1].set_thetamax(180)\n",
    "    ax[1].xaxis.set_major_locator(ticker.MultipleLocator(np.pi/4.))\n",
    "\n",
    "    # ax[0].set_rgridminor(True)\n",
    "    # ax[0].set_rmax(.5)\n",
    "    # label_position=ax[0].get_rlabel_position()\n",
    "    # ax[0].text(np.radians(label_position+10),\n",
    "    #            ax[0].get_rmax()/2.,'Velocity [m/s]',\n",
    "    #            rotation=label_position,ha='center',va='center')\n",
    "\n",
    "    # ax.set_rmax(2)\n",
    "    # ax[1].set_rticks([0, .05,.1])  # Less radial ticks\n",
    "    # ax[0].grid(which='both')\n",
    "    # ax[1].legend(title='Water Depth', loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    ax[1].set_title('Theta')\n",
    "    ax[0].set_title('Phi')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# scatter_depth_polar(statistic_cur)\n",
    "# scatter_depth_polar(con_cur)\n",
    "scatter_depth_polar(con_cur6)\n",
    "# scatter_depth_polar(adcp_cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_profile(cur):\n",
    "    fig, ax = plt.subplots(nrows=3, squeeze=False, sharex=True)\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    for d_i in [2600, 2350, 2100]:\n",
    "        i = np.argmin(np.abs(cur.depth-d_i))\n",
    "        label = f'{cur.depth[i]:.0f} m'\n",
    "        ax[0].plot(cur.time,\n",
    "                   cur.velocity_abs[:, i],\n",
    "                   label=label, alpha=.5)\n",
    "        ax[1].plot(cur.time,\n",
    "                   np.rad2deg(cur.phi[:, i]),\n",
    "                   label=label, alpha=.5)\n",
    "\n",
    "        ax[2].plot(cur.time,\n",
    "                   np.rad2deg(cur.theta[:, i]),\n",
    "                   label=label, alpha=.5)\n",
    "\n",
    "    for ax_i in ax:\n",
    "        ax_i.grid()\n",
    "    # ax[0].legend(loc='lower center', bbox_to_anchor=(.5, 1), title= 'Water Depth', ncol=5)\n",
    "\n",
    "\n",
    "    h, l = ax[0].get_legend_handles_labels()\n",
    "    ph = [ax[0].plot([],marker=\"\", ls=\"\")[0]]\n",
    "    handles = ph + h\n",
    "    labels = [\"Water Depth:\"] + l\n",
    "    leg = ax[0].legend(handles, labels, ncol=4, loc='lower center', bbox_to_anchor=(.5, 1))\n",
    "\n",
    "    for vpack in leg._legend_handle_box.get_children()[:1]:\n",
    "        for hpack in vpack.get_children():\n",
    "            hpack.get_children()[0].set_width(0)\n",
    "\n",
    "    ax[-1].xaxis.set_major_formatter(\n",
    "        mdates.ConciseDateFormatter(ax[1].xaxis.get_major_locator()))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "# time_profile(adcp_cur)\n",
    "# time_profile(statistic_cur)\n",
    "time_profile(con_cur)\n",
    "time_profile(con_cur6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aaa31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(a[0]) as f:\n",
    "    shapes = [f[i].shape for i in f]\n",
    "    i = np.argsort(np.array(shapes, dtype=object))\n",
    "\n",
    "    shape_last = None\n",
    "    items = np.array([i for i in f], dtype=object)[i]\n",
    "    for i in items:\n",
    "        if shape_last is None:\n",
    "            pass\n",
    "        elif shape_last != f[i].shape:\n",
    "            print('')\n",
    "        shape_last = f[i].shape\n",
    "\n",
    "        attrs = dict(f[i].attrs)\n",
    "    #     print(attrs)\n",
    "        if 'comment' in attrs:\n",
    "            comment = attrs['comment'].decode()\n",
    "        else:\n",
    "            comment = attrs['long_name'].decode()\n",
    "        print(f\"self.{i} = None  # [{attrs['units'].decode()}]: {comment} - shape:{f[i].shape}\")\n",
    "\n",
    "    print('\\n#######\\n')\n",
    "    shape_last = None\n",
    "    for i in items:\n",
    "        if shape_last is None:\n",
    "            pass\n",
    "        elif shape_last != f[i].shape:\n",
    "            print('')\n",
    "        shape_last = f[i].shape\n",
    "\n",
    "        attrs = dict(f[i].attrs)\n",
    "        if 'comment' in attrs:\n",
    "            comment = attrs['comment'].decode()\n",
    "        else:\n",
    "            comment = attrs['long_name'].decode()\n",
    "        print(f\"self.{i} = self.file['{i}']  # [{attrs['units'].decode()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_bins = 120.  # [seconds]\n",
    "dt = np.diff(adcp.current.timestamp[:2])\n",
    "\n",
    "con_cur = current_convolve(core_len_depth=3, core_len_t=int(step_bins/dt), speed_limits=15, adcp=adcp,\n",
    "                             #downsample=False\n",
    "                            )\n",
    "#con_cur = current_convolve(core_len_depth=5, core_len_t=int(step_bins/dt), speed_limits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve_smoothn(x, y, core_len, mode='valid', downsample=False, *args, **kwargs):\n",
    "    core = np.ones(len_core)\n",
    "    dtype_convert_x = None\n",
    "    if np.issubdtype(x.dtype, np.timedelta64) or np.issubdtype(x.dtype, np.datetime64):\n",
    "        dtype_convert_x = x.dtype\n",
    "        x = x.astype(float)\n",
    "        \n",
    "    x = np.convolve(x, core, mode=mode, *args, **kwargs)/np.sum(core)\n",
    "    y = np.convolve(y, core, mode=mode, *args, **kwargs)/np.sum(core)\n",
    "    \n",
    "    if downsample:\n",
    "        x=x[::len_core//2]\n",
    "        y=y[::len_core//2]\n",
    "    \n",
    "    \n",
    "    if dtype_convert_x is not None:\n",
    "        x = x.astype(dtype_convert_x)\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae01098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_bins = 2400.  # [seconds]\n",
    "dt = np.mean(np.diff(con_cur.timestamp))\n",
    "\n",
    "con_cur_down = current_convolve(core_len_depth=1, core_len_t=int(step_bins/dt), speed_limits=15, \n",
    "                             adcp={'timestamp': con_cur.timestamp,\n",
    "                                   'depth': con_cur.depth,\n",
    "                                   'velocity_east': con_cur.velocity_east,\n",
    "                                   'velocity_north': con_cur.velocity_north,\n",
    "                                   'velocity_up': con_cur.velocity_up},\n",
    "                             downsample=False\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02887952",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,6), nrows=2, squeeze=False, sharex=True)\n",
    "ax = ax.flatten()\n",
    "\n",
    "dt = strawb.tools.datetime2float(df_cur.time.to_numpy())\n",
    "len_core =int(1200.//np.mean(np.diff(dt)))\n",
    "core = np.ones(len_core)\n",
    "\n",
    "ax[0].plot(*convolve_downsample(df_cur.time.to_numpy(), \n",
    "                                df_cur.current_speed_calculated, \n",
    "                                len_core),\n",
    "           label='2660m Curentmeter', alpha=1, color='black')\n",
    "\n",
    "ax[1].plot(*strawb.tools.periodic2plot(*convolve_downsample(df_cur.time.to_numpy(),  \n",
    "                                               np.unwrap(df_cur.current_direction, period=360), \n",
    "                                               len_core),\n",
    "                           period=360), \n",
    "           label='Curentmeter', alpha=1, color='black')\n",
    "\n",
    "# ax[2].plot(*convolve_downsample(df.time.to_numpy(), \n",
    "#                                 df.current_velocity_up, \n",
    "#                                 len_core),\n",
    "#            label='2660m Curentmeter', alpha=1, color='black')\n",
    "\n",
    "\n",
    "# len_core = int(2400.//np.mean(np.diff(strawb.tools.datetime2float(con_cur_w.time))))\n",
    "# if len_core<2:\n",
    "#     len_core = 2\n",
    "# print(len_core)\n",
    "# for j, d_i in enumerate(np.linspace(2660, 2150, 3)):\n",
    "#     i = np.argmin(np.abs(con_cur_w.depth-d_i))\n",
    "#     label = f'{con_cur_w.depth[i]:.0f}m ADCP'\n",
    "#     color = plt.get_cmap('viridis_r')(i/con_cur_w.depth.shape[0])\n",
    "#     ax[0].plot(*convolve_downsample(con_cur_w.time, con_cur_w.velocity_abs[:, i], len_core),\n",
    "#                label=label, \n",
    "#                alpha=.5, #color=color, \n",
    "#                ls=['--', ':'][j%1], #color='gray'\n",
    "#               )\n",
    "    \n",
    "#     ax[1].plot(*strawb.tools.periodic2plot(*convolve_downsample(con_cur_w.time, \n",
    "#                                                    np.rad2deg(np.unwrap(con_cur_w.phi[:, i])), \n",
    "#                                                    len_core),\n",
    "#                               period=360), \n",
    "#                label=label, \n",
    "#                alpha=.5, #color=color, \n",
    "#                ls=['--', ':'][j%1], #color='gray'\n",
    "#               )\n",
    "    \n",
    "for j, d_i in enumerate(np.linspace(2660, 2150, 3)):\n",
    "# for j, d_i in enumerate(con_cur_down.depth[:-10:10]):\n",
    "    i = np.argmin(np.abs(con_cur_down.depth-d_i))\n",
    "    label = f'{con_cur_down.depth[i]:.0f}m ADCP'\n",
    "    color = plt.get_cmap('viridis')(i/con_cur_down.depth.shape[0])\n",
    "    color=None\n",
    "    ax[0].plot(con_cur_down.time, con_cur_down.velocity_abs[:, i],\n",
    "               label=label, #ls='--',\n",
    "               alpha=.75, color=color, ls=['--', ':'][j%1], #color='gray'\n",
    "              )\n",
    "    \n",
    "    ax[1].plot(*strawb.tools.periodic2plot(con_cur_down.time, \n",
    "                              np.rad2deg(np.unwrap(con_cur_down.phi[:, i])), \n",
    "                              period=360), \n",
    "               label=label, \n",
    "               alpha=.75, color=color, ls=['--', ':'][j%1], #color='gray'\n",
    "              )\n",
    "#     ax[2].plot(con_cur_down.time, con_cur_down.velocity_up[:, i],\n",
    "#                label=label, \n",
    "#                alpha=.75, color=color, ls=['--', ':'][j%1], #color='gray'\n",
    "#               )\n",
    "\n",
    "for axi in ax:\n",
    "    axi.grid()\n",
    "    \n",
    "ax[0].legend(ncol=5, loc='lower center', bbox_to_anchor=(.5, 1))\n",
    "# ax[0].legend(loc='upper left')\n",
    "ax[0].set_ylabel('Absolute Speed [m/s]')\n",
    "ax[1].set_ylabel('Phi [$^\\circ$]')\n",
    "# ax[2].set_ylabel('Speed Up [m/s]')\n",
    "ax[1].set_ylim(0, 360)\n",
    "ax[-1].set_xlim(con_cur.time[0], con_cur.time[-1])\n",
    "ax[1].set_yticks(np.arange(0, 361, 90))\n",
    "ax[-1].xaxis.set_major_formatter(\n",
    "    mdates.ConciseDateFormatter(ax[1].xaxis.get_major_locator()))\n",
    "\n",
    "ax[-1].autoscale(enable=True, axis='x', tight=True)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10951df",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cur_down.time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c990b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic2plot([0,1], [1,np.pi*2-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7779e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_convolve_vpt(current, core_len_depth, core_len_t, downsample=True):\n",
    "    \"\"\"speed_limits as m/s\"\"\"\n",
    "    core = np.ones((core_len_t, core_len_depth))\n",
    "\n",
    "    con_time = np.convolve(current.timestamp,\n",
    "                           np.ones(core_len_t)/core_len_t, \n",
    "                           mode='valid')\n",
    "\n",
    "    con_depth = np.convolve(current.depth,\n",
    "                            np.ones(core_len_depth)/core_len_depth, \n",
    "                            mode='valid')\n",
    "    con_velocity_abs = masked_convolve2d(current.velocity_abs, \n",
    "                                 core, mode='valid', norm=True, correct_missing=True)\n",
    "                            \n",
    "    x = np.unwrap(np_fill(current.phi.filled(np.nan), fill_dir=['f', 'b']), axis=0)\n",
    "    con_phi = masked_convolve2d(np.ma.array(x, mask=current.phi.mask), \n",
    "                                 core, mode='valid', norm=True, correct_missing=True)%(np.pi*2)\n",
    "    \n",
    "    x = np.unwrap(np_fill(current.theta.filled(np.nan), fill_dir=['f', 'b']),axis=0)\n",
    "    con_theta = masked_convolve2d(np.ma.array(x, mask=current.theta.mask), \n",
    "                                  core, mode='valid', norm=True, correct_missing=True)%np.pi\n",
    "    if downsample:\n",
    "        return Current(timestamp=con_time[::core_len_t//2],\n",
    "                          depth=con_depth,\n",
    "                          phi=con_phi[::core_len_t//2], \n",
    "                          theta=con_theta[::core_len_t//2], \n",
    "                          velocity_abs=con_velocity_abs[::core_len_t//2])\n",
    "    else:\n",
    "        return Current(timestamp=con_time,\n",
    "                          depth=con_depth,\n",
    "                          phi=con_phi, \n",
    "                          theta=con_theta, \n",
    "                          velocity_abs=con_velocity_abs)\n",
    "        \n",
    "    \n",
    "step_bins = 3600.  # [seconds]\n",
    "dt = np.diff(adcp.current.timestamp[:2])\n",
    "con_cur_0 = current_convolve(core_len_depth=1, \n",
    "                             core_len_t=int(step_bins/dt), speed_limits=5, \n",
    "                             #downsample=False\n",
    "                            )\n",
    "\n",
    "# step_bins = 480.  # [seconds]\n",
    "# dt = np.diff(con_cur_0.timestamp[:2])\n",
    "# con_cur_0_vpt = current_convolve_vpt(con_cur_0, core_len_depth=3, core_len_t=int(step_bins/dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_bins = 1200.  # [seconds]\n",
    "# dt = np.diff(con_cur_0.timestamp[:2])\n",
    "# con_cur_0_vpt = current_convolve_vpt(con_cur_0, \n",
    "#                                      core_len_t=int(step_bins/dt), \n",
    "#                                      downsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_bins = 3600.  # [seconds]\n",
    "dt = np.diff(con_cur_0.timestamp[:2])\n",
    "con_cur_0_vpt = current_convolve_vpt(con_cur_0, \n",
    "                                     core_len_t=int(step_bins/dt), \n",
    "                                     downsample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5), sharex=True, nrows=3)\n",
    "\n",
    "t = strawb.tools.datetime2float(df.time.to_numpy())\n",
    "len_core =int(1200.//np.mean(np.diff(t)))\n",
    "core = np.ones(len_core)\n",
    "ct = strawb.tools.asdatetime(np.convolve(t, core, mode='valid')[::len_core//2]/np.sum(core))\n",
    "cp = np.convolve(np.unwrap(np.deg2rad(df.current_direction)), \n",
    "                                       core, \n",
    "                                       mode='valid')[::len_core//2]/np.sum(core)\n",
    "\n",
    "cp = np.convolve(np.unwrap(np.deg2rad(df.current_direction)), \n",
    "                                       core, \n",
    "                                       mode='valid')[::len_core//2]/np.sum(core)\n",
    "cp %= (np.pi*2)\n",
    "\n",
    "ax[0].plot(con_cur_0.time, con_cur_0.velocity_abs[:,0])\n",
    "ax[0].plot(con_cur_0_vpt.time, con_cur_0_vpt.velocity_abs[:,0])\n",
    "ax[0].plot(ct,\n",
    "           np.convolve(df.current_speed_calculated, core, mode='valid')[::len_core//2]/np.sum(core),\n",
    "           label='Curentmeter 2660m', alpha=.75)\n",
    "\n",
    "ax[1].plot(*periodic2plot(con_cur_0.time, con_cur_0.phi[:,0]))\n",
    "ax[1].plot(*periodic2plot(con_cur_0_vpt.time, con_cur_0_vpt.phi[:,0]))\n",
    "ax[1].plot(*periodic2plot(ct, cp), label='Curentmeter', alpha=.75)\n",
    "\n",
    "ax[2].plot(con_cur_0.time, np.unwrap(np_fill(con_cur_0.phi[:,0], fill_dir=['f', 'b'], axis=0), axis=0))\n",
    "ax[2].plot(con_cur_0_vpt.time, np.unwrap(np_fill(con_cur_0_vpt.phi[:,0], fill_dir=['f', 'b'])))\n",
    "ax[2].plot(ct, np.unwrap(cp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b945a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5), sharex=True, nrows=3)\n",
    "\n",
    "t = strawb.tools.datetime2float(df.time.to_numpy())\n",
    "len_core =int(1200.//np.mean(np.diff(t)))\n",
    "core = np.ones(len_core)\n",
    "ct = strawb.tools.asdatetime(np.convolve(t, core, mode='valid')[::len_core//2]/np.sum(core))\n",
    "cp = np.convolve(np.unwrap(np.deg2rad(df.current_direction)), \n",
    "                                       core, \n",
    "                                       mode='valid')[::len_core//2]/np.sum(core)\n",
    "\n",
    "cp = np.convolve(np.unwrap(np.deg2rad(df.current_direction)), \n",
    "                                       core, \n",
    "                                       mode='valid')[::len_core//2]/np.sum(core)\n",
    "cp %= (np.pi*2)\n",
    "\n",
    "ax[0].plot(con_cur_0.time, con_cur_0.velocity_abs[:,0])\n",
    "# ax[0].plot(con_cur_0_vpt.time, con_cur_0_vpt.velocity_abs[:,0])\n",
    "ax[0].plot(ct,\n",
    "           np.convolve(df.current_speed_calculated, core, mode='valid')[::len_core//2]/np.sum(core),\n",
    "           label='Curentmeter 2660m', alpha=1)\n",
    "\n",
    "ax[1].plot(con_cur_0.time, con_cur_0.vel_east[:,0])\n",
    "# ax[1].plot(con_cur_0_vpt.time, con_cur_0_vpt.vel_east[:,0])\n",
    "ax[1].plot(ct,\n",
    "           np.convolve(df.current_velocity_east, core, mode='valid')[::len_core//2]/np.sum(core),\n",
    "           label='Curentmeter 2660m', alpha=1)\n",
    "for i in range(1, 10):\n",
    "    ax[1].plot(con_cur_0.time, con_cur_0.vel_east[:,i])\n",
    "\n",
    "ax[2].plot(con_cur_0.time, con_cur_0.vel_north[:,0])\n",
    "# ax[2].plot(con_cur_0_vpt.time, con_cur_0_vpt.vel_north[:,0])\n",
    "ax[2].plot(ct,\n",
    "           np.convolve(df.current_velocity_north, core, mode='valid')[::len_core//2]/np.sum(core),\n",
    "           label='Curentmeter 2660m', alpha=1)\n",
    "for i in range(1, 10):\n",
    "    ax[2].plot(con_cur_0.time, con_cur_0.vel_north[:,i])\n",
    "\n",
    "ax[1].axhline(0, color='k')\n",
    "ax[2].axhline(0, color='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unwrap(np_fill(con_cur_0.phi[100:120][:,3], fill_dir=['f', 'b'], axis=0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8dda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_left_2d(a):\n",
    "    idx = np.where(~np.isnan(a), np.arange(a.shape[-1]), 0)\n",
    "    print(idx)\n",
    "    np.maximum.accumulate(idx, axis=-1, out=idx)\n",
    "    print(idx)\n",
    "    return a[np.arange(idx.shape[0])[:,None], idx]\n",
    "\n",
    "fill_left_2d(aa.filled(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e536462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _np_fill_(arr, axis=-1, fill_dir='f'):\n",
    "    \"\"\"Base function for np_fill, np_ffill, np_bfill.\"\"\"\n",
    "    if axis < 0:\n",
    "        axis = len(arr.shape) + axis\n",
    "    \n",
    "    if fill_dir.lower() in ['b', 'backward']:\n",
    "        dir_change = tuple([*[slice(None)]*axis, slice(None, None, -1)])\n",
    "        return np_ffill(arr[dir_change])[dir_change]\n",
    "    elif fill_dir.lower() not in ['f', 'forward']:\n",
    "        raise KeyError(f\"fill_dir must be one of: 'b', 'backward', 'f', 'forward'. Got: {fill_dir}\")\n",
    "    \n",
    "    idx_shape = tuple([slice(None)] + [np.newaxis] * (len(arr.shape) - axis - 1))\n",
    "    idx = np.where(~np.isnan(arr), np.arange(arr.shape[axis])[idx_shape], 0)\n",
    "    np.maximum.accumulate(idx, axis=axis, out=idx)\n",
    "    slc = [np.arange(k)[tuple([slice(None) if dim==i else np.newaxis\n",
    "        for dim in range(len(arr.shape))])]\n",
    "        for i, k in enumerate(arr.shape)]\n",
    "    slc[axis] = idx\n",
    "    return arr[tuple(slc)]\n",
    "\n",
    "def np_fill(arr, axis=-1, fill_dir='f'):\n",
    "    \"\"\"General fill function which supports multiple filling steps. I.e.: \n",
    "    fill_dir=['f', 'b'] or fill_dir=['b', 'f']\"\"\"\n",
    "    if isinstance(fill_dir, (tuple, list, np.ndarray)):\n",
    "        for i in fill_dir:\n",
    "            arr = _np_fill_(arr, axis=axis, fill_dir=i)\n",
    "    else:\n",
    "        arr = _np_fill_(arr, axis=axis, fill_dir=fill_dir)\n",
    "    return arr\n",
    "\n",
    "def np_ffill(arr, axis=-1):\n",
    "    return np_fill(arr, axis=axis, fill_dir='forward')\n",
    "\n",
    "def np_bfill(arr, axis=-1):\n",
    "    return np_fill(arr, axis=axis, fill_dir='backward')\n",
    "\n",
    "np.unwrap(np_fill(aa.filled(np.nan), fill_dir=['f', 'b']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
