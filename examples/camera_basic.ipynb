{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import strawb\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.ndimage\n",
    "import random\n",
    "import scipy.spatial\n",
    "import cv2\n",
    "import scipy.interpolate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files from the ONC server\n",
    "Be careful, depending on the amount of data this can take a while!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DB\n",
    "db = strawb.SyncDBHandler(file_name='Default')  # loads the db\n",
    "db.load_onc_db_update(save_db=True)  # update the DB, could take some time if it has to load info. from ONC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some info from the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.dataframe.columns)\n",
    "\n",
    "### these are the available device codes\n",
    "print(db.dataframe.deviceCode.unique())\n",
    "\n",
    "### different measurement types for PMTSPEC and LIDAR, \n",
    "# works only if hdf5 attributes are imported from files on disc\n",
    "#print(db.dataframe.measurement_type.unique())\n",
    "\n",
    "### these are the parts of each module that produce data\n",
    "print(db.dataframe.dataProductCode.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select (a) file(s) of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (db.dataframe.deviceCode == 'TUMPMTSPECTROMETER001') # that's the pmtspec module\n",
    "mask &= (db.dataframe.dataProductCode =='MSSCD') # that's the camera data of the pmtspec module\n",
    "\n",
    "## select the file for the biolumi event with a window of +- 5 hours\n",
    "# timestamp = pd.Timestamp('2022-03-04T23:44:09', tz='UTC')  # gain = 30\n",
    "timestamp = pd.Timestamp('2021-09-04T23:44:09', tz='UTC')  # gain = 50\n",
    "mask &= db.dataframe.dateFrom >= timestamp - pd.Timedelta('5H')  # - 5 hours\n",
    "mask &= db.dataframe.dateFrom <= timestamp + pd.Timedelta('5H')  # - 5 hours\n",
    "\n",
    "### selected one file from the DB (it's the same as the file we selected above by hand)\n",
    "db.dataframe[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the missing files which aren't synced so far from `db.dataframe[mask]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not db.dataframe.synced[mask].all():\n",
    "    db.update_db_and_load_files(\n",
    "        db.dataframe[mask],\n",
    "        output=True,  # print output to console\n",
    "        download=True,  # download the files\n",
    "        save_db=True,\n",
    "    )  # update the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the file to the Camera Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the Camera file(s) -> dataProductCode == 'MSSCD'\n",
    "item = db.dataframe[mask & (db.dataframe.dataProductCode =='MSSCD')]\n",
    "\n",
    "try: # if the pmtspec file is still open\n",
    "    camera.file_handler.close()\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "# generate a virtual hdf5 to combine the datasets if there are multiple files selected\n",
    "if len(item) > 1:\n",
    "    vhdf5 = strawb.VirtualHDF5('MSSCD_event_view.hdf5', item.fullPath.to_list())  \n",
    "    file_name = vhdf5.file_name\n",
    "else:\n",
    "    file_name = item.fullPath[0]\n",
    "\n",
    "# create an instance of the Camera\n",
    "camera = strawb.Camera(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Module: {camera.file_handler.module}')\n",
    "print(f'Number of Frames: {camera.file_handler.exposure_time.shape[0]}')\n",
    "print(f'Date: {np.min(camera.file_handler.time.asdatetime()[:])} - {np.max(camera.file_handler.time.asdatetime()[:])}')\n",
    "print(f'Exposure Times [s]: {np.unique(camera.file_handler.exposure_time)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask images to export (here only one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may take some time, if the time period isn't changed, index 170 is the bright event\n",
    "if False:\n",
    "    # mask over a threshold + mask invalid frames + mask no lucifer enabled\n",
    "    mask = (camera.images.integrated_minus_dark > 1e6) & camera.images.invalid_mask\n",
    "\n",
    "    index = np.argsort(camera.images.integrated_minus_dark)  # sort by charge [min,...,max]\n",
    "    index = index[mask[index]]  # remove invalid items  & cam_module.invalid_mask\n",
    "    index = index[::-1]  # revers the order\n",
    "else:\n",
    "    index = [170]\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show one image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "rgb = camera.images.load_rgb(index=index)\n",
    "plt.imshow(rgb[0,:,:]/2**16)  # rgb[frame, row, col], /255 to get 0->1\n",
    "#plt.savefig(\"figures/biolumi_demo.pdf\", backend=\"pdf\")\n",
    "#plt.savefig(\"figures/biolumi_demo.png\", dpi=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to access the raw data (numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The raw pixel values are NOT loaded by default to the module to save RAM.\n",
    "# They can be accessed directly from the file with the index, index = None (default) to loads all images\n",
    "a = camera.file_handler.raw[[1,3]]  # direct h5py access, allows only sorted (non-duplicate) index access.\n",
    "print(a.shape)\n",
    "\n",
    "a = camera.file_handler.raw.getunsorted([1,3])  # STRAWb helper to access it unsorted (and duplicate) by index\n",
    "print(a.shape)\n",
    "\n",
    "raw = camera.file_handler.raw[:]  # get all images\n",
    "# returns array of images on default, even if only one element is accessed\n",
    "print(f'raw shape: {raw.shape}') # shape of images, n_pic x 2D shape of picture\n",
    "print(f'raw picture: {raw[0].shape}') # 2D shape of picture\n",
    "\n",
    "raw = camera.images.cut2effective_pixel_arr(raw)\n",
    "print(f'shape reduced to effective pixel: {raw[0].shape}') # 2D shape of picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have the raw-data with valid pixel range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram for some pixel\n",
    "bins = np.linspace(0, 2**16, 1000)\n",
    "plt.figure()\n",
    "for i in range(1,10,2):\n",
    "    # pixel are selected with: 1200-50*i & 900-50*i\n",
    "    plt.hist(raw[:, 1200-50*i, 900-50*i], bins=bins, histtype='step')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load or generate ImageClusterDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(strawb.sync_db_handler.ImageClusterDB._default_file_name_):\n",
    "    image_cluster_db = strawb.sync_db_handler.ImageClusterDB(load_db=False)\n",
    "    image_cluster_db.dataframe = camera.find_cluster.df_all()\n",
    "    image_cluster_db.save_db()\n",
    "else:\n",
    "    image_cluster_db = strawb.sync_db_handler.ImageClusterDB()\n",
    "    \n",
    "image_cluster_db.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a DataFrame without label 0 and add charge, charge_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = image_cluster_db.dataframe[image_cluster_db.dataframe.label!=0]\n",
    "\n",
    "df = df_2[df_2.label!=0]\n",
    "df.loc[:,'charge'] = (df.charge_with_noise - df.noise).to_numpy()\n",
    "df.loc[:,'charge_log'] = np.log(df.charge_with_noise - df.noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hist of cluster sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = df.n_pixel\n",
    "# get similar size bins in log space\n",
    "bins = np.unique(np.geomspace(parameter.min(), parameter.max()*1.1, 100).astype(int))\n",
    "\n",
    "# # linear bins\n",
    "# bins = np.arange(int(df.n_pixel.min()), int(df.n_pixel.max()*1.1), 1)\n",
    "\n",
    "count, edges = np.histogram(parameter, bins=bins,)\n",
    "\n",
    "plt.figure()\n",
    "StepPatch = plt.stairs(count, edges, fill=True)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Cluster Size [pixel]')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid()\n",
    "StepPatch.zorder=5\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images with detected cluster bigger than a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pictures filtered by a parameter and a limit\n",
    "\n",
    "# limit = 2e5\n",
    "# parameter = 'charge'\n",
    "\n",
    "limit = 20  # limit from plot\n",
    "parameter = 'n_pixel'\n",
    "\n",
    "file_times = camera.file_handler.time.asdatetime()[:]\n",
    "indexes = [np.argwhere(file_times==i )[0,0] for i in df[df[parameter]  > limit].time]\n",
    "indexes = np.unique(indexes)\n",
    "\n",
    "index_df_dict = {i: df[df.time==file_times[i]] for i in indexes}\n",
    "index_df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df_i in index_df_dict.items():\n",
    "    plt.figure()\n",
    "    rgb = camera.images.load_rgb(index=i)\n",
    "    plt.imshow(rgb[0,:,:]/2**16)  # rgb[frame, row, col], /255 to get 0->1\n",
    "    for j, df_j in df_i[df_i[parameter] > limit].iterrows():\n",
    "        plt.plot(strawb.tools.connect_polar(df_j.box_corners_y),\n",
    "                 strawb.tools.connect_polar(df_j.box_corners_x),\n",
    "                 color='w', alpha=.5, label='Min. Box'\n",
    "                 )\n",
    "        plt.plot(*df_j.center_of_mass[::-1],\n",
    "                 'o', color='w', alpha=.75,\n",
    "                 label='Center of Mass',\n",
    "                 )\n",
    "        plt.plot(*df_j.center_of_pix[::-1],\n",
    "                 'x', color='w', alpha=.75,\n",
    "                 label='Center of Pix',\n",
    "                 )\n",
    "        plt.plot(*df_j.box_center_x_y[::-1],\n",
    "                 '>', color='w', alpha=.75,\n",
    "                 label='Center of Box',\n",
    "                 )\n",
    "        \n",
    "    # don't show double labels\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a plotting function for fast df insights\n",
    "def stair_scatter(df, color=None, size=1, alpha=.1, ax=None, columns=None, log=True, **kwargs):\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    rows = columns[1:] \n",
    "    cols = columns[:-1]\n",
    "    \n",
    "    # ax[row, col]\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(nrows=len(rows), \n",
    "                       ncols=len(cols), \n",
    "                       sharex='col', sharey='row', \n",
    "                       squeeze=False, \n",
    "                       **kwargs)\n",
    "        \n",
    "        for j, cols_j in enumerate(cols):\n",
    "            if log:\n",
    "                ax[-1,j].set_xscale('log')\n",
    "            ax[-1,j].set_xlabel(cols_j.replace('_',' '), rotation=0) #rotation=70\n",
    "        for i, row_i in enumerate(rows):\n",
    "            ax[i, 0].set_ylabel(row_i.replace('_',' '), rotation=90) #rotation=30)\n",
    "            if log:\n",
    "                ax[i, 0].set_yscale('log')\n",
    "        for i, row_i in enumerate(rows):\n",
    "            for j, cols_j in enumerate(cols):\n",
    "                if j<=i:\n",
    "                    ax[i, j].grid()\n",
    "                else:\n",
    "                    ax[i,j].axis('off')\n",
    "\n",
    "    for i, row_i in enumerate(rows):\n",
    "        for j, cols_j in enumerate(cols):\n",
    "            if j<=i:#cols_j != row_i:\n",
    "    #             ax[i, j].text(0.5, 0.5, f'x:{cols_j}\\ny:{row_i}', \n",
    "    #                           horizontalalignment='center',\n",
    "    #                           verticalalignment='center', \n",
    "    #                           transform=ax[i, j].transAxes)\n",
    "                ax[i, j].scatter(df[cols_j], df[row_i], s=size, c=color, alpha=alpha)\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "\n",
    "# define a container for a ML-Model\n",
    "class ClusterModel:\n",
    "    def __init__(self, model, df, columns, n=1000, name='', *kwargs):\n",
    "        self.name = name\n",
    "        # define the model\n",
    "        self.model = model\n",
    "\n",
    "        # fit the model\n",
    "        X = sklearn.preprocessing.StandardScaler().fit_transform(df[columns].to_numpy())\n",
    "        random_int = np.random.randint(0, len(X), n)  # select n out of X\n",
    "        self.model.fit(X[random_int])\n",
    "\n",
    "        # cal the all peaks\n",
    "        self.labels = self.model.predict(X)\n",
    "        \n",
    "        # sort the labels by count\n",
    "        clusters, clusters_counts = np.unique(self.labels, return_counts=True)\n",
    "        self.clusters = clusters[np.argsort(-clusters_counts)]\n",
    "        self.clusters_counts = clusters_counts[np.argsort(-clusters_counts)]\n",
    "\n",
    "        self.labels_cs = np.zeros_like(self.labels, dtype=int) - 1\n",
    "        for i, c_i in enumerate(self.clusters):\n",
    "            self.labels_cs[self.labels == c_i] = i\n",
    "            \n",
    "        self.df = df\n",
    "\n",
    "    def plot_level_hist(self, ax=None, norm_x=True, norm_y=True):\n",
    "        if ax is None:\n",
    "            plt.figure()\n",
    "            ax = plt.gca()\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_xlabel('Classification Typ')\n",
    "            ax.set_ylabel('Count')\n",
    "            \n",
    "        if norm_x:\n",
    "            class_typ = np.linspace(0, 1,len(self.clusters_counts))\n",
    "        else:\n",
    "            class_typ = np.arange(0,len(self.clusters_counts)+1, 1)\n",
    "            \n",
    "        if norm_y:\n",
    "            norm_y_s = self.clusters_counts.max()\n",
    "        else:\n",
    "            norm_y_s = 1\n",
    "            \n",
    "        ax.plot(class_typ, self.clusters_counts/norm_y_s, label=f'{self.name.replace(\"_\",\"-\")} {len(self.clusters)}')\n",
    "#         plt.hist(self.labels_cs, bins=len(self.clusters_counts))\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "columns = ['n_pixel', 'charge']\n",
    "columns_log = ['n_pixel', 'charge_log']\n",
    "\n",
    "n = 20000\n",
    "n_clusters = 4\n",
    "k_means_4 = ClusterModel(sklearn.cluster.KMeans(n_clusters=n_clusters), df, columns, name='KMeans_4', n=n)\n",
    "# k_means_4_log = ClusterModel(sklearn.cluster.KMeans(n_clusters=n_clusters), df, columns_log, name='KMeans_4_log', n=n)\n",
    "\n",
    "n_clusters = 2\n",
    "k_means_2 = ClusterModel(sklearn.cluster.KMeans(n_clusters=n_clusters), df, columns, name='KMeans_2', n=n)\n",
    "# k_means_2_log = ClusterModel(sklearn.cluster.KMeans(n_clusters=n_clusters), df, columns_log, name='KMeans_2_log', n=n)\n",
    "\n",
    "# n = 2000\n",
    "# aff_pro = ClusterModel(sklearn.cluster.AffinityPropagation(damping=.7), df, columns, name='AffinityPropagation')\n",
    "# aff_pro_log = ClusterModel(sklearn.cluster.AffinityPropagation(damping=.7), df, columns_log, name='AffinityPropagation_log')\n",
    "\n",
    "# n = 20000\n",
    "# mean_shift = ClusterModel(sklearn.cluster.MeanShift(n_jobs=-1), df, columns, name='MeanShift')\n",
    "# mean_shift_log = ClusterModel(sklearn.cluster.MeanShift(n_jobs=-1), df, columns_log, name='MeanShift_log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [k_means_2,#k_means_2_log,\n",
    "              k_means_4, #k_means_4_log,\n",
    "#               aff_pro, aff_pro_log,\n",
    "#               mean_shift, mean_shift_log\n",
    "             ]\n",
    "\n",
    "\n",
    "ax = None\n",
    "for i, alg_i in enumerate(algorithms):\n",
    "    ax = alg_i.plot_level_hist(ax)\n",
    "    \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [#'plateau_sizes', 'left_thresholds', 'right_thresholds'\n",
    "           'n_pixel', 'charge', #'charge_with_noise', 'noise', \n",
    "           'mean_absolute_deviation_per_pixel', 'mean_deviation_per_pixel_in_sigma']\n",
    "\n",
    "alg_i=k_means_4\n",
    "stair_scatter(alg_i.df, \n",
    "              color=alg_i.labels_cs,\n",
    "              size=1+10*alg_i.labels_cs,\n",
    "              columns=columns,\n",
    "              alpha=1,\n",
    "              figsize=(9,9))\n",
    "    \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_i=k_means_4\n",
    "# Sort the labels by counts\n",
    "labels, counts = np.unique(alg_i.labels_cs, return_counts=True)\n",
    "\n",
    "# Take half of the labels and show cluster\n",
    "df[alg_i.labels_cs>labels[np.argsort(counts)][len(labels)//2]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3dbe8948e6ba6f7b500cbad156adccce2d4d02afc71091580e98904bda0c5804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
