{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "import strawb\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load files from the ONC server\n",
    "Be careful, depending on the amount of data this can take a while!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DB\n",
    "db = strawb.SyncDBHandler(file_name='Default')  # loads the db\n",
    "db.load_onc_db_update(save_db=True)  # update the DB, could take some time if it has to load info. from ONC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some info from the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.dataframe.columns)\n",
    "\n",
    "### these are the available device codes\n",
    "print(db.dataframe.deviceCode.unique())\n",
    "\n",
    "### different measurement types for PMTSPEC and LIDAR, \n",
    "# works only if hdf5 attributes are imported from files on disc\n",
    "#print(db.dataframe.measurement_type.unique())\n",
    "\n",
    "### these are the parts of each module that produce data\n",
    "print(db.dataframe.dataProductCode.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select (a) file(s) of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (db.dataframe.deviceCode == 'TUMPMTSPECTROMETER001') # that's the pmtspec module\n",
    "mask &= (db.dataframe.dataProductCode =='MSSCD') # that's the camera data of the pmtspec module\n",
    "\n",
    "## select the file for the biolumi event with a window of +- 5 hours\n",
    "# timestamp = pd.Timestamp('2022-03-04T23:44:09', tz='UTC')  # gain = 30\n",
    "timestamp = pandas.Timestamp('2021-09-04T23:44:09', tz='UTC')  # gain = 50\n",
    "# mask &= db.dataframe.dateFrom >= timestamp - pd.Timedelta('5H')  # - 5 hours\n",
    "# mask &= db.dataframe.dateFrom <= timestamp + pd.Timedelta('5H')  # - 5 hours\n",
    "\n",
    "mask_time = strawb.tools.pd_timestamp_mask_between(\n",
    "    db.dataframe.dateFrom,  \n",
    "    db.dataframe.dateTo, \n",
    "    timestamp - pandas.Timedelta('4H'),\n",
    "    timestamp + pandas.Timedelta('3H'),\n",
    "    )\n",
    "\n",
    "\n",
    "# # LED TUMPMTSPECTROMETER001 run\n",
    "# timestamp = pandas.Timestamp('2022-08-02T09:30:00', tz='UTC')  # LED images\n",
    "\n",
    "# mask_time = strawb.tools.pd_timestamp_mask_between(\n",
    "#     db.dataframe.dateFrom,  \n",
    "#     db.dataframe.dateTo, \n",
    "#     timestamp - pandas.Timedelta('1H'),\n",
    "#     timestamp + pandas.Timedelta('2H'),\n",
    "#     )\n",
    "\n",
    "mask &= mask_time\n",
    "### selected one file from the DB (it's the same as the file we selected above by hand)\n",
    "db.dataframe[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the missing files which aren't synced so far from `db.dataframe[mask]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not db.dataframe.synced[mask].all():\n",
    "    db.update_db_and_load_files(\n",
    "        db.dataframe[mask],\n",
    "        output=True,  # print output to console\n",
    "        download=True,  # download the files\n",
    "        save_db=True,\n",
    "    )  # update the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the file to the Camera Module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the Camera file(s) -> dataProductCode == 'MSSCD'\n",
    "item = db.dataframe[mask & (db.dataframe.dataProductCode =='MSSCD')]\n",
    "# item = pandas.DataFrame({'fullPath': glob.glob(os.path.expanduser('~/Downloads/*CAMERA.hdf5'))})\n",
    "\n",
    "try: # if the pmtspec file is still open\n",
    "    camera.file_handler.close()\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "# generate a virtual hdf5 to combine the datasets if there are multiple files selected\n",
    "if len(item) > 1:\n",
    "    vhdf5 = strawb.VirtualHDF5('MSSCD_event_view.hdf5', item.fullPath.to_list())  \n",
    "    file_name = vhdf5.file_name\n",
    "else:\n",
    "    file_name = item.fullPath[0]\n",
    "\n",
    "# create an instance of the Camera\n",
    "camera = strawb.Camera(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Module: {camera.file_handler.module}')\n",
    "print(f'Number of Frames: {camera.file_handler.exposure_time.shape[0]}')\n",
    "print(f'Date: {np.min(camera.file_handler.time.asdatetime()[:])} - {np.max(camera.file_handler.time.asdatetime()[:])}')\n",
    "print(f'Exposure Times [s]: {np.unique(camera.file_handler.exposure_time)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask images to export (here only one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# may take some time, if the time period isn't changed, index 170 is the bright event\n",
    "if False:\n",
    "    # mask over a threshold + mask invalid frames + mask no lucifer enabled\n",
    "    mask = (camera.images.integrated_minus_dark > 1e6) & camera.images.valid_mask\n",
    "\n",
    "    index = np.argsort(camera.images.integrated_minus_dark)  # sort by charge [min,...,max]\n",
    "    index = index[mask[index]]  # remove invalid items  & cam_module.invalid_mask\n",
    "    index = index[::-1]  # revers the order\n",
    "else:\n",
    "    index = [170]\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = camera.images.load_raw(index=index)[0]\n",
    "rgb = camera.images.frame_raw_to_rgb(raw/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "raw = camera.images.load_raw(index=index)[0]\n",
    "plt.imshow(camera.images.frame_raw_to_rgb(raw/2)[:,:]/2**16)  # rgb[frame, row, col], /255 to get 0->1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show one image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(camera.images.load_rgb(index=index)[0,:,:]/2**16)  # rgb[frame, row, col], /255 to get 0->1\n",
    "#plt.savefig(\"figures/biolumi_demo.pdf\", backend=\"pdf\")\n",
    "#plt.savefig(\"figures/biolumi_demo.png\", dpi=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show RAW Data, mosaic and demosaicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "def invert_colors(x, gamma=1, axis=-1):\n",
    "    x = x.astype(np.float64)\n",
    "    \n",
    "    if axis<0:\n",
    "        axis = len(x.shape) + axis\n",
    "        \n",
    "    slicer = [slice(None)]*axis\n",
    "    \n",
    "    # cal. color angles\n",
    "    brightness = np.sqrt(np.sum(x[(*slicer, slice(0, 3))] ** 2, axis=axis))\n",
    "    phi = np.arctan2(x[(*slicer, 1)],\n",
    "                     x[(*slicer, 0)])\n",
    "    \n",
    "    mask_0 = brightness!=0\n",
    "    theta = np.zeros_like(phi)\n",
    "    theta[mask_0] = np.arccos(x[(*slicer, 2)][mask_0] / brightness[mask_0])\n",
    "    \n",
    "    # get the inverse of (0,0,0) -> (1,1,1)\n",
    "    phi[~mask_0] = np.pi/4.\n",
    "    theta[~mask_0] = 0.9553166181245092  # the angle for (1,1,1)\n",
    "\n",
    "    # invert length aka. brightness\n",
    "    brightness = np.sqrt(3) - brightness\n",
    "    brightness = brightness**gamma\n",
    "\n",
    "    # back to colors\n",
    "    x[(*slicer, 0)] = brightness * np.sin(theta) * np.cos(phi)\n",
    "    x[(*slicer, 1)] = brightness * np.sin(theta) * np.sin(phi)\n",
    "    x[(*slicer, 2)] = brightness * np.cos(theta)\n",
    "    x[(*slicer, slice(None, 3))] /= x[(*slicer, slice(None, 3))].max()\n",
    "    return x #.astype(dtype)\n",
    "\n",
    "def cmap_cut(name, vmax=1, invert=True):\n",
    "    \"\"\"Cut the upper part of the cmap defined with vmax. vmax=1 will not cut the cmap.\n",
    "    vmax=.5 will cut the upper half.\"\"\"\n",
    "    cmap = plt.get_cmap(name)\n",
    "    x = np.array([cmap(x_i) for x_i in np.linspace(0, 1, cmap.N)])\n",
    "    if invert:\n",
    "        x = invert_colors(x)\n",
    "    cmap_new = colors.ListedColormap(x[:int(cmap.N / vmax)], f'new_{cmap.name}')\n",
    "    return cmap_new\n",
    "\n",
    "# set up data\n",
    "raw = camera.file_handler.raw[index][0]\n",
    "# cut the margins from the array\n",
    "raw = camera.images.cut2effective_pixel(raw)\n",
    "raw_i = raw/raw.max()\n",
    "\n",
    "raw_ma = np.ma.array(raw_i).astype(np.float64)\n",
    "\n",
    "\n",
    "# Plot parameter\n",
    "vmax = 1.1\n",
    "gray = False\n",
    "\n",
    "figsize = np.array([9,3])\n",
    "\n",
    "# PLOT\n",
    "fig, ax = plt.subplots(ncols=2,nrows=1, figsize=figsize, squeeze=False, sharex='row', sharey='row', \n",
    "                       gridspec_kw=dict(width_ratios=[1.05, 1.15, 1.00][1:]))\n",
    "ax = ax.flatten()\n",
    "\n",
    "i_ax = 0\n",
    "# # FIRST plot\n",
    "# ax[i_ax].set_title('RAW - Grayscale')\n",
    "# cs = ax[i_ax].imshow(raw_i, cmap=cmap_cut('gray_r'))\n",
    "\n",
    "# # set colobar size\n",
    "# divider = make_axes_locatable(ax[i_ax])\n",
    "# cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "# plt.colorbar(cs, cax=cax)\n",
    "# i_ax += 1\n",
    "\n",
    "# SECOND plot\n",
    "ax[i_ax].set_title('RAW - RGB mosaic')\n",
    "\n",
    "# to set colobar size\n",
    "divider = make_axes_locatable(ax[1])\n",
    "\n",
    "for color_i in ['Greens', 'Blues', 'Reds']:\n",
    "    # rgb_mask needs EffMargins to adopted if margins are cut from data\n",
    "    raw_ma.mask=~camera.images.get_raw_rgb_mask(\n",
    "        raw_i.shape, \n",
    "        color_i, \n",
    "        eff_margin=camera.file_handler.EffMargins[:])\n",
    "    cs = ax[i_ax].imshow(\n",
    "        raw_ma.filled(np.nan), \n",
    "        vmin=0, vmax=1,\n",
    "        cmap='gray_r' if gray else cmap_cut(color_i, \n",
    "                                            vmax=1 if color_i=='Blue' else vmax), \n",
    "        interpolation='nearest')\n",
    "    \n",
    "    # add colobar to divider\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar= plt.colorbar(cs, cax=cax)\n",
    "    if color_i != 'Reds':  # remove ticks for green and blue\n",
    "        cbar.set_ticks([])\n",
    "i_ax += 1\n",
    "\n",
    "\n",
    "ax[i_ax].set_title('Image - demosaiced')\n",
    "rgb = camera.images.load_rgb(index=index, subtract_dark=False)\n",
    "ax[i_ax].imshow((rgb[0]/2**16))  # rgb[frame, row, col], /255 to get 0->1\n",
    "\n",
    "# ax[-1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('image_demosaic.pdf')\n",
    "\n",
    "# Less zoom version\n",
    "ax[-1].set_xlim(20, 600)\n",
    "ax[-1].set_ylim(250, 700)\n",
    "ax[-1].invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('image_demosaic_zoom1.pdf')\n",
    "\n",
    "# Zoom version\n",
    "scale = .3\n",
    "ax[-1].set_xlim(295, 300 + int((418-295)*scale))\n",
    "ax[-1].set_ylim(450, 450 + int((550-450)*scale/.8))\n",
    "ax[-1].invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('image_demosaic_zoom2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to access the raw data (numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The raw pixel values are NOT loaded by default to the module to save RAM.\n",
    "# They can be accessed directly from the file with the index, index = None (default) to loads all images\n",
    "a = camera.file_handler.raw[[1,3]]  # direct h5py access, allows only sorted (non-duplicate) index access.\n",
    "print(a.shape)\n",
    "\n",
    "a = camera.file_handler.raw.getunsorted([1,3])  # STRAWb helper to access it unsorted (and duplicate) by index\n",
    "print(a.shape)\n",
    "\n",
    "raw = camera.file_handler.raw[:]  # get all images\n",
    "# returns array of images on default, even if only one element is accessed\n",
    "print(f'raw shape: {raw.shape}') # shape of images, n_pic x 2D shape of picture\n",
    "print(f'raw picture: {raw[0].shape}') # 2D shape of picture\n",
    "\n",
    "raw = camera.images.cut2effective_pixel(raw)\n",
    "print(f'shape reduced to effective pixel: {raw[0].shape}') # 2D shape of picture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we have the raw-data with valid pixel range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram for some pixel\n",
    "bins = np.arange(0, 2**16, 1000)\n",
    "plt.figure()\n",
    "for i in range(1,10,2):\n",
    "    # pixel are selected with: 1200-50*i & 900-50*i\n",
    "    plt.hist(raw[:, 1200-50*i, 900-50*i], bins=bins, histtype='step')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load or generate ImageClusterDB\n",
    "Detecting the clusters and calculating their parameters **takes some time, ~5-10min**. Therefore, generate a file name, if it exists, load the DB from there or generate it and store it for a faster access the next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start,  t_end = pandas.to_datetime(camera.file_handler.time.asdatetime()[[0,-1]])\n",
    "\n",
    "# formatter\n",
    "str_formatter = '{dev_code}_{t_start:%Y%m%dT%H%M%S}_{t_end:%Y%m%dT%H%M%S}_test_imagecluster.gz'\n",
    "formatter_dict = {'dev_code': camera.config.device_code,\n",
    "                 't_start': t_start,\n",
    "                 't_end': t_end}\n",
    "\n",
    "file_name = str_formatter.format(**formatter_dict)\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_update = False\n",
    "\n",
    "image_cluster_db = strawb.sync_db_handler.ImageClusterDB(file_name=file_name, \n",
    "                                                         device_code=camera.config.device_code,\n",
    "                                                         load_db=False)\n",
    "if force_update or not os.path.exists(file_name):\n",
    "    image_cluster_db.dataframe = camera.find_cluster.df_all()\n",
    "    image_cluster_db.save_db()\n",
    "else:\n",
    "    image_cluster_db.load_db()\n",
    "    \n",
    "# image_cluster_db = strawb.sync_db_handler.ImageClusterDB(load_db=False)\n",
    "# image_cluster_db.dataframe = camera.find_cluster.df_all()\n",
    "    \n",
    "image_cluster_db.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a DataFrame without label 0 and add charge, charge_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = image_cluster_db.dataframe[image_cluster_db.dataframe.label!=0]\n",
    "\n",
    "df = df[df.label!=0]\n",
    "df.loc[:,'charge'] = (df.charge_with_noise - df.noise).to_numpy()\n",
    "df.loc[:,'charge_log'] = np.log(df.charge_with_noise - df.noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hist of cluster sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter = df.n_pixel\n",
    "# get similar size bins in log space\n",
    "bins = np.unique(np.geomspace(parameter.min(), parameter.max()*1.1, 100).astype(int))\n",
    "\n",
    "# # linear bins\n",
    "# bins = np.arange(int(df.n_pixel.min()), int(df.n_pixel.max()*1.1), 1)\n",
    "\n",
    "count, edges = np.histogram(parameter, bins=bins,)\n",
    "\n",
    "plt.figure()\n",
    "StepPatch = plt.stairs(count, edges, fill=True)\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Cluster Size [pixel]')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid()\n",
    "StepPatch.zorder=5\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show images with detected cluster bigger than a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pictures filtered by a parameter and a limit\n",
    "\n",
    "# limit = 2e5\n",
    "# parameter = 'charge'\n",
    "\n",
    "limit = 25  # limit from plot\n",
    "parameter = 'n_pixel'\n",
    "\n",
    "file_times = camera.file_handler.time.asdatetime()[:]\n",
    "\n",
    "gb = df[df[parameter]  > limit].groupby('time')\n",
    "df_filter = df[df.time.isin(gb.groups) & (df.n_pixel > 5)]\n",
    "# indexes = np.unique([np.argwhere(file_times == i) for i in gb.groups])\n",
    "\n",
    "df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 20\n",
    "\n",
    "# images = []  # to store the images later\n",
    "\n",
    "for t_i, df_i in df_filter.groupby('time'):\n",
    "    fig, ax = plt.subplots(ncols=2, #len(df_i)+1,\n",
    "                           nrows=1, squeeze=False, figsize=(9,5))\n",
    "\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    i = np.argwhere(file_times==t_i).flatten()[0]\n",
    "    \n",
    "    rgb = camera.images.load_rgb(index=i)[0]/2**16\n",
    "#     images.append(rgb)  # to store the images later\n",
    "#     continue\n",
    "    ax[0].imshow(rgb)  # rgb[frame, row, col], /255 to get 0->1\n",
    "    ax[1].imshow(rgb)  # rgb[frame, row, col], /255 to get 0->1\n",
    "    \n",
    "    n=1\n",
    "    for j, df_j in df_i.iterrows():\n",
    "        box_corners = cv2.boxPoints(((df_j.box_center_x, df_j.box_center_y), \n",
    "                                     (df_j.box_size_x, df_j.box_size_y), \n",
    "                                     df_j.angle))\n",
    "        \n",
    "        ax[1].plot(strawb.tools.connect_polar(box_corners[:,1]),\n",
    "                 strawb.tools.connect_polar(box_corners[:,0]),\n",
    "                 color='w', alpha=.5, label='Min. Box'\n",
    "                 )\n",
    "        ax[1].plot(df_j.center_of_mass_y, df_j.center_of_mass_x, \n",
    "                 'o', color='w', alpha=.75,\n",
    "                 label='Center of Mass',\n",
    "                 )\n",
    "        ax[1].plot(df_j.center_of_pix_y, df_j.center_of_pix_x,\n",
    "                 'x', color='w', alpha=.75,\n",
    "                 label='Center of Pix',\n",
    "                 )\n",
    "        ax[1].plot(df_j.box_center_y, df_j.box_center_x,\n",
    "                 '>', color='w', alpha=.75,\n",
    "                 label='Center of Box',\n",
    "                 )\n",
    "        \n",
    "        \n",
    "        \n",
    "    # don't show double labels\n",
    "    handles, labels = ax[1].get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax[1].legend(by_label.values(), by_label.keys(), loc='upper right')\n",
    "\n",
    "    fig.suptitle(f'{camera.file_handler.module} - {t_i:%Y-%m-%d %H:%M:%S}', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{camera.file_handler.module}_{t_i:%Y%m%dT%H%M%S}_camera.pdf')\n",
    "    \n",
    "# # in case you can store the images, e.g. with numpy\n",
    "# np.savez_compressed('LED_images.npz', images=rgb_s)\n",
    "\n",
    "# # and read it back\n",
    "# with np.load('LED_images.npz') as f:\n",
    "#     images = f['images']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSpec\n",
    "GridSpec can be used to set different sizes for each subplot.\n",
    "Here the goal is to get subplots all with the same height. All subplots are set to aspect-ratio equal. The subplots can be of ratios (widt/hight)\n",
    "\n",
    "The width ratio for the GridSpec is simply the list of all individual image ratios $r_i$ of:\n",
    "$$ r_i = \\frac{h_i}{w_i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import copy\n",
    "\n",
    "def get_rect(row):\n",
    "    return ((row['box_center_x'], row['box_center_y']),\n",
    "            (row['box_size_x'], row['box_size_y']),\n",
    "            row['angle'])\n",
    "    \n",
    "for t_i, df_i in df_filter.groupby('time'):\n",
    "    df_ii = df_i[df_i[parameter] > limit]\n",
    "    \n",
    "    # Calculate all pictures of clusters for on picture to set up the GridSpec width_ratios\n",
    "    rgb = camera.images.load_rgb(index=i)[0]/2**16\n",
    "    index = np.argmin(np.abs(camera.file_handler.time[:] - df_i.time.iloc[0].timestamp()))\n",
    "    \n",
    "    rgb = camera.images.load_rgb(index=index)[0]/2**16\n",
    "    \n",
    "    # Calculate all pictures of clusters for on picture to set up the GridSpec width_ratios\n",
    "    image_size_list = [rgb.shape[:2]]\n",
    "    images_tran = []\n",
    "    \n",
    "    for j, df_j in df_ii.iterrows():        \n",
    "        rect_scale = strawb.camera.rect_scale_pad(get_rect(df_j), scale=1, pad=50)\n",
    "        img_target, rect_target, t_matrix = strawb.camera.img_rectangle_cut(rgb,\n",
    "                                                                            rect_scale, \n",
    "                                                                            angle=None,\n",
    "                                                                            angle_normalize=False)\n",
    "        images_tran.append([img_target, rect_target, t_matrix])\n",
    "        image_size_list.append(img_target.shape[:2])\n",
    "        \n",
    "    # grid spec to resize the plots a bit \n",
    "    s = np.array(image_size_list)\n",
    "    width_ratios = s[:,1]/s[:,0]\n",
    "    print(width_ratios, len(images_tran))\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(9,5), \n",
    "                           nrows=1, \n",
    "                           ncols=len(df_i[df_i[parameter] > limit])+1, \n",
    "                           squeeze=False,\n",
    "                           gridspec_kw=dict(width_ratios=width_ratios, height_ratios=[1])\n",
    "                          )\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    # Draw image and add cluster\n",
    "    ax[0].imshow(rgb)\n",
    "\n",
    "    for n, (j, df_j) in enumerate(df_ii.iterrows()):\n",
    "        # Draw Box and more for croped to cluster\n",
    "        rect_scale = strawb.camera.rect_scale_pad(get_rect(df_j), scale=1, pad=50)\n",
    "        img_target, rect_target, t_matrix = images_tran[n]\n",
    "        box_i = strawb.camera.transform_cv2np(cv2.boxPoints(get_rect(df_j)), t_matrix)\n",
    "        \n",
    "        # Draw Box and more for cluster\n",
    "        label_dict = dict(color='w', alpha=.5)\n",
    "        ax[0].plot(*strawb.tools.connect_polar(box_i).T[::-1], **label_dict, label='Biolumi. Event')\n",
    "#         ax[0].plot(*df_j.center_of_mass[::-1],'o', **label_dict, label='Center of Mass')\n",
    "#         ax[0].plot(*df_j.center_of_pix[::-1], '*', **label_dict, label='Center of Pix')\n",
    "#         ax[0].plot(*df_j.box_center[::-1],'x', **label_dict, label='Center of Box')\n",
    "\n",
    "        ax[n+1].imshow(img_target)\n",
    "        ax[n+1].plot(*strawb.tools.connect_polar(box_i).T, '-', color='gray', alpha=.75, label='Cluster Box')\n",
    "\n",
    "\n",
    "        pos = np.array(df_j[['center_of_mass_y', 'center_of_mass_x']])\n",
    "        ax[n+1].plot(*strawb.camera.transform_np([pos], t_matrix).T, 'o', **label_dict, label='Center Mass')\n",
    "        pos = np.array(df_j[['center_of_pix_y', 'center_of_pix_x']])\n",
    "        ax[n+1].plot(*strawb.camera.transform_np([pos], t_matrix).T, '*', **label_dict, label='Center Pixel',)\n",
    "        pos = np.array(df_j[['box_center_y', 'box_center_x']])\n",
    "        ax[n+1].plot(*strawb.camera.transform_np([pos], t_matrix).T, 'x', **label_dict, label='Center Box',)\n",
    "        \n",
    "    for axi in ax:\n",
    "        axi.axis('off')\n",
    "        \n",
    "    # don't show double labels\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    for label_i in by_label:\n",
    "        lin_i = copy.copy(by_label[label_i])\n",
    "        lin_i.set_alpha(1)\n",
    "        lin_i.set_c('gray')\n",
    "        by_label[label_i] = lin_i\n",
    "#     ax[0].legend(by_label.values(), by_label.keys(), ncol=2)\n",
    "    \n",
    "    leg = fig.legend(by_label.values(), by_label.keys(), loc='upper center', ncol=4)\n",
    "        \n",
    "#     fig.tight_layout()\n",
    "#     fig.subplots_adjust(right=0.75) \n",
    "    fig.tight_layout()\n",
    "    \n",
    "#     plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a plotting function for fast df insights\n",
    "def stair_scatter(df, color=None, size=1, alpha=.1, ax=None, columns=None, log=True, **kwargs):\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    rows = columns[1:] \n",
    "    cols = columns[:-1]\n",
    "    \n",
    "    # ax[row, col]\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(nrows=len(rows), \n",
    "                       ncols=len(cols), \n",
    "                       sharex='col', sharey='row', \n",
    "                       squeeze=False, \n",
    "                       **kwargs)\n",
    "        \n",
    "        for j, cols_j in enumerate(cols):\n",
    "            if log:\n",
    "                ax[-1,j].set_xscale('log')\n",
    "            ax[-1,j].set_xlabel(cols_j.replace('_',' '), rotation=0) #rotation=70\n",
    "        for i, row_i in enumerate(rows):\n",
    "            ax[i, 0].set_ylabel(row_i.replace('_',' '), rotation=90) #rotation=30)\n",
    "            if log:\n",
    "                ax[i, 0].set_yscale('log')\n",
    "        for i, row_i in enumerate(rows):\n",
    "            for j, cols_j in enumerate(cols):\n",
    "                if j<=i:\n",
    "                    ax[i, j].grid()\n",
    "                else:\n",
    "                    ax[i,j].axis('off')\n",
    "\n",
    "    for i, row_i in enumerate(rows):\n",
    "        for j, cols_j in enumerate(cols):\n",
    "            if j<=i:#cols_j != row_i:\n",
    "    #             ax[i, j].text(0.5, 0.5, f'x:{cols_j}\\ny:{row_i}', \n",
    "    #                           horizontalalignment='center',\n",
    "    #                           verticalalignment='center', \n",
    "    #                           transform=ax[i, j].transAxes)\n",
    "                ax[i, j].scatter(df[cols_j], df[row_i], s=size, c=color, alpha=alpha)\n",
    "        \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "\n",
    "# define a container for a ML-Model\n",
    "class ClusterModel:\n",
    "    def __init__(self, model, df, columns, n=1000, name='', *kwargs):\n",
    "        self.name = name\n",
    "        # define the model\n",
    "        self.model = model\n",
    "\n",
    "        # fit the model\n",
    "        X = sklearn.preprocessing.StandardScaler().fit_transform(df[columns].to_numpy())\n",
    "        random_int = np.random.randint(0, len(X), n)  # select n out of X\n",
    "        self.model.fit(X[random_int])\n",
    "\n",
    "        # cal the all peaks\n",
    "        self.labels = self.model.predict(X)\n",
    "        \n",
    "        # sort the labels by count\n",
    "        clusters, clusters_counts = np.unique(self.labels, return_counts=True)\n",
    "        self.clusters = clusters[np.argsort(-clusters_counts)]\n",
    "        self.clusters_counts = clusters_counts[np.argsort(-clusters_counts)]\n",
    "\n",
    "        self.labels_cs = np.zeros_like(self.labels, dtype=int) - 1\n",
    "        for i, c_i in enumerate(self.clusters):\n",
    "            self.labels_cs[self.labels == c_i] = i\n",
    "            \n",
    "        self.df = df\n",
    "\n",
    "    def plot_level_hist(self, ax=None, norm_x=True, norm_y=True):\n",
    "        if ax is None:\n",
    "            plt.figure()\n",
    "            ax = plt.gca()\n",
    "            ax.set_yscale('log')\n",
    "            ax.set_xlabel('Classification Typ')\n",
    "            ax.set_ylabel('Count')\n",
    "            \n",
    "        if norm_x:\n",
    "            class_typ = np.linspace(0, 1,len(self.clusters_counts))\n",
    "        else:\n",
    "            class_typ = np.arange(0,len(self.clusters_counts)+1, 1)\n",
    "            \n",
    "        if norm_y:\n",
    "            norm_y_s = self.clusters_counts.max()\n",
    "        else:\n",
    "            norm_y_s = 1\n",
    "            \n",
    "        ax.plot(class_typ, self.clusters_counts/norm_y_s, label=f'{self.name.replace(\"_\",\"-\")} {len(self.clusters)}')\n",
    "#         plt.hist(self.labels_cs, bins=len(self.clusters_counts))\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "columns = ['n_pixel', 'charge']\n",
    "columns_log = ['n_pixel', 'charge_log']\n",
    "\n",
    "n = 20000\n",
    "n_clusters = 4\n",
    "k_means_4 = ClusterModel(sklearn.cluster.KMeans(n_clusters=n_clusters), df, columns, name='KMeans_4', n=n)\n",
    "# k_means_4_log = ClusterModel(sklearn.cluster.KMeans(n_clusters=n_clusters), df, columns_log, name='KMeans_4_log', n=n)\n",
    "\n",
    "n_clusters = 2\n",
    "k_means_2 = ClusterModel(sklearn.cluster.KMeans(n_clusters=n_clusters), df, columns, name='KMeans_2', n=n)\n",
    "# k_means_2_log = ClusterModel(sklearn.cluster.KMeans(n_clusters=n_clusters), df, columns_log, name='KMeans_2_log', n=n)\n",
    "\n",
    "# n = 2000\n",
    "# aff_pro = ClusterModel(sklearn.cluster.AffinityPropagation(damping=.7), df, columns, name='AffinityPropagation')\n",
    "# aff_pro_log = ClusterModel(sklearn.cluster.AffinityPropagation(damping=.7), df, columns_log, name='AffinityPropagation_log')\n",
    "\n",
    "# n = 20000\n",
    "# mean_shift = ClusterModel(sklearn.cluster.MeanShift(n_jobs=-1), df, columns, name='MeanShift')\n",
    "# mean_shift_log = ClusterModel(sklearn.cluster.MeanShift(n_jobs=-1), df, columns_log, name='MeanShift_log')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [k_means_2,#k_means_2_log,\n",
    "              k_means_4, #k_means_4_log,\n",
    "#               aff_pro, aff_pro_log,\n",
    "#               mean_shift, mean_shift_log\n",
    "             ]\n",
    "\n",
    "\n",
    "ax = None\n",
    "for i, alg_i in enumerate(algorithms):\n",
    "    ax = alg_i.plot_level_hist(ax)\n",
    "    \n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [#'plateau_sizes', 'left_thresholds', 'right_thresholds'\n",
    "           'n_pixel', 'charge', #'charge_with_noise', 'noise', \n",
    "           'sn_mean_deviation', 'sn_mean_deviation_sigma']\n",
    "\n",
    "alg_i=k_means_4\n",
    "stair_scatter(alg_i.df, \n",
    "              color=alg_i.labels_cs,\n",
    "              size=1+10*alg_i.labels_cs,\n",
    "              columns=columns,\n",
    "              alpha=1,\n",
    "              figsize=(9,9))\n",
    "    \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_i=k_means_4\n",
    "# Sort the labels by counts\n",
    "labels, counts = np.unique(alg_i.labels_cs, return_counts=True)\n",
    "\n",
    "# Take half of the labels and show cluster\n",
    "df[alg_i.labels_cs>labels[np.argsort(counts)][len(labels)//3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_i=k_means_2\n",
    "# Sort the labels by counts\n",
    "labels, counts = np.unique(alg_i.labels_cs, return_counts=True)\n",
    "\n",
    "# Take half of the labels and show cluster\n",
    "df[alg_i.labels_cs>labels[np.argsort(counts)][len(labels)//2]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3dbe8948e6ba6f7b500cbad156adccce2d4d02afc71091580e98904bda0c5804"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
