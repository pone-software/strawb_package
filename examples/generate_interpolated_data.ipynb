{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9736a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import tqdm\n",
    "import tqdm.notebook\n",
    "import h5py\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import multiprocessing\n",
    "import sys\n",
    "\n",
    "import dateutil\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import strawb\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb666f",
   "metadata": {},
   "source": [
    "# Load DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824cfe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = strawb.SyncDBHandler()\n",
    "db.load_onc_db_update(save_db=True, output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd808c7d",
   "metadata": {},
   "source": [
    "# Mask files of interest: PMTSpec, PMT rates, downloaded, valid, not rate_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41576fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = db.dataframe.dataProductCode == 'PMTSD'\n",
    "mask &= db.dataframe.deviceCode == 'TUMPMTSPECTROMETER001'\n",
    "mask &= db.dataframe.synced\n",
    "mask &= db.dataframe.file_version > 2\n",
    "mask &= db.dataframe.measurement_type != 'rate_scan'\n",
    "\n",
    "mask_time = db.dataframe.dateFrom>='2021-09-22T04:00'\n",
    "mask_time &= db.dataframe.dateFrom<'2021-09-22T05:00'\n",
    "db.dataframe[mask & mask_time].iloc[0]\n",
    "\n",
    "pmt = strawb.sensors.PMTSpec(db.dataframe[mask & mask_time].fullPath.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc616010",
   "metadata": {},
   "outputs": [],
   "source": [
    "strawb.trb_tools.InterpolatedRatesFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34154ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_interp_rates(t, dataframe, dt, interp_frequency = 1./60., bar_position=0, move_to_dss=True):\n",
    "    mask_i = dataframe.dateFrom >= t\n",
    "    mask_i &= dataframe.dateFrom < t+dt\n",
    "    \n",
    "    device_code = dataframe[mask_i].deviceCode.unique()[0]\n",
    "    \n",
    "    file_name = f'{device_code.lower()}_{t:%Y%m%d}_{dt.freqstr}_{interp_frequency:.2f}_rates_interpolated.hdf5'\n",
    "    file_path_0 = os.path.join(os.path.abspath('.'), file_name)\n",
    "    \n",
    "    directory = os.path.join(strawb.Config.proc_data_dir, device_code.lower()) #, f'{t:%Y%m}')\n",
    "    file_path_1 = os.path.join(directory, file_name)\n",
    "    \n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    file_attrs= {'device_code': device_code,\n",
    "                            'file_end': (t+dt).timestamp() - 1e-3,\n",
    "                            'file_start': t.timestamp(),\n",
    "                           }\n",
    "    group_attrs={'interp_frequency': interp_frequency}\n",
    "    \n",
    "    err_dict = {}\n",
    "#     print(file_path_0)\n",
    "    if os.path.exists(file_path_0):\n",
    "        os.remove(file_path_0)\n",
    "        \n",
    "    file = strawb.trb_tools.InterpolatedRatesFile(file_path_0, read_data=False)  # don't read as file doesn't exist\n",
    "    \n",
    "    print(f\"Start new file for: {t}\")  # you need this print to see the progress bar of this process\n",
    "#     for i in dataframe.fullPath[mask_i]:\n",
    "    for i in tqdm.notebook.tqdm(dataframe.fullPath[mask_i], position=bar_position, desc=str(t)):\n",
    "#         print(t, os.path.basename(i))\n",
    "        pmt_i = strawb.sensors.PMTSpec(i)\n",
    "\n",
    "        daq_frequency_readout = pmt_i.file_handler.daq_frequency_readout[:]\n",
    "\n",
    "        # check that readout frequency doesn't change in a file\n",
    "        unique = np.unique(daq_frequency_readout[daq_frequency_readout != -1])\n",
    "        if unique.shape[0] > 1:\n",
    "            print('skipp ', os.path.basename(i), unique)\n",
    "            continue\n",
    "        del daq_frequency_readout, unique\n",
    "\n",
    "        # print(np.unique(daq_frequency_readout[daq_frequency_readout != -1]).shape)\n",
    "        # print(daq_frequency_readout[:], daq_frequency_readout[daq_frequency_readout != -1])\n",
    "        # print(np.unique(daq_frequency_readout[daq_frequency_readout != -1]).shape)\n",
    "\n",
    "        try:\n",
    "            pmt_i.trb_rates.interp_frequency = interp_frequency\n",
    "        except Exception as err:\n",
    "            err_dict.update({i: err.args})\n",
    "        else:\n",
    "            file.write_to_file(pmt_i, file_attrs=file_attrs, group_attrs=group_attrs)\n",
    "        finally:\n",
    "            del pmt_i \n",
    "                \n",
    "    if move_to_dss:\n",
    "        shutil.move(file_path_0, file_path_1)\n",
    "#     print('--> DONE ', t)\n",
    "    return err_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f48a2",
   "metadata": {},
   "source": [
    "# Parse one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = calculate_interp_rates(t = dateutil.parser.isoparse('2021-09-22 00:00:00+00:00'),\n",
    "                             dt = pandas.offsets.Hour(2),\n",
    "                             dataframe = db.dataframe[mask],\n",
    "                             interp_frequency = 1,\n",
    "                             move_to_dss=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc22d5",
   "metadata": {},
   "source": [
    "# Parse multiple files with multiple cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de6884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the interval per file\n",
    "## Candidates for the interval -> pandas.date_range(..., freq=)\n",
    "# pandas.offsets.Second\n",
    "# pandas.offsets.Minute\n",
    "# pandas.offsets.Hour\n",
    "# pandas.offsets.Day\n",
    "# pandas.offsets.Week\n",
    "# pandas.offsets.MonthBegin\n",
    "# pandas.offsets.YearBegin\n",
    "dt = pandas.offsets.MonthBegin(1)\n",
    "\n",
    "# Manualy\n",
    "t_start = dateutil.parser.isoparse('2021-09-01 00:00:00+00:00')\n",
    "t_end = dateutil.parser.isoparse('2021-09-05 10:00:00+00:00')\n",
    "\n",
    "# Take min and max from DB\n",
    "# t_start = db.dataframe.dateFrom[mask].min() - dt\n",
    "# t_end = db.dataframe.dateFrom[mask].max()\n",
    "\n",
    "\n",
    "dr = pandas.date_range(start=t_start, #db.dataframe.dateFrom[mask].min() - dt,\n",
    "                       end=t_end,\n",
    "                       freq=dt,\n",
    "                       normalize=True\n",
    "                      )\n",
    "\n",
    "dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(*args, **kwargs):\n",
    "    print(f'args: {args}')\n",
    "    print(f'kwargs: {kwargs}')\n",
    "    \n",
    "f(1,2,3,4,5,7,8,9, a=1)\n",
    "\n",
    "[[error1, 1,2,3,], [error1, 1,2,3,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1befd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process pool\n",
    "pool = multiprocessing.Pool(4)\n",
    "\n",
    "# Total progress bar\n",
    "pbar = tqdm.notebook.tqdm(dr, desc='Compile interpolated rates', position=0)\n",
    "\n",
    "# collect results and errors\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "# called if after a process sucessfully executed the function\n",
    "def update(*a):\n",
    "    results.append(a)\n",
    "    pbar.update()\n",
    "\n",
    "# called if after a process failed to executed the function\n",
    "def update_err(*a):\n",
    "    errors.append(a)\n",
    "    pbar.update()\n",
    "\n",
    "# create the tasks and execute them\n",
    "for i, dr_i in enumerate(dr):\n",
    "    pool.apply_async(calculate_interp_rates,\n",
    "                     args=(dr_i,),\n",
    "                     kwds={'dataframe': db.dataframe[mask], \n",
    "                           'dt': dt, \n",
    "                           'interp_frequency': 1, \n",
    "                           'bar_position': i+1, \n",
    "                           'move_to_dss': False},\n",
    "                     callback=update,\n",
    "                     error_callback=update_err)\n",
    "\n",
    "# wait for the process to finish\n",
    "pool.close()\n",
    "pool.join()\n",
    "# close the progress bar\n",
    "pbar.close()\n",
    "\n",
    "# Print errors and results\n",
    "print('Results:', results)\n",
    "print('Errors : ', errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ee61d",
   "metadata": {},
   "source": [
    "# Test multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17391f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dummy function\n",
    "def test(i, bar_position, *args, **kwargs):        \n",
    "    print('')  # needed otherwise it doesn't work\n",
    "    for j in tqdm.notebook.tqdm(range(5), desc=f'Process {i}', position=bar_position):\n",
    "        time.sleep(.1)\n",
    "        if j == 3 and i == 2:\n",
    "            raise KeyError(i, 'Test')\n",
    "        \n",
    "    return i\n",
    "\n",
    "# iterable for the pool\n",
    "x = np.arange(5)\n",
    "\n",
    "# Process pool\n",
    "pool = multiprocessing.Pool(4)\n",
    "\n",
    "# Total progress bar\n",
    "pbar = tqdm.notebook.tqdm(x, desc='Compile interpolated rates', position=0)\n",
    "\n",
    "# collect results and errors\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "# called if after a process sucessfully executed the function\n",
    "def update(*a):\n",
    "    results.append(a)\n",
    "    pbar.update()\n",
    "\n",
    "# called if after a process failed to executed the function\n",
    "def update_err(*a):\n",
    "    errors.append(a)\n",
    "    pbar.update()\n",
    "\n",
    "# create the tasks and execute them\n",
    "for i, dr_i in enumerate(x):\n",
    "    pool.apply_async(test,\n",
    "                     args=(dr_i,),\n",
    "                     kwds={'dataframe': db.dataframe[mask], \n",
    "                           'dt': dt, \n",
    "                           'interp_frequency': 1, \n",
    "                           'bar_position': i+1, \n",
    "                           'move_to_dss': False},\n",
    "                     callback=update,\n",
    "                     error_callback=update_err)\n",
    "\n",
    "# wait for the process to finish\n",
    "pool.close()\n",
    "pool.join()\n",
    "# close the progress bar\n",
    "pbar.close()\n",
    "\n",
    "# Print errors and results\n",
    "print('Results:', results)\n",
    "print('Errors : ', errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0bdf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
