{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "\n",
    "# This examples shows who to download files from the ONC server\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import scipy.ndimage\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib\n",
    "\n",
    "import strawb.tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ONC DB and mask files of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if DB exits, if not load it, but update it anyway\n",
    "if os.path.exists(strawb.Config.pandas_file_sync_db):\n",
    "    db = strawb.SyncDBHandler()  # loads the db from disc\n",
    "else:\n",
    "    db = strawb.SyncDBHandler(load_db=False)  # loads the db from ONC server\n",
    "\n",
    "db.load_onc_db_update(output=True, save_db=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask by device and data-product\n",
    "mask = db.dataframe['deviceCode'] == 'TUMMUONTRACKER001'\n",
    "mask &= db.dataframe.dataProductCode == 'MTSD'  # see SyncDBHandler.sensor_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dataframe.dateTo.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some masked entries\n",
    "db.dataframe[mask].iloc[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download a specific file, needs some minutes if file isn't synced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['TUMMUONTRACKER001_20220731T001146.146Z-SDAQ-MUON.hdf5']\n",
    "db_i = db.get_files_from_names(file_list)\n",
    "db_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon = strawb.MuonTracker(file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show file version - 4 has tot data, which we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon.file_handler.file_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.plot(muon.file_handler.tot_time_ns[:])\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('time [s]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all have the same shape -> entry 'i' represents one event\n",
    "print(f'tot_time   : {muon.file_handler.tot_time.shape}')\n",
    "print(f'tot_time_ns: {muon.file_handler.tot_time_ns.shape}')\n",
    "print(f'tot_channel: {muon.file_handler.tot_channel.shape}')\n",
    "print(f'tot_tot    : {muon.file_handler.tot_tot.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first n events\n",
    "n = 5\n",
    "\n",
    "# Absolute Timestamp in seconds [s] with resolution [ns]\n",
    "print(f'tot_time   : {muon.file_handler.tot_time[:n]}')\n",
    "\n",
    "# Absolute Timestamp in seconds [s] with resolution [ns], converted to dateformat\n",
    "print(f'tot_time   : {muon.file_handler.tot_time.asdatetime()[:n]}')\n",
    "\n",
    "# TRB Timestamp in [ns] - not absolute therefore most precise\n",
    "print(f'tot_time_ns: {muon.file_handler.tot_time_ns[:n]}')\n",
    "\n",
    "# TRB Channel of the event\n",
    "print(f'tot_channel: {muon.file_handler.tot_channel[:n]}')\n",
    "\n",
    "# TRB time over threshold in [ns]\n",
    "print(f'tot_tot    : {muon.file_handler.tot_tot[:n]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Cut Data\n",
    "It seems, the TRB has an overflow at 2750 in both time data. (can be corrected with np.unwrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000000\n",
    "tot_time_ns = muon.file_handler.tot_time_ns[:n]\n",
    "\n",
    "mask_valid = tot_time_ns!=1e-9\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tot_time_ns[mask_valid], lw=3, label='raw')\n",
    "period=2750\n",
    "plt.plot(np.unwrap(tot_time_ns[mask_valid], period=period), label=period)\n",
    "period=2749\n",
    "plt.plot(np.unwrap(tot_time_ns[mask_valid], period=period), label=period)\n",
    "\n",
    "period=1000\n",
    "plt.plot(np.unwrap(tot_time_ns[mask_valid], period=period), label=period)\n",
    "\n",
    "period=2748.75\n",
    "plt.plot(np.unwrap(tot_time_ns[mask_valid], period=period), label=period)\n",
    "\n",
    "period=2**38*1e-8\n",
    "plt.plot(np.unwrap(tot_time_ns[mask_valid], period=period), label=period)\n",
    "period=2**39*1e-8\n",
    "plt.plot(np.unwrap(tot_time_ns[mask_valid], period=period), label=period)\n",
    "plt.legend()\n",
    "# plt.xlim((842581.3723510662, 842594.7912079565))\n",
    "# plt.ylim((7300, 7310))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = muon.file_handler.tot_tot[:]\n",
    "\n",
    "tot_time_ns = muon.file_handler.tot_time_ns[:]\n",
    "\n",
    "# some values are 1ns, exclude them\n",
    "mask_valid = tot_time_ns!=1e-9\n",
    "\n",
    "# some tot values are very high ~1e12, exclude them here or not\n",
    "max_tot = 1 * 1e3 # cut at 1us - [ns]\n",
    "mask_valid &= (tot<max_tot) & (tot > 0)\n",
    "\n",
    "print(f'exclude {np.sum(~mask_valid)} events')\n",
    "\n",
    "# the overflow is close to 2750 - it seems it is based on 2 bit and 2**38*1e-8\n",
    "trb_overflow = 2**38*1e-8\n",
    "\n",
    "# time in seconds, time_masked since epoch (1.1.1970); remove the overflow, \n",
    "# but don't do it at tot_time_ns as it can cause precision loss\n",
    "# time_masked = np.unwrap(muon.file_handler.tot_time[mask_valid], period=trb_overflow)\n",
    "time_masked = np.unwrap(tot_time_ns[mask_valid], period=trb_overflow)\n",
    "time_masked += muon.file_handler.tot_time[0] - time_masked[0]\n",
    "\n",
    "df_base = pandas.DataFrame({\n",
    "    # time_masked since epoch (1.1.1970)\n",
    "    'time': time_masked,\n",
    "    # time_ns TRB internal\n",
    "    'time_ns': tot_time_ns[mask_valid], \n",
    "    # channel id\n",
    "    'channel': muon.file_handler.tot_channel[mask_valid], \n",
    "    # tot in nanoseconds\n",
    "    'tot': tot[mask_valid]})\n",
    "\n",
    "# # the time isn't sorted correctly, do it here\n",
    "df_base.sort_values(['time', 'time_ns', 'tot'], inplace=True)\n",
    "\n",
    "# free RAM - parameter not needed\n",
    "del tot_time_ns, time_masked, mask_valid, tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeline of events\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# plot only the first n entries\n",
    "n = 10000\n",
    "sc = plt.scatter(strawb.tools.asdatetime(df_base.time.iloc[:n]),\n",
    "            df_base.tot.iloc[:n],\n",
    "            c=df_base.channel.iloc[:n])\n",
    "\n",
    "plt.colorbar(sc, label='Channel')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(\n",
    "    mdates.ConciseDateFormatter(ax.xaxis.get_major_locator())\n",
    ")\n",
    "ax.set_axisbelow(True)  # show grid behind scatter\n",
    "\n",
    "plt.ylabel('ToT [ns]')\n",
    "plt.xlabel('Date [s]')\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show short ToT's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen. hist\n",
    "counts, edges = np.histogram(df_base.tot, bins=1000)\n",
    "\n",
    "# plot hist\n",
    "plt.figure()\n",
    "plt.stairs(counts, edges=edges)\n",
    "plt.xlabel('ToT [ns]')\n",
    "plt.ylabel('Counts')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hist\n",
    "plt.figure()\n",
    "\n",
    "# gen. hist\n",
    "dt = np.diff(df_base.time_ns)\n",
    "counts, edges = np.histogram(dt[(dt>=0) &(dt<1e-1)], bins=1000)\n",
    "plt.stairs(counts, edges=edges)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Delta time between events [s]')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event builder\n",
    "Detect and build events. An event is defined as set of tot-events where the timestamps between the singel tot-events isn't greater as a limit (`dt_max`). Muons are traveling with ~c and 1ns corresponds to 0.3m distance. The MounTracker has a diameter of 13\", so ~0.3m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the label function\n",
    "def label_intermediate(input):\n",
    "    \"\"\" Label features in an array based on a second intermediate array, which length is shorter by one.\n",
    "    input                     =  [1,0,1,1,0,0,0,1]\n",
    "    scipy.ndimage.label(input)=  [1,0,2,2,0,0,0,3]\n",
    "    label_intermediate(input) = [1,1,2,2,2,0,0,3,3]\n",
    "\n",
    "    PARAMETERS\n",
    "    ----------\n",
    "    input : array_like\n",
    "        The intermediate array-like object to be labeled. Any non-zero values in `input` are\n",
    "        counted as features and zero values are considered the background.\n",
    "\n",
    "    RETURNS\n",
    "    -------\n",
    "    label : ndarray or int\n",
    "        An integer ndarray where each unique feature in `input` has a unique\n",
    "        label in the returned array. And each label is extended by one item.\n",
    "    num_features : int\n",
    "    Example\n",
    "    -------\n",
    "    >>> d_a = np.diff(a)\n",
    "    >>> label = label_intermediate(d_a<1.)\n",
    "    >>> assert len(label) == len(a)\n",
    "    \"\"\"\n",
    "    label, num_features = scipy.ndimage.label(input, structure=None)\n",
    "    label = np.append(label, [0])  # add one item\n",
    "    label[1:][label[:-1]!=0] = label[:-1][label[:-1]!=0]  # add the shifted labels if label!=0\n",
    "    return label, num_features\n",
    "\n",
    "# test\n",
    "a = np.array([1,0,2,2,0,0,0,3])\n",
    "l, _ = label_intermediate(a)\n",
    "print(f'input         :  {a}')\n",
    "print(f'l_intermediate: {l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build events for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_ns = 20e-9\n",
    "# # add label to df\n",
    "# df_base.sort_values(['time', 'time_ns'], inplace=True)\n",
    "\n",
    "# evet selection\n",
    "dt = np.diff(df_base['time_ns'])\n",
    "# df_base['label'], _ = label_intermediate((dt>=0) & (dt<threshold_ns))\n",
    "df_base['label'], _ = label_intermediate(np.abs(dt)<threshold_ns)\n",
    "\n",
    "# remove all label 0, and make a copy of the dataframe, keep the base\n",
    "df = df_base[df_base['label']>0].copy()\n",
    "# df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# add label count, but only if it doesn't exist\n",
    "if 'label_count' not in df:\n",
    "    df = pandas.merge(df, df.groupby('label')['label'].count(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=(None, '_count'))\n",
    "    \n",
    "if 'time_ns_label' not in df:\n",
    "    df = pandas.merge(df, df.groupby('label')['time_ns'].min(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=(None, '_label'))\n",
    "    df['time_ns_label'] = df.time_ns - df.time_ns_label\n",
    "\n",
    "# # the time isn't sorted correctly, do it here\n",
    "# df.sort_values(['time', 'time_ns_label', 'tot'], inplace=True)\n",
    "\n",
    "print(f'events reduced from: {len(df_base)} to {len(df)} - or {len(df)/len(df_base)*100:.2f}%')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show one Event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the events with most entries\n",
    "event_mask = df.label_count==df.label_count.max()\n",
    "\n",
    "# show the event\n",
    "df[df.label==df.label[event_mask].iloc[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the active channels per event\n",
    "plt.figure()\n",
    "\n",
    "label_counts = df.groupby('label')['label_count'].first()\n",
    "plt.hist(label_counts, bins=np.arange(2, label_counts.max()+2)-.5)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Delta time between events [s]')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "plt.grid()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build events with multiplicity `length`\n",
    "\n",
    "## check if one channel appears multiple times in one label\n",
    "because we use a pivot table later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels where one channel appears multiple times\n",
    "mask_duplicate = df.duplicated(['label', 'channel'], keep=False)\n",
    "df_duplicate = df[mask_duplicate].copy()\n",
    "\n",
    "# cal. the time diff between the duplicate per label\n",
    "if 'time_ns_duplicate' in df_duplicate:\n",
    "    df_duplicate.pop('time_ns_duplicate')\n",
    "df_duplicate = pandas.merge(df_duplicate, df_duplicate.groupby('label').time_ns.first(),\n",
    "             how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=(None, '_duplicate'))\n",
    "df_duplicate['time_ns_duplicate'] = df_duplicate.time_ns - df_duplicate.time_ns_duplicate\n",
    "df_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if time_ns_duplicate is not 0, there are two duplicates in on label\n",
    "label_non_zero = df_duplicate[df_duplicate.time_ns_duplicate!=0].label.unique()\n",
    "\n",
    "# show it\n",
    "df_duplicate[df_duplicate.label.isin(label_non_zero)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hist\n",
    "plt.figure()\n",
    "\n",
    "# gen. hist\n",
    "counts_0, edges_0 = np.histogram(df.tot, bins=1000)\n",
    "\n",
    "counts, edges = np.histogram(df.tot[mask_duplicate], bins=edges_0)\n",
    "plt.stairs(counts, edges=edges,label='duplicates')\n",
    "\n",
    "counts, edges = np.histogram(df.tot[~mask_duplicate], bins=edges_0)\n",
    "plt.stairs(counts, edges=edges,label='non duplicates')\n",
    "\n",
    "# plt.stairs(counts_0, edges=edges_0, label='all', color='gray', lw=1, alpha=1, ls=':')\n",
    "\n",
    "\n",
    "plt.xlabel('ToT [ns]')\n",
    "plt.ylabel('Counts')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# the plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result: \n",
    "- most of the events don't show duplicate entries per channel\n",
    "- duplicate show a tot of ~25ns and ~58ns, whereas non-duplicate have ~25ns\n",
    "- therefore -> the long TOT seem to be incorrect \n",
    "    - it is sorted by tot, and we want only the shortest\n",
    "    - we get it with: aggfunc='first' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a dataframe with non duplicates\n",
    "df_nondup = df[~mask_duplicate].copy()\n",
    "\n",
    "print(f'events reduced from: {len(df)} to {len(df_nondup)} - or {len(df_nondup)/len(df)*100:.2f}%')\n",
    "\n",
    "# add label count, but only if it doesn't exist\n",
    "if 'label_count' not in df_nondup:\n",
    "    df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['label'].count(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=(None, '_count'))\n",
    "    \n",
    "if 'time_ns_label' not in df:\n",
    "    df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['time_ns'].min(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=(None, '_label'))\n",
    "    df_nondup['time_ns_label'] = df_nondup.time_ns - df_nondup.time_ns_label\n",
    "    \n",
    "# add the channel of the first event to each label (to do the multiplicity plot)\n",
    "if 'channel_first' not in df:\n",
    "    df_nondup.sort_values('time_ns_label')\n",
    "    df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['channel'].first(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=(None, '_first'))\n",
    "\n",
    "# the time isn't sorted correctly, do it here\n",
    "df_nondup.sort_values(['time', 'time_ns_label', 'tot'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplicity plot of hits per channel\n",
    "Plot the 2d histogram of first channel hit to secondary channel hits for each label.\n",
    "\n",
    "The x-axis is the channel of the first hit and the y-axis of the secondary channel hits. There should be no counts on the diagonal as duplicate channels are removed for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nrows_ncols(number_subfigures, nrows=None, ncols=None):\n",
    "    number_subfigures = int(number_subfigures)\n",
    "    if (ncols is None and nrows is None) or \\\n",
    "       (ncols is not None and nrows is not None):\n",
    "        raise ValueError(f'either ncols or nrows must be set. Both are set: ncols={ncols}, nrows={nrows} ')\n",
    "    elif nrows is not None:\n",
    "        nrows = int(nrows)\n",
    "        ncols = int(np.ceil(number_subfigures/nrows))\n",
    "    else:\n",
    "        ncols = int(ncols)\n",
    "        nrows = int(np.ceil(number_subfigures/ncols))\n",
    "        \n",
    "    active = np.zeros(int(nrows*ncols)).astype(bool)\n",
    "    active[:number_subfigures] = True\n",
    "    return nrows, ncols, active\n",
    "\n",
    "get_nrows_ncols(3, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols, ax_active = get_nrows_ncols(df_nondup.label_count.max(), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "# remove the first channel entries\n",
    "mask_events = df_nondup.channel != df_nondup.channel_first\n",
    "\n",
    "for i in range(df_nondup.label_count.max()):\n",
    "    if i==0:\n",
    "        mask_label_count = df_nondup.label_count > 1\n",
    "        title = 'all hits'\n",
    "    else:\n",
    "        mask_label_count = df_nondup.label_count == i+1\n",
    "        title = f'hit multiplicity {i+1}'\n",
    "\n",
    "    print(i, (mask_events&mask_label_count).sum())\n",
    "        \n",
    "    c, e_x, e_y = np.histogram2d(df_nondup.channel_first[mask_events&mask_label_count], \n",
    "                                 df_nondup.channel[mask_events&mask_label_count], \n",
    "                                 bins=np.arange(1, 18)-.5)\n",
    "    c = np.ma.masked_equal(c, 0)\n",
    "    \n",
    "    cb = ax[i].pcolormesh(e_x, e_y, np.log10(c.filled(np.nan)), shading='auto')\n",
    "    # cb = plt.matshow(np.log10(statistic_i.filled(np.nan)))\n",
    "\n",
    "    fig.colorbar(cb, ax=ax[i], shrink=.6, label=f'log$_{{10}}$(counts)', location='right')\n",
    "    ax[i].set_title(title)\n",
    "\n",
    "for axi in ax[ax_active]:\n",
    "    axi.axline((0,0), slope=1, ls='--', color='gray')\n",
    "    axi.set_aspect('equal')\n",
    "    axi.grid(lw=.5)\n",
    "    axi.set_xlim(.5, 16.5)\n",
    "    axi.set_xticks(ticks=np.arange(1,17))\n",
    "    \n",
    "    axi.set_ylim(16.5, .5)\n",
    "    axi.set_yticks(ticks=np.arange(1,17))\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_xlabel('channel first hit') for axi in ax[-1,:]]\n",
    "[axi.set_ylabel('channel secondary hit') for axi in ax[:,0]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "    axi.set_axis_off()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplicity plot of hits per scintillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nondup['scintillator'] = df_nondup.channel.copy()\n",
    "\n",
    "# upper hemisphere is even, lower odd\n",
    "for i, sipm_pair in enumerate([[1,11], [2,12], \n",
    "                               [3, 9], [4,10],\n",
    "                               [5,15], [8,14], \n",
    "                               [7,13], [6,16]]):\n",
    "    df_nondup.loc[df_nondup['channel'].isin(sipm_pair), 'scintillator'] = i+1\n",
    "    \n",
    "### add the channel of the first event to each label (to do the multiplicity plot)\n",
    "if 'scintillator_first' in df_nondup:\n",
    "    df_nondup.pop('scintillator_first')\n",
    "df_nondup.sort_values('time_ns_label')\n",
    "df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['scintillator'].first(), how='left',\n",
    "                  right_index=True, left_on='label', \n",
    "                  suffixes=(None, '_first'))\n",
    "    \n",
    "### add label count, but only if it doesn't exist\n",
    "if 'scintillator_count' in df_nondup:\n",
    "    df_nondup.pop('scintillator_count')\n",
    "df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['scintillator'].count(), how='left',\n",
    "                  right_index=True, left_on='label', \n",
    "                  suffixes=(None, '_count'))\n",
    "    \n",
    "\n",
    "# the time isn't sorted correctly, do it here\n",
    "df_nondup.sort_values(['time', 'time_ns_label', 'tot'], inplace=True)\n",
    "\n",
    "### count how many (different) scintillator are involved at one label\n",
    "if 'scintillator_double' in df_nondup:\n",
    "    df_nondup.pop('scintillator_double')\n",
    "df_nondup = pandas.merge(df_nondup, df_nondup.groupby(['label', 'scintillator']).scintillator.count(), \n",
    "                         how='left', \n",
    "                         right_index=True, left_on=['label','scintillator'], \n",
    "                         suffixes=(None, '_double'))\n",
    "# this results in 1, if there is only one sipm involved or 2 if both sipms \n",
    "# for one scintillator are involved. True if both are involved:\n",
    "df_nondup.scintillator_double = df_nondup.scintillator_double == 2 \n",
    "\n",
    "if 'scintillator_double_count' in df_nondup:\n",
    "    df_nondup.pop('scintillator_double_count')\n",
    "# now count the scintillator_same_count for each label\n",
    "df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['scintillator_double'].sum(), how='left',\n",
    "                  right_index=True, left_on='label', \n",
    "                  suffixes=(None, '_count'))\n",
    "# if both sipms at one scintillator are involved it is 2\n",
    "# if two scintillator are fully involved it is 4,...\n",
    "# -> /= 2 to get the fully involved scintillator count\n",
    "df_nondup.scintillator_double_count /= 2\n",
    "df_nondup.scintillator_double_count = df_nondup.scintillator_double_count.astype(int)\n",
    "\n",
    "# get 'scintillator_count' right\n",
    "df_nondup['scintillator_count'] -= df_nondup['scintillator_double_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nondup[df_nondup.scintillator_count == df_nondup.scintillator_count.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('upper hemisphere is even, lower odd')\n",
    "\n",
    "nrows, ncols, ax_active = get_nrows_ncols(df_nondup.scintillator_count.max(), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "# remove the first channel entries\n",
    "mask_events = df_nondup.scintillator != df_nondup.scintillator_first\n",
    "\n",
    "for i in range(df_nondup.scintillator_count.max()):\n",
    "    if i==0:\n",
    "        mask_label_count = df_nondup.scintillator_count > 1\n",
    "        title = 'all hits'\n",
    "    else:\n",
    "        mask_label_count = df_nondup.scintillator_count == i+1\n",
    "        title = f'scintillator multiplicity {i+1}'\n",
    "        \n",
    "    c, e_x, e_y = np.histogram2d(df_nondup.scintillator_first[mask_events&mask_label_count], \n",
    "                                 df_nondup.scintillator[mask_events&mask_label_count], \n",
    "                                 bins=np.arange(1, 18)-.5)\n",
    "    c = np.ma.masked_equal(c, 0)\n",
    "    \n",
    "    cb = ax[i].pcolormesh(e_x, e_y, np.log10(c.filled(np.nan)), shading='auto')\n",
    "    # cb = plt.matshow(np.log10(statistic_i.filled(np.nan)))\n",
    "\n",
    "    fig.colorbar(cb, ax=ax[i], shrink=.6, label=f'log$_{{10}}$(counts)', location='right')\n",
    "    ax[i].set_title(title)\n",
    "\n",
    "\n",
    "for axi in ax[ax_active]:\n",
    "    axi.axline((0,0), slope=1, ls='--', color='gray')\n",
    "    axi.set_aspect('equal')\n",
    "    axi.grid(lw=.5)\n",
    "    axi.set_xlim(.5, 8.5)\n",
    "    axi.set_xticks(ticks=np.arange(1,9))\n",
    "    \n",
    "    axi.set_ylim(8.5, .5)\n",
    "    axi.set_yticks(ticks=np.arange(1,9))\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_xlabel('scintillator first hit') for axi in ax[-1,:]]\n",
    "[axi.set_ylabel('scintillator secondary hit') for axi in ax[:,0]]\n",
    "\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "    axi.set_axis_off()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplicity plot of full scintillator hits (both sipms saw something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('upper hemisphere is even, lower odd')\n",
    "nrows, ncols, ax_active = get_nrows_ncols(df_nondup.scintillator_double_count.max()+1, ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "# remove the first channel entries\n",
    "mask_events = df_nondup.scintillator != df_nondup.scintillator_first\n",
    "\n",
    "for i in range(df_nondup.scintillator_double_count.max()+1):\n",
    "    if i==0:\n",
    "        mask_label_count = df_nondup.scintillator_double_count > 0\n",
    "        title = 'all hits'\n",
    "    else:\n",
    "        mask_label_count = df_nondup.scintillator_double_count == i\n",
    "        title = f'scintillator multiplicity {i}'\n",
    "        \n",
    "    c, e_x, e_y = np.histogram2d(df_nondup.scintillator_first[mask_events&mask_label_count], \n",
    "                                 df_nondup.scintillator[mask_events&mask_label_count], \n",
    "                                 bins=np.arange(1, 18)-.5)\n",
    "    c = np.ma.masked_equal(c, 0)\n",
    "    \n",
    "    cb = ax[i].pcolormesh(e_x, e_y, np.log10(c.filled(np.nan)), shading='auto')\n",
    "    # cb = plt.matshow(np.log10(statistic_i.filled(np.nan)))\n",
    "\n",
    "    fig.colorbar(cb, ax=ax[i], shrink=.6, label=f'log$_{{10}}$(counts)', location='right')\n",
    "    ax[i].set_title(title)\n",
    "\n",
    "\n",
    "for axi in ax[ax_active]:\n",
    "    axi.axline((0,0), slope=1, ls='--', color='gray')\n",
    "    axi.set_aspect('equal')\n",
    "    axi.grid(lw=.5)\n",
    "    axi.set_xlim(.5, 8.5)\n",
    "    axi.set_xticks(ticks=np.arange(1,9))\n",
    "    \n",
    "    axi.set_ylim(8.5, .5)\n",
    "    axi.set_yticks(ticks=np.arange(1,9))\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_xlabel('scintillator first hit') for axi in ax[-1,:]]\n",
    "[axi.set_ylabel('scintillator secondary hit') for axi in ax[:,0]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "    axi.set_axis_off()\n",
    "\n",
    "# ax[-1].stairs(statistic_i.sum(axis=0), fill=True, edges=binned_stat.bin_edges[0])\n",
    "# ax[-1].set_yscale('log')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# and now only the scintillator with double hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('upper hemisphere is even, lower odd')\n",
    "nrows, ncols, ax_active = get_nrows_ncols(df_nondup.scintillator_double_count.max()+1, ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "# remove the first channel entries\n",
    "mask_events = df_nondup.scintillator != df_nondup.scintillator_first\n",
    "mask_events &= df_nondup.scintillator_double\n",
    "\n",
    "for i in range(df_nondup.scintillator_double_count.max()+1):\n",
    "    if i==0:\n",
    "        mask_label_count = df_nondup.scintillator_double_count > 0\n",
    "        title = 'all hits'\n",
    "    else:\n",
    "        mask_label_count = df_nondup.scintillator_double_count == i\n",
    "        title = f'scintillator multiplicity {i}'\n",
    "        \n",
    "    c, e_x, e_y = np.histogram2d(df_nondup.scintillator_first[mask_events&mask_label_count], \n",
    "                                 df_nondup.scintillator[mask_events&mask_label_count], \n",
    "                                 bins=np.arange(1, 18)-.5)\n",
    "    c = np.ma.masked_equal(c, 0)\n",
    "    \n",
    "    cb = ax[i].pcolormesh(e_x, e_y, np.log10(c.filled(np.nan)), shading='auto')\n",
    "    # cb = plt.matshow(np.log10(statistic_i.filled(np.nan)))\n",
    "\n",
    "    fig.colorbar(cb, ax=ax[i], shrink=.6, label=f'log$_{{10}}$(counts)', location='right')\n",
    "    ax[i].set_title(title)\n",
    "\n",
    "\n",
    "for axi in ax[ax_active]:\n",
    "    axi.axline((0,0), slope=1, ls='--', color='gray')\n",
    "    axi.set_aspect('equal')\n",
    "    axi.grid(lw=.5)\n",
    "    axi.set_xlim(.5, 8.5)\n",
    "    axi.set_xticks(ticks=np.arange(1,9))\n",
    "    \n",
    "    axi.set_ylim(8.5, .5)\n",
    "    axi.set_yticks(ticks=np.arange(1,9))\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_xlabel('scintillator first hit') for axi in ax[-1,:]]\n",
    "[axi.set_ylabel('scintillator secondary hit') for axi in ax[:,0]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "    axi.set_axis_off()\n",
    "    \n",
    "# ax[-1].stairs(statistic_i.sum(axis=0), fill=True, edges=binned_stat.bin_edges[0])\n",
    "# ax[-1].set_yscale('log')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the labels (sipm events) which have at least on full scintillator hit (both SiPMs saw something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_double = df_nondup[df_nondup.scintillator_double_count > 0]\n",
    "\n",
    "print(f'events reduced from: {len(df_nondup)} to {len(df_double)} - or {len(df_double)/len(df_nondup)*100:.2f}%')\n",
    "df_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scintillator_unique = np.sort(df_double.scintillator.unique())\n",
    "\n",
    "nrows, ncols, ax_active = get_nrows_ncols(len(scintillator_unique), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "bins = np.arange(-df_double.time_ns_label.max(), df_double.time_ns_label.max(), .5e-9)\n",
    "print(f'Bins: 0 to {df_double.time_ns_label.max()}, length: {len(bins)}')\n",
    "\n",
    "list_fits = []\n",
    "for i, s_i in enumerate(scintillator_unique):\n",
    "    mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "    ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "    t_0 = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "    t_1 = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "    dt = t_1 - t_0\n",
    "\n",
    "    channels = np.sort(df_double[mask_scintillator].channel.unique())\n",
    "        \n",
    "    dt[ch_first==channels[0]] *= -1\n",
    "    counts, edges = np.histogram(dt, bins=bins)\n",
    "    ax[i].stairs(counts, edges=edges*1e9,label=f'dt: ch{channels[1]} - ch{channels[0]}',)\n",
    "        \n",
    "    ax[i].legend(loc='upper left', ncol=2, title=f'scintillator {s_i}')\n",
    "    ax[i].grid()\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_ylabel('counts') for axi in ax[:,0]]\n",
    "[axi.set_xlabel('$\\Delta$ t [ns]') for axi in ax[-1,:]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "#     axi.set_axis_off()\n",
    "    axi.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scintillator_unique = np.sort(df_double.scintillator.unique())\n",
    "\n",
    "nrows, ncols, ax_active = get_nrows_ncols(len(scintillator_unique), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "bins = np.arange(0, df_double.time_ns_label.max(), .2e-9)\n",
    "print(f'Bins: 0 to {df_double.time_ns_label.max()}, length: {len(bins)}')\n",
    "\n",
    "for i, s_i in enumerate(scintillator_unique):\n",
    "    mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "    mask_scintillator &= df_double.scintillator_double_count==2\n",
    "    ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "    t_0 = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "    t_1 = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "    dt = t_1 - t_0\n",
    "\n",
    "    channels = df_double[mask_scintillator].channel.unique()\n",
    "    for ch_i in np.sort(channels):\n",
    "        counts, edges = np.histogram(dt[ch_first==ch_i], bins=bins)\n",
    "        ax[i].stairs(counts, edges=edges*1e9,label=f'{ch_i}')\n",
    "        \n",
    "    ax[i].legend(loc='upper right', ncol=2, title=f'scintillator {s_i} \\nfirst event in channel:')\n",
    "    ax[i].grid()\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_ylabel('counts') for axi in ax[:,0]]\n",
    "[axi.set_xlabel('$\\Delta$ t [ns]') for axi in ax[-1,:]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "#     axi.set_axis_off()\n",
    "    axi.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate gaussian offset between channel + gaussian signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(-df_double.time_ns_label.max(), df_double.time_ns_label.max(), .5e-9)\n",
    "print(f'Bins: 0 to {df_double.time_ns_label.max()}, length: {len(bins)}')\n",
    "\n",
    "s_i = 2\n",
    "mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "t_0 = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "t_1 = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "dt = t_1 - t_0\n",
    "\n",
    "channels = np.sort(df_double[mask_scintillator].channel.unique())\n",
    "\n",
    "dt[ch_first==channels[0]] *= -1\n",
    "counts, edges = np.histogram(dt, bins=bins)\n",
    "edges *= 1e9\n",
    "x = strawb.tools.cal_middle(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import scipy.optimize\n",
    "\n",
    "def gauss(x, *params):\n",
    "    \"\"\"Generalized sum of N gaussians. N is defined with: N=len(params)//3\n",
    "    therefore len(params) must be a multiple of 3, i.e. 3, 6, 9,...\n",
    "    and gaussian i is defined by: \n",
    "    x0_i = params[::3]\n",
    "    sigma_i = params[1::3]\n",
    "    scale_i = params[2::3]\n",
    "    \"\"\"\n",
    "    y = np.zeros_like(x)\n",
    "    for i in range(0, len(params), 3):\n",
    "        y = y + params[i+2] * np.exp( -((x - params[i])/params[i+1])**2 / 2)\n",
    "    return y\n",
    "\n",
    "def fit_peaks_gauss(x, y, distance=None, height_min=None, height_max=None, verbose=2, min_peaks=None):\n",
    "    if distance is None:\n",
    "        distance = 1\n",
    "    else:\n",
    "        distance = int(distance / np.diff(x).mean())\n",
    "        if distance<2:\n",
    "            distance = 1\n",
    "    if verbose<1:\n",
    "        print('distance in index ', distance)\n",
    "    i_pk, p_pk = scipy.signal.find_peaks(y, distance=distance,\n",
    "                                             height=(height_min, height_max),\n",
    "                                             threshold=(None, None),\n",
    "                                             prominence=(None, None),\n",
    "                                             width=(None, None),\n",
    "#                                              plateau_size=(None, None)\n",
    "                                        )\n",
    "\n",
    "    # convert to dataframe; scipy.signal.find_peaks measures in indices, convert it here\n",
    "    df_p = pandas.DataFrame(p_pk)\n",
    "    for i in df_p.columns.intersection(\n",
    "        ['left_edges', 'right_edges', 'left_bases', 'right_bases', 'left_ips', 'right_ips']):\n",
    "        df_p[i] = np.interp(df_p[i], np.arange(len(x)), x)\n",
    "    df_p['widths'] = df_p['right_ips'] - df_p['left_ips']\n",
    "    df_p['peak_pos'] = x[i_pk]\n",
    "    df_p[['x0', 'sigma', 'scale']] = np.nan \n",
    "\n",
    "    # fit single\n",
    "    for i, row_i in df_p.iterrows():\n",
    "        p0=[row_i.peak_pos, \n",
    "            row_i.widths/np.sqrt(2*np.log(2))/2,\n",
    "            row_i.peak_heights]\n",
    "        d_left = row_i.peak_pos - row_i.left_ips\n",
    "        d_right = row_i.right_ips - row_i.peak_pos\n",
    "        mask_data = (x>=row_i.peak_pos-+d_right*1.2) & (x<=row_i.peak_pos+d_right*1.2)\n",
    "        if mask_data.sum()<=len(p0):\n",
    "            ind = np.argwhere(x==row_i.peak_pos)[0]\n",
    "            mask_data = (x>=x[ind-len(p0)]) & (x<=x[ind+len(p0)])\n",
    "        try:\n",
    "            # use relative error -> absolute_sigma=False, to concentrate on the peak\n",
    "            popt, pcov = scipy.optimize.curve_fit(gauss, x[mask_data], y[mask_data], p0=p0)\n",
    "\n",
    "            df_p.loc[i, 'x0'] = popt[0]\n",
    "            df_p.loc[i, 'sigma'] = np.abs(popt[1])\n",
    "            df_p.loc[i, 'scale'] = popt[2]\n",
    "            if verbose<1:\n",
    "                print(popt)\n",
    "        except Exception as a:\n",
    "            if verbose<2:\n",
    "                print(i, a)\n",
    "\n",
    "    # fit all together\n",
    "    p0 = np.concatenate([df_p.peak_pos, \n",
    "                         df_p.widths/np.sqrt(2*np.log(2))/2,\n",
    "                         df_p.peak_heights]).reshape(3,-1).T\n",
    "    \n",
    "    if min_peaks is not None and len(p0) <= min_peaks:\n",
    "        p0 = np.append(p0, [0,1,1]*(min_peaks-len(p0)))\n",
    "\n",
    "    # use absolute error -> absolute_sigma=True+sigma, to NOT concentrate on the peaks\n",
    "    popt, pcov = scipy.optimize.curve_fit(gauss, x, y, \n",
    "                                          p0=p0.flatten(),\n",
    "                                          absolute_sigma=True, \n",
    "                                          sigma=np.sqrt(np.abs(counts))+1,\n",
    "                                         )\n",
    "\n",
    "    # merg the two dataframes\n",
    "    df_full = pandas.DataFrame(columns=['x0', 'sigma', 'scale'], \n",
    "                     data= popt.reshape(-1,3))\n",
    "    df_full.sort_values('x0', inplace=True, ignore_index=True)\n",
    "    df_p = df_p.merge(df_full, how='outer', left_index=True, right_index=True, suffixes=['_single', None])\n",
    "\n",
    "    return df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = fit_peaks_gauss(x, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scintillator_unique = np.sort(df_double.scintillator.unique())\n",
    "\n",
    "nrows, ncols, ax_active = get_nrows_ncols(len(scintillator_unique), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "bins = np.arange(-df_double.time_ns_label.max(), df_double.time_ns_label.max(), .5e-9)\n",
    "print(f'Bins: 0 to {df_double.time_ns_label.max()}, length: {len(bins)}')\n",
    "\n",
    "list_fits = []\n",
    "for i, s_i in enumerate(scintillator_unique):\n",
    "    mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "    ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "    t_0 = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "    t_1 = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "    dt = t_1 - t_0\n",
    "\n",
    "    channels = np.sort(df_double[mask_scintillator].channel.unique())\n",
    "        \n",
    "    dt[ch_first==channels[0]] *= -1\n",
    "    counts, edges = np.histogram(dt, bins=bins)\n",
    "    ax[i].stairs(counts, edges=edges*1e9,label=f'dt: ch{channels[1]} - ch{channels[0]}',)\n",
    "    \n",
    "    # fit peaks\n",
    "    x_fit = strawb.tools.cal_middle(edges)*1e9\n",
    "    df_p = fit_peaks_gauss(x_fit, counts, distance=3, height_min=counts.max()/10, min_peaks=2)\n",
    "    df_p['scintillator'] = s_i\n",
    "    list_fits.append(df_p)\n",
    "    x_plot = np.linspace(x_fit.min(), x_fit.max(), 1000)\n",
    "    popt = df_p[['x0', 'sigma', 'scale']]\n",
    "    lin, = ax[i].plot(x_plot, gauss(x_plot, *popt.to_numpy().flatten()), '-', label='fit')\n",
    "    for j, row_j in df_p[['x0', 'sigma', 'scale']].iterrows():\n",
    "        ax[i].plot(x_plot, gauss(x_plot, row_j.x0, row_j.sigma, row_j.scale), '--', zorder=0,\n",
    "#                    color=lin.get_color()\n",
    "                  )\n",
    "\n",
    "#     popt = df_p[['x0_single', 'sigma_single', 'scale_single']]\n",
    "#     popt = popt[~popt.isna().any(axis=1)]  # exclude missing values\n",
    "#     lin, = ax[i].plot(x_plot, gauss(x_plot, *popt.to_numpy().flatten()), '--', label='fit single')\n",
    "#     for i, row_i in popt.iterrows():\n",
    "#         ax[i].plot(x_plot, gauss(x_plot, row_i.x0_single, row_i.sigma_single, row_i.scale_single), ':', color=lin.get_color())\n",
    "\n",
    "        \n",
    "    ax[i].legend(loc='upper left', ncol=2, title=f'scintillator {s_i}')\n",
    "    ax[i].grid()\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_ylabel('counts') for axi in ax[:,0]]\n",
    "[axi.set_xlabel('$\\Delta$ t [ns]') for axi in ax[-1,:]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "#     axi.set_axis_off()\n",
    "    axi.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# combine all fit df's and take only the columns of interest\n",
    "columns = ['scintillator', \n",
    "           'x0', 'sigma', 'scale', \n",
    "           'x0_single', 'sigma_single', 'scale_single', \n",
    "           'peak_heights', 'peak_pos']\n",
    "df_fits = pandas.concat(list_fits, ignore_index=True)[columns]\n",
    "\n",
    "df_fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sper2cart(radius, phi, theta=None):\n",
    "    \"\"\"Converts sperical or polar coordinates to cartesian.\n",
    "    sph2cart(1, 0) -> x,y = (1 , 0) \n",
    "    sph2cart(1, 0, 0) -> x,y,z = (0, 0, 1)\n",
    "    PARAMETER\n",
    "    ---------\n",
    "    radius: int, float, list or ndarray\n",
    "    phi: int, float, list or ndarray\n",
    "        should be in the range from [0, 2*np.pi]\n",
    "    theta: int, float, list or ndarray, optional\n",
    "        set theta (is not None) to use sperical coordinates\n",
    "        should be in the range from [0, np.pi]\n",
    "    RETURN\n",
    "    ------\n",
    "    x: float or ndarray\n",
    "    y: float or ndarray\n",
    "    z: float or ndarray, optional\n",
    "        if theta is not None\n",
    "    \"\"\"\n",
    "    rr, pp, tt = np.broadcast_arrays(radius, phi, theta)    \n",
    "    if theta is None:\n",
    "        x = np.cos(pp) * rr\n",
    "        y = np.sin(pp) * rr\n",
    "        return x, y\n",
    "    else:\n",
    "        x = np.sin(tt) * np.cos(pp) * rr\n",
    "        y = np.sin(tt) * np.sin(pp) * rr\n",
    "        z = np.cos(tt) * rr\n",
    "        return x, y, z\n",
    "    \n",
    "    \n",
    "def cart2sper(x, y, z=None):\n",
    "    \"\"\"Converts cartesian to sperical (z!=None) or polar coordinates.\n",
    "    cart2sph(1, 0) -> r,phi = (1 , 0) \n",
    "    cart2sph(0, 0, 1) -> r,phi,theta = (1, 0, 0)\n",
    "    PARAMETER\n",
    "    ---------\n",
    "    x: int, float, list or ndarray\n",
    "    y: int, float, list or ndarray\n",
    "    z: int, float, list or ndarray, optional\n",
    "        set z (is not None) to use sperical coordinates\n",
    "    RETURN\n",
    "    ------\n",
    "    radius: float or ndarray\n",
    "    phi: float or ndarray\n",
    "        in the range from [0, 2*np.pi]\n",
    "    theta: float or ndarray, optional\n",
    "        in the range from [0, np.pi]\n",
    "    \"\"\"\n",
    "    xx, yy, zz = np.broadcast_arrays(x, y, z)    \n",
    "    \n",
    "    r_xy = np.hypot(xx, yy)\n",
    "    phi = np.arctan2(yy, xx) % (np.pi * 2.)\n",
    "    if z is None:\n",
    "        return r_xy, phi\n",
    "    \n",
    "    r_xyz = np.hypot(zz, r_xy)\n",
    "    theta = np.pi/2 - np.arctan2(zz, r_xy) \n",
    "    return r_xyz, phi, theta\n",
    "\n",
    "def min_max(x, axis=-1):\n",
    "    return np.array([np.min(x, axis=axis), np.max(x, axis=axis)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_0 = np.array([.070/2, .070/2, .01])\n",
    "pos_1 = np.array([-.070/2, -.070/2, -.01])\n",
    "\n",
    "n = int(1e4)\n",
    "\n",
    "# sphere\n",
    "# theta = np.random.random_sample(n) * np.pi\n",
    "# phi = np.random.random_sample(n) * np.pi*2.\n",
    "\n",
    "# pos_mu = np.array(sper2cart(radius=.075, phi=phi, theta=theta))\n",
    "\n",
    "pos_mu = np.array([(np.random.random_sample(n)-.5) * .075,\n",
    "                   (np.random.random_sample(n)-.5) * .075,\n",
    "                   (np.random.random_sample(n)-.5) * .02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(*pos_mu, s=3, alpha=.1)\n",
    "ax.scatter(*pos_0)\n",
    "ax.scatter(*pos_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_0 = np.array([.075/2, .075/2, .01])\n",
    "pos_1 = np.array([-.075/2, -.075/2, -.01])\n",
    "\n",
    "n = int(1e6)\n",
    "\n",
    "# use different start points\n",
    "# sphere\n",
    "pos_mu = np.array(sper2cart(radius=.075,\n",
    "                            phi=np.random.random_sample(n) * np.pi*2., \n",
    "                            theta=np.random.random_sample(n) * np.pi))\n",
    "\n",
    "# plane\n",
    "# pos_mu = np.array([(np.random.random_sample(n)-.5) * .075,\n",
    "#                    (np.random.random_sample(n)-.5) * .075,\n",
    "#                     np.ones(n) * 0.01])\n",
    "\n",
    "# rectangle\n",
    "# pos_mu = np.array([(np.random.random_sample(n)-.5) * .075,\n",
    "#                    (np.random.random_sample(n)-.5) * .075,\n",
    "#                    (np.random.random_sample(n)-.5) * .0001])\n",
    "\n",
    "# calculate the times of the SiPM\n",
    "t_s1 = cart2sper(*(pos_mu - pos_0.reshape(-1,1)))[0] / 2.99e8 *  1.5 - .05e-9\n",
    "t_s1 += np.random.normal(size=len(t_s1), scale=.005e-9)\n",
    "t_s2 = cart2sper(*(pos_mu - pos_1.reshape(-1,1)))[0] / 2.99e8 *  1.5\n",
    "t_s2 += np.random.normal(size=len(t_s1), scale=.007e-9)\n",
    "\n",
    "bins_s = np.arange(-10, 10, .001) *  1e-10\n",
    "\n",
    "# t_0 = np.concatenate([t_s1, t_s2])\n",
    "t_0 = t_s1 - t_s2\n",
    "# t_0 += np.random.normal(loc=5, scale=1, size=len(t_0))\n",
    "\n",
    "counts, edges = np.histogram(t_0, bins=bins_s*1e9)\n",
    "x = strawb.tools.cal_middle(edges)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=False, \n",
    "                       figsize=(6,4),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax = ax.flatten()\n",
    "\n",
    "counts, edges = np.histogram(t_0, bins=bins_s)\n",
    "ax[0].stairs(counts, edges=edges)\n",
    "\n",
    "counts, edges = np.histogram(t_s1, bins=bins_s)\n",
    "ax[0].stairs(counts, edges=edges)\n",
    "counts, edges = np.histogram(t_s2, bins=bins_s)\n",
    "ax[0].stairs(counts, edges=edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
