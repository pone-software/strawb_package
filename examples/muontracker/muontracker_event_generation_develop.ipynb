{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "# This examples shows who to download files from the ONC server\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import strawb\n",
    "import strawb.sensors.module\n",
    "import strawb.tools\n",
    "\n",
    "import h5py \n",
    "\n",
    "import pandas\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ONC DB and mask files of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if DB exits, if not load it, but update it anyway\n",
    "if os.path.exists(strawb.Config.pandas_file_sync_db):\n",
    "    db = strawb.SyncDBHandler()  # loads the db from disc\n",
    "else:\n",
    "    db = strawb.SyncDBHandler(load_db=False)  # loads the db from ONC server\n",
    "\n",
    "db.load_onc_db_update(output=True, save_db=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask by device and data-product\n",
    "mask = db.dataframe['deviceCode'] == 'TUMMUONTRACKER001'\n",
    "mask &= db.dataframe.dataProductCode == 'MTSD'  # see SyncDBHandler.sensor_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dataframe[mask & db.dataframe.synced & (db.dataframe.file_version>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.dataframe.dateTo.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some masked entries\n",
    "db.dataframe[mask].iloc[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download a specific file, needs some minutes if file isn't synced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['TUMMUONTRACKER001_20220731T001146.146Z-SDAQ-MUON.hdf5']\n",
    "db_i = db.get_files_from_names(file_list)\n",
    "db_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muon = strawb.MuonTracker(file_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The event builder introduced in this notebook is initegrated to strawb and simplifies to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keeping all events\n",
    "# df = muon.event_builder.event_builder(reduce_dataframe=False)\n",
    "# # or cutting to the evets of interes\n",
    "# df = muon.event_builder.event_builder(reduce_dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Cut Data\n",
    "It seems, the TRB has an overflow at 2750 in both time data. (can be corrected with np.unwrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(muon, trb_overflow = 2750.):\n",
    "    \"\"\" Load data and do first cleaning.\n",
    "    removes: tot_time_ns!=1e-9 <-> there are some events with 1ns\n",
    "    removes the TRB overflow in the timestamp but don't do it at tot_time_ns as it can cause precision loss\"\"\"\n",
    "    tot = muon.file_handler.tot_tot[:]\n",
    "\n",
    "    tot_time_ns = muon.file_handler.tot_time_ns[:]\n",
    "\n",
    "    # some values are 1ns, exclude them\n",
    "    mask_valid = tot_time_ns!=1e-9\n",
    "\n",
    "    # some tot values are very high ~1e12, exclude them here or not\n",
    "    if True:\n",
    "        max_tot = 1 * 1e3 # cut at 1us - [ns]\n",
    "        mask_valid &= (tot<max_tot) & (tot > 0)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(f'exclude {np.sum(~mask_valid)} events')\n",
    "\n",
    "    # time in seconds, time_masked since epoch (1.1.1970); remove the overflow, \n",
    "    # but don't do it at tot_time_ns as it can cause precision loss\n",
    "    time_masked = np.unwrap(muon.file_handler.tot_time[mask_valid], period=trb_overflow)\n",
    "\n",
    "    df_base = pandas.DataFrame({\n",
    "        # time_masked since epoch (1.1.1970)\n",
    "        'time': time_masked,\n",
    "        # time_ns TRB internal\n",
    "        'time_ns': tot_time_ns[mask_valid], \n",
    "        # channel id\n",
    "        'channel': muon.file_handler.tot_channel[mask_valid], \n",
    "        # tot in nano-seconds\n",
    "        'tot': tot[mask_valid]})\n",
    "\n",
    "    # the time isn't sorted correctly, do it here\n",
    "    df_base.sort_values(['time', 'time_ns', 'tot'], inplace=True)\n",
    "\n",
    "    # free RAM - parameter not needed\n",
    "    del tot_time_ns, time_masked, mask_valid, tot\n",
    "    return df_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event builder\n",
    "Detect and build events. A event is defined as set of tot-events where the timestamps between the singel tot-events isn't greater as a limit (`dt_max`). Muons are traveling with ~c and 1ns corresbonds to 0.3m distance. The mountracker has a diameter of 13\", so ~0.3m.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the label function\n",
    "def label_intermediate(input):\n",
    "    \"\"\" Label features in an array based on a second intermediate array, which length is shorter by one.\n",
    "    input                     =  [1,0,1,1,0,0,0,1]\n",
    "    scipy.ndimage.label(input)=  [1,0,2,2,0,0,0,3]\n",
    "    label_intermediate(input) = [1,1,2,2,2,0,0,3,3]\n",
    "    Parameters\n",
    "    ----------\n",
    "    input : array_like\n",
    "        The intermediate array-like object to be labeled. Any non-zero values in `input` are\n",
    "        counted as features and zero values are considered the background.\n",
    "    Retruns\n",
    "    -------\n",
    "    label : ndarray or int\n",
    "        An integer ndarray where each unique feature in `input` has a unique\n",
    "        label in the returned array. And each label is extended by one item.\n",
    "    num_features : int\n",
    "    Example\n",
    "    -------\n",
    "    >>> d_a = np.diff(a)\n",
    "    >>> label = label_intermediate(d_a<1.)\n",
    "    >>> assert len(label) == len(a)\n",
    "    \"\"\"\n",
    "    label, num_features = scipy.ndimage.label(input, structure=None)\n",
    "    label = np.append(label, [0])  # add one item\n",
    "    label[1:][label[:-1]!=0] = label[:-1][label[:-1]!=0]  # add the shifted labels if label!=0\n",
    "    return label, num_features\n",
    "\n",
    "# test\n",
    "a = np.array([1,0,2,2,0,0,0,3])\n",
    "l, _ = label_intermediate(a)\n",
    "print(f'input         :  {a}')\n",
    "print(f'l_intermediate: {l}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build events for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(dataframe, threshold_ns = 20e-9):\n",
    "    # evet selection\n",
    "    dt = np.diff(dataframe['time_ns'])\n",
    "    dataframe['label'], _ = label_intermediate((dt>=0) & (dt<threshold_ns))\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def add_label_timing(dataframe):\n",
    "    # add label count, but only if it doesn't exists\n",
    "    if 'label_count' in dataframe:\n",
    "        dataframe.pop('label_count')\n",
    "    dataframe = pandas.merge(dataframe, dataframe.groupby('label')['label'].count(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=[None, '_count'])\n",
    "\n",
    "    if 'time_ns_label' in dataframe:\n",
    "        dataframe.pop('time_ns_label')\n",
    "    dataframe = pandas.merge(dataframe, dataframe.groupby('label')['time_ns'].min(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=[None, '_label'])\n",
    "    dataframe['time_ns_label'] = dataframe.time_ns - dataframe.time_ns_label\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate(dataframe):\n",
    "    \"\"\"most of the events don't show doublicate entries per channel\n",
    "    - doublicate show a tot of ~25ns and ~58ns, whereas non doublicate have ~25ns\n",
    "    - therefore -> the long TOT seem to be incorrect\n",
    "    - it is sorted by tot and we want only the shortest\n",
    "    - we get it with: aggfunc='first'\n",
    "\n",
    "    \"\"\"\n",
    "    # the time isn't sorted correctly, do it here, to get keep='first' \n",
    "    # keeping the ~25ns and not the ~58ns\n",
    "    dataframe.sort_values(['label', 'time_ns_label', 'tot'], inplace=True)\n",
    "\n",
    "    # mask doublicate per label and channel\n",
    "    mask_duplicate = dataframe.duplicated(['label', 'channel'], keep='first')\n",
    "    # get a dataframe with non duplicates\n",
    "    return dataframe[~mask_duplicate].copy()\n",
    "\n",
    "def add_scintillator(dataframe, inplace=False):\n",
    "    \"\"\"Adds the scintillator number\"\"\"\n",
    "    if not inplace:\n",
    "        dataframe = dataframe.copy()\n",
    "        \n",
    "    # create the mapping between channel and scintillator\n",
    "    trans_ch = np.array([[1,11], [2,12], [3, 9], [4,10],[5,15], [8,14], [7,13], [6,16]]).flatten()\n",
    "    trans_scin = np.array([[1,1], [2,2], [3, 3], [4, 4],[5, 5], [6, 6], [7, 7], [8, 8]]).flatten()\n",
    "\n",
    "    # add a new column with the scintillator number; replace needs the same dtype\n",
    "    dataframe['scintillator'] = dataframe.channel.replace(\n",
    "        trans_ch.flatten().astype(dataframe.channel.dtype), \n",
    "        trans_scin.flatten().astype(dataframe.channel.dtype))\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def add_scintillator_counts(dataframe):\n",
    "    # scintillator_double\n",
    "    scintillator_count = dataframe.groupby('label')['scintillator'].count()\n",
    "    scintillator_count.name = 'scintillator_count'\n",
    "    \n",
    "    # groupby(['label', 'scintillator']).scintillator.count() results in 1, \n",
    "    # if there is only one sipm involved or 2 if both sipms for one scintillator are involved. \n",
    "    # True if both are involved: == 2\n",
    "    scintillator_double = dataframe.groupby(['label', 'scintillator']).scintillator.count() == 2\n",
    "    scintillator_double.name = 'scintillator_double'\n",
    "    \n",
    "    # now count the scintillator_double for each label to get or the counts of\n",
    "    # full scintillator hits\n",
    "    scintillator_double_count = scintillator_double.groupby('label').sum()\n",
    "    scintillator_double_count.name = 'scintillator_double_count'\n",
    "\n",
    "    df_sci = pandas.DataFrame(scintillator_double)\n",
    "    df_sci = df_sci.merge(scintillator_double_count, how='left', left_on='label', right_index=True)\n",
    "\n",
    "    # remove the names, otherwise, merg will add a suffixe\n",
    "    if 'scintillator_double' in dataframe:\n",
    "        dataframe.pop('scintillator_double')\n",
    "    if 'scintillator_double_count' in dataframe:\n",
    "        dataframe.pop('scintillator_double_count')\n",
    "    if 'scintillator_count' in dataframe:\n",
    "        dataframe.pop('scintillator_count')\n",
    "        \n",
    "    dataframe = pandas.merge(dataframe, scintillator_count, how='left', right_index=True, \n",
    "                             left_on='label')\n",
    "    dataframe = pandas.merge(dataframe, df_sci, how='left', right_index=True, \n",
    "                             left_on=['label','scintillator'])\n",
    "    \n",
    "    # only count a scintillator once\n",
    "    dataframe['scintillator_count'] -= dataframe['scintillator_double_count']\n",
    "    return dataframe\n",
    "\n",
    "def event_builder(muon, threshold_ns = 20e-9):\n",
    "    \"\"\"Combines all the different steps to generate the events from the raw data.\n",
    "    That includes:\n",
    "    - remove invalid entires\n",
    "    - label events where at least two entries are in a specified time range (threshold_ns)\n",
    "    - calculate in event timing\n",
    "    - remove the invalid doublicate entries\n",
    "    - label the scintillator for each entrie and count how many different scintillator \n",
    "      got hit per event and if a entrie is part of a double scintillator hit \n",
    "      (both SiPMs of the scintillator are present in the event)\n",
    "    - reduce to events with at least one double scintillator hit\n",
    "    \"\"\"\n",
    "    df_base = get_dataframe(muon)\n",
    "\n",
    "    # detect if there are two or more entires within a dt of some ns\n",
    "    df_base = add_labels(df_base, threshold_ns = threshold_ns)\n",
    "\n",
    "    # remove all entires with no close by neigbour (add_labels)\n",
    "    df_events = df_base[df_base['label']>0]\n",
    "    print(f'events reduced from: {len(df_base)} to {len(df_events)} - or {len(df_events)/len(df_base)*100:.2f}% of df_base')\n",
    "\n",
    "    # add label timing, important for a proper event ordering\n",
    "    df_events = add_label_timing(df_events)\n",
    "\n",
    "    # some channels appear two time with the same timing in one event (label), remove it\n",
    "    df_events_nd = remove_duplicate(df_events)\n",
    "    print(f'events reduced from: {len(df_events)} to {len(df_events_nd)} - or {len(df_events_nd)/len(df_base)*100:.2f}% of df_base')\n",
    "    # df_nondup.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_events_nd = add_scintillator(df_events_nd)\n",
    "    df_events_nd = add_scintillator_counts(df_events_nd)\n",
    "\n",
    "    df_double = df_events_nd[df_events_nd.scintillator_double_count > 0].copy()\n",
    "    df_double.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f'events reduced from: {len(df_events_nd)} to {len(df_double)} - or {len(df_double)/len(df_base)*100:.2f}%  of df_base')\n",
    "    \n",
    "    return df_base, df_events, df_events_nd, df_double\n",
    "\n",
    "df_base, df, df_nondup, df_double = event_builder(muon)\n",
    "df_double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_double[~df_double.scintillator_double]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build events with multiplicity `length`\n",
    "\n",
    "## what to do with doublicate entries per label\n",
    "- most of the events don't show doublicate entries per channel\n",
    "- doublicate show a tot of ~25ns and ~58ns, whereas non doublicate have ~25ns\n",
    "- therefore -> the long TOT seem to be incorrect \n",
    "    - it is sorted by tot and we want only the shortest\n",
    "    - we get it with: aggfunc='first' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result: \n",
    "- most of the events don't show doublicate entries per channel\n",
    "- doublicate show a tot of ~25ns and ~58ns, whereas non doublicate have ~25ns\n",
    "- therefore -> the long TOT seem to be incorrect \n",
    "    - it is sorted by tot and we want only the shortest\n",
    "    - we get it with: aggfunc='first' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask doublicate per label and channel\n",
    "mask_duplicate = df.duplicated(['label', 'channel'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~mask_duplicate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[mask_duplicate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask doublicate per label and channel\n",
    "mask_duplicate = df.duplicated(['label', 'channel'], keep='first')\n",
    "\n",
    "# get a dataframe with non duplicates\n",
    "df_nondup = df[~mask_duplicate].copy()\n",
    "df_nondup.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f'events reduced from: {len(df)} to {len(df_nondup)} - or {len(df_nondup)/len(df)*100:.2f}%')\n",
    "\n",
    "# add label count, but only if it doesn't exists\n",
    "if 'label_count' not in df_nondup:\n",
    "    df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['label'].count(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=[None, '_count'])\n",
    "    \n",
    "if 'time_ns_label' not in df:\n",
    "    df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['time_ns'].min(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=[None, '_label'])\n",
    "    df_nondup['time_ns_label'] = df_nondup.time_ns - df_nondup.time_ns_label\n",
    "    \n",
    "# add the channel of the first event to each label (to do the multiplicity plot)\n",
    "if 'channel_first' not in df:\n",
    "    df_nondup.sort_values('time_ns_label')\n",
    "    df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['channel'].first(), how='left',\n",
    "                      right_index=True, left_on='label', \n",
    "                      suffixes=[None, '_first'])\n",
    "\n",
    "# the time isn't sorted correctly, do it here\n",
    "df_nondup.sort_values(['time', 'time_ns_label', 'tot'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add scintillator label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nondup['scintillator'] = df_nondup.channel.copy()\n",
    "\n",
    "# upper hemisphere is even, lower odd\n",
    "for i, sipm_pair in enumerate([[1,11], [2,12], \n",
    "                               [3, 9], [4,10],\n",
    "                               [5,15], [8,14], \n",
    "                               [7,13], [6,16]]):\n",
    "    df_nondup.loc[df_nondup['channel'].isin(sipm_pair), 'scintillator'] = i+1\n",
    "    \n",
    "# sort needed for 'channel_first', 'scintillator_first' as time is not stricktly increasing\n",
    "df_nondup.sort_values('time_ns_label')\n",
    "\n",
    "# # add the channel of the first event to each label (to do the multiplicity plot)\n",
    "# if 'channel_first' not in df:\n",
    "#     df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['channel'].first(), how='left',\n",
    "#                       right_index=True, left_on='label', \n",
    "#                       suffixes=[None, '_first'])\n",
    "\n",
    "### add the channel of the first event to each label (to do the multiplicity plot)\n",
    "if 'scintillator_first' in df_nondup:\n",
    "    df_nondup.pop('scintillator_first')\n",
    "df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['scintillator'].first(), how='left',\n",
    "                  right_index=True, left_on='label', \n",
    "                  suffixes=[None, '_first'])\n",
    "    \n",
    "### add label count, but only if it doesn't exists\n",
    "if 'scintillator_count' in df_nondup:\n",
    "    df_nondup.pop('scintillator_count')\n",
    "df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['scintillator'].count(), how='left',\n",
    "                  right_index=True, left_on='label', \n",
    "                  suffixes=[None, '_count'])\n",
    "    \n",
    "\n",
    "# # the time isn't sorted correctly, do it here\n",
    "# df_nondup.sort_values(['time', 'time_ns_label', 'tot'], inplace=True)\n",
    "\n",
    "### count how many different scintillator are involved at one label\n",
    "if 'scintillator_double' in df_nondup:\n",
    "    df_nondup.pop('scintillator_double')\n",
    "df_nondup = pandas.merge(df_nondup, df_nondup.groupby(['label', 'scintillator']).scintillator.count(), \n",
    "                         how='left', \n",
    "                         right_index=True, left_on=['label','scintillator'], \n",
    "                         suffixes=[None, '_double'])\n",
    "# this results in 1, if there is only one sipm involved or 2 if both sipms \n",
    "# for one scintillator are involved. True if both are involved:\n",
    "df_nondup.scintillator_double = df_nondup.scintillator_double == 2 \n",
    "\n",
    "if 'scintillator_double_count' in df_nondup:\n",
    "    df_nondup.pop('scintillator_double_count')\n",
    "# now count the scintillator_same_count for each label\n",
    "df_nondup = pandas.merge(df_nondup, df_nondup.groupby('label')['scintillator_double'].sum(), how='left',\n",
    "                  right_index=True, left_on='label', \n",
    "                  suffixes=[None, '_count'])\n",
    "# if both sipms at one scintillator are invovled it is 2\n",
    "# if two scintillator are fully invovled it is 4,...\n",
    "# -> /= 2 to get the fully invovled scintillator count\n",
    "df_nondup.scintillator_double_count /= 2\n",
    "df_nondup.scintillator_double_count = df_nondup.scintillator_double_count.astype(int)\n",
    "\n",
    "# get 'scintillator_count' right\n",
    "df_nondup['scintillator_count'] -= df_nondup['scintillator_double_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reduce to events with at least one scintillator hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_double = df_nondup[df_nondup.scintillator_double_count > 0]\n",
    "\n",
    "print(f'events reduced from: {len(df_nondup)} to {len(df_double)} - or {len(df_double)/len(df_nondup)*100:.2f}%')\n",
    "df_double"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplicity plot of hits per channel\n",
    "Plot the 2d histogramm of first channel hit to secondary channel hits for each label.\n",
    "\n",
    "The x axis is the channel of the first hit and the y axis of the secondary channel hits. There should be no counts on the diagonal as doublicate channels are removed for each label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nrows_ncols(number_subfigures, nrows=None, ncols=None):\n",
    "    number_subfigures = int(number_subfigures)\n",
    "    if (ncols is None and nrows is None) or \\\n",
    "       (ncols is not None and nrows is not None):\n",
    "        raise ValueError(f'either ncols or nrows must be set. Both are set: ncols={ncols}, nrows={nrows} ')\n",
    "    elif nrows is not None:\n",
    "        nrows = int(nrows)\n",
    "        ncols = int(np.ceil(number_subfigures/nrows))\n",
    "    else:\n",
    "        ncols = int(ncols)\n",
    "        nrows = int(np.ceil(number_subfigures/ncols))\n",
    "        \n",
    "    active = np.zeros(int(nrows*ncols)).astype(bool)\n",
    "    active[:number_subfigures] = True\n",
    "    return nrows, ncols, active\n",
    "\n",
    "get_nrows_ncols(3, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols, ax_active = get_nrows_ncols(df_nondup.label_count.max(), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "# remove the first channel entires\n",
    "mask_events = df_nondup.channel != df_nondup.channel_first\n",
    "\n",
    "for i in range(df_nondup.label_count.max()):\n",
    "    if i==0:\n",
    "        mask_label_count = df_nondup.label_count > 1\n",
    "        title = 'all hits'\n",
    "    else:\n",
    "        mask_label_count = df_nondup.label_count == i+1\n",
    "        title = f'hit multiplicity {i+1}'\n",
    "\n",
    "    print(i, (mask_events&mask_label_count).sum())\n",
    "        \n",
    "    c, e_x, e_y = np.histogram2d(df_nondup.channel_first[mask_events&mask_label_count], \n",
    "                                 df_nondup.channel[mask_events&mask_label_count], \n",
    "                                 bins=np.arange(1, 18)-.5)\n",
    "    c = np.ma.masked_equal(c, 0)\n",
    "    \n",
    "    cb = ax[i].pcolormesh(e_x, e_y, np.log10(c.filled(np.nan)), shading='auto')\n",
    "    # cb = plt.matshow(np.log10(statistic_i.filled(np.nan)))\n",
    "\n",
    "    fig.colorbar(cb, ax=ax[i], shrink=.6, label=f'log$_{{10}}$(counts)', location='right')\n",
    "    ax[i].set_title(title)\n",
    "\n",
    "for axi in ax[ax_active]:\n",
    "    axi.axline((0,0), slope=1, ls='--', color='gray')\n",
    "    axi.set_aspect('equal')\n",
    "    axi.grid(lw=.5)\n",
    "    axi.set_xlim(.5, 16.5)\n",
    "    axi.set_xticks(ticks=np.arange(1,17))\n",
    "    \n",
    "    axi.set_ylim(16.5, .5)\n",
    "    axi.set_yticks(ticks=np.arange(1,17))\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_xlabel('channel first hit') for axi in ax[-1,:]]\n",
    "[axi.set_ylabel('channel secondary hit') for axi in ax[:,0]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "    axi.set_axis_off()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplicity plot of hits per scintillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nondup[df_nondup.scintillator_count == df_nondup.scintillator_count.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('upper hemisphere is even, lower odd')\n",
    "\n",
    "nrows, ncols, ax_active = get_nrows_ncols(df_nondup.scintillator_count.max(), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "# remove the first channel entires\n",
    "mask_events = df_nondup.scintillator != df_nondup.scintillator_first\n",
    "\n",
    "for i in range(df_nondup.scintillator_count.max()):\n",
    "    if i==0:\n",
    "        mask_label_count = df_nondup.scintillator_count > 1\n",
    "        title = 'all hits'\n",
    "    else:\n",
    "        mask_label_count = df_nondup.scintillator_count == i+1\n",
    "        title = f'scintillator multiplicity {i+1}'\n",
    "        \n",
    "    c, e_x, e_y = np.histogram2d(df_nondup.scintillator_first[mask_events&mask_label_count], \n",
    "                                 df_nondup.scintillator[mask_events&mask_label_count], \n",
    "                                 bins=np.arange(1, 18)-.5)\n",
    "    c = np.ma.masked_equal(c, 0)\n",
    "    \n",
    "    cb = ax[i].pcolormesh(e_x, e_y, np.log10(c.filled(np.nan)), shading='auto')\n",
    "    # cb = plt.matshow(np.log10(statistic_i.filled(np.nan)))\n",
    "\n",
    "    fig.colorbar(cb, ax=ax[i], shrink=.6, label=f'log$_{{10}}$(counts)', location='right')\n",
    "    ax[i].set_title(title)\n",
    "\n",
    "\n",
    "for axi in ax[ax_active]:\n",
    "    axi.axline((0,0), slope=1, ls='--', color='gray')\n",
    "    axi.set_aspect('equal')\n",
    "    axi.grid(lw=.5)\n",
    "    axi.set_xlim(.5, 8.5)\n",
    "    axi.set_xticks(ticks=np.arange(1,9))\n",
    "    \n",
    "    axi.set_ylim(8.5, .5)\n",
    "    axi.set_yticks(ticks=np.arange(1,9))\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_xlabel('scintillator first hit') for axi in ax[-1,:]]\n",
    "[axi.set_ylabel('scintillator secondary hit') for axi in ax[:,0]]\n",
    "\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "    axi.set_axis_off()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiplicity plot of full scintillator hits (both sipms saw something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('upper hemisphere is even, lower odd')\n",
    "nrows, ncols, ax_active = get_nrows_ncols(df_nondup.scintillator_double_count.max()+1, ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "# remove the first channel entires\n",
    "mask_events = df_nondup.scintillator != df_nondup.scintillator_first\n",
    "\n",
    "for i in range(df_nondup.scintillator_double_count.max()+1):\n",
    "    if i==0:\n",
    "        mask_label_count = df_nondup.scintillator_double_count > 0\n",
    "        title = 'all hits'\n",
    "    else:\n",
    "        mask_label_count = df_nondup.scintillator_double_count == i\n",
    "        title = f'scintillator multiplicity {i}'\n",
    "        \n",
    "    c, e_x, e_y = np.histogram2d(df_nondup.scintillator_first[mask_events&mask_label_count], \n",
    "                                 df_nondup.scintillator[mask_events&mask_label_count], \n",
    "                                 bins=np.arange(1, 18)-.5)\n",
    "    c = np.ma.masked_equal(c, 0)\n",
    "    \n",
    "    cb = ax[i].pcolormesh(e_x, e_y, np.log10(c.filled(np.nan)), shading='auto')\n",
    "    # cb = plt.matshow(np.log10(statistic_i.filled(np.nan)))\n",
    "\n",
    "    fig.colorbar(cb, ax=ax[i], shrink=.6, label=f'log$_{{10}}$(counts)', location='right')\n",
    "    ax[i].set_title(title)\n",
    "\n",
    "\n",
    "for axi in ax[ax_active]:\n",
    "    axi.axline((0,0), slope=1, ls='--', color='gray')\n",
    "    axi.set_aspect('equal')\n",
    "    axi.grid(lw=.5)\n",
    "    axi.set_xlim(.5, 8.5)\n",
    "    axi.set_xticks(ticks=np.arange(1,9))\n",
    "    \n",
    "    axi.set_ylim(8.5, .5)\n",
    "    axi.set_yticks(ticks=np.arange(1,9))\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_xlabel('scintillator first hit') for axi in ax[-1,:]]\n",
    "[axi.set_ylabel('scintillator secondary hit') for axi in ax[:,0]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "    axi.set_axis_off()\n",
    "\n",
    "# ax[-1].stairs(statistic_i.sum(axis=0), fill=True, edges=binned_stat.bin_edges[0])\n",
    "# ax[-1].set_yscale('log')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# and now only the scintillator with double hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the labels (sipm events) which have at least on full scintillator hit (both sipms saw something)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('upper hemisphere is even, lower odd')\n",
    "nrows, ncols, ax_active = get_nrows_ncols(df_nondup.scintillator_double_count.max()+1, ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "# remove the first channel entires\n",
    "mask_events = df_nondup.scintillator != df_nondup.scintillator_first\n",
    "mask_events &= df_nondup.scintillator_double\n",
    "\n",
    "for i in range(df_nondup.scintillator_double_count.max()+1):\n",
    "    if i==0:\n",
    "        mask_label_count = df_nondup.scintillator_double_count > 0\n",
    "        title = 'all hits'\n",
    "    else:\n",
    "        mask_label_count = df_nondup.scintillator_double_count == i\n",
    "        title = f'scintillator multiplicity {i}'\n",
    "        \n",
    "    c, e_x, e_y = np.histogram2d(df_nondup.scintillator_first[mask_events&mask_label_count], \n",
    "                                 df_nondup.scintillator[mask_events&mask_label_count], \n",
    "                                 bins=np.arange(1, 18)-.5)\n",
    "    c = np.ma.masked_equal(c, 0)\n",
    "    \n",
    "    cb = ax[i].pcolormesh(e_x, e_y, np.log10(c.filled(np.nan)), shading='auto')\n",
    "    # cb = plt.matshow(np.log10(statistic_i.filled(np.nan)))\n",
    "\n",
    "    fig.colorbar(cb, ax=ax[i], shrink=.6, label=f'log$_{{10}}$(counts)', location='right')\n",
    "    ax[i].set_title(title)\n",
    "\n",
    "\n",
    "for axi in ax[ax_active]:\n",
    "    axi.axline((0,0), slope=1, ls='--', color='gray')\n",
    "    axi.set_aspect('equal')\n",
    "    axi.grid(lw=.5)\n",
    "    axi.set_xlim(.5, 8.5)\n",
    "    axi.set_xticks(ticks=np.arange(1,9))\n",
    "    \n",
    "    axi.set_ylim(8.5, .5)\n",
    "    axi.set_yticks(ticks=np.arange(1,9))\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_xlabel('scintillator first hit') for axi in ax[-1,:]]\n",
    "[axi.set_ylabel('scintillator secondary hit') for axi in ax[:,0]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "    axi.set_axis_off()\n",
    "    \n",
    "# ax[-1].stairs(statistic_i.sum(axis=0), fill=True, edges=binned_stat.bin_edges[0])\n",
    "# ax[-1].set_yscale('log')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scintillator_unique = np.sort(df_double.scintillator.unique())\n",
    "\n",
    "nrows, ncols, ax_active = get_nrows_ncols(len(scintillator_unique), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax_shape = ax.shape\n",
    "\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "bins = np.arange(-df_double.time_ns_label.max(), df_double.time_ns_label.max(), .5e-9)\n",
    "print(f'Bins: 0 to {df_double.time_ns_label.max()}, length: {len(bins)}')\n",
    "\n",
    "list_fits = []\n",
    "for i, s_i in enumerate(scintillator_unique):\n",
    "    mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "    ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "    t_0 = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "    t_1 = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "    dt = t_1 - t_0\n",
    "\n",
    "    channels = np.sort(df_double[mask_scintillator].channel.unique())\n",
    "        \n",
    "    dt[ch_first==channels[0]] *= -1\n",
    "    counts, edges = np.histogram(dt, bins=bins)\n",
    "    ax[i].stairs(counts, edges=edges*1e9,label=f'dt: ch{channels[1]} - ch{channels[0]}',)\n",
    "        \n",
    "    ax[i].legend(loc='upper left', ncol=2, title=f'scintillator {s_i}')\n",
    "    ax[i].grid()\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_ylabel('counts') for axi in ax[:,0]]\n",
    "[axi.set_xlabel('$\\Delta$ t [ns]') for axi in ax[-1,:]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "#     axi.set_axis_off()\n",
    "    axi.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scintillator_unique = np.sort(df_double.scintillator.unique())\n",
    "\n",
    "nrows, ncols, ax_active = get_nrows_ncols(len(scintillator_unique), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "bins = np.arange(0, df_double.time_ns_label.max(), .2e-9)\n",
    "print(f'Bins: 0 to {df_double.time_ns_label.max()}, length: {len(bins)}')\n",
    "\n",
    "for i, s_i in enumerate(scintillator_unique):\n",
    "    mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "    mask_scintillator &= df_double.scintillator_double_count==2\n",
    "    ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "    t_0 = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "    t_1 = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "    dt = t_1 - t_0\n",
    "\n",
    "    channels = df_double[mask_scintillator].channel.unique()\n",
    "    for ch_i in np.sort(channels):\n",
    "        counts, edges = np.histogram(dt[ch_first==ch_i], bins=bins)\n",
    "        ax[i].stairs(counts, edges=edges*1e9,label=f'{ch_i}')\n",
    "        \n",
    "    ax[i].legend(loc='upper right', ncol=2, title=f'scintillator {s_i} \\nfirst event in channel:')\n",
    "    ax[i].grid()\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_ylabel('counts') for axi in ax[:,0]]\n",
    "[axi.set_xlabel('$\\Delta$ t [ns]') for axi in ax[-1,:]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "#     axi.set_axis_off()\n",
    "    axi.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate gaussian offset between channel + gaussian signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(-df_double.time_ns_label.max(), df_double.time_ns_label.max(), .5e-9)\n",
    "print(f'Bins: 0 to {df_double.time_ns_label.max()}, length: {len(bins)}')\n",
    "\n",
    "s_i = 2\n",
    "mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "t_0 = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "t_1 = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "dt = t_1 - t_0\n",
    "\n",
    "channels = np.sort(df_double[mask_scintillator].channel.unique())\n",
    "\n",
    "dt[ch_first==channels[0]] *= -1\n",
    "counts, edges = np.histogram(dt, bins=bins)\n",
    "edges *= 1e9\n",
    "x = strawb.tools.cal_middle(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "import scipy.optimize\n",
    "\n",
    "def gauss(x, *params):\n",
    "    \"\"\"Generalized sum of N gaussians. N is defined with: N=len(params)//3\n",
    "    therefore len(params) must be a multiple of 3, i.e. 3, 6, 9,...\n",
    "    and gaussian i is defined by: \n",
    "    x0_i = params[::3]\n",
    "    sigma_i = params[1::3]\n",
    "    scale_i = params[2::3]\n",
    "    \"\"\"\n",
    "    y = np.zeros_like(x)\n",
    "    for i in range(0, len(params), 3):\n",
    "        y = y + params[i+2] * np.exp( -((x - params[i])/params[i+1])**2 / 2)\n",
    "    return y\n",
    "\n",
    "def fit_peaks_gauss(x, y, distance=None, height_min=None, height_max=None, verbose=2, min_peaks=None):\n",
    "    if distance is None:\n",
    "        distance = 1\n",
    "    else:\n",
    "        distance = int(distance / np.diff(x).mean())\n",
    "        if distance<2:\n",
    "            distance = 1\n",
    "    if verbose<1:\n",
    "        print('distance in index ', distance)\n",
    "    i_pk, p_pk = scipy.signal.find_peaks(y, distance=distance,\n",
    "                                             height=(height_min, height_max),\n",
    "                                             threshold=(None, None),\n",
    "                                             prominence=(None, None),\n",
    "                                             width=(None, None),\n",
    "#                                              plateau_size=(None, None)\n",
    "                                        )\n",
    "\n",
    "    # convert to dataframe; scipy.signal.find_peaks measures in indices, convert it here\n",
    "    df_p = pandas.DataFrame(p_pk)\n",
    "    for i in df_p.columns.intersection(\n",
    "        ['left_edges', 'right_edges', 'left_bases', 'right_bases', 'left_ips', 'right_ips']):\n",
    "        df_p[i] = np.interp(df_p[i], np.arange(len(x)), x)\n",
    "    df_p['widths'] = df_p['right_ips'] - df_p['left_ips']\n",
    "    df_p['peak_pos'] = x[i_pk]\n",
    "    df_p[['x0', 'sigma', 'scale']] = np.nan \n",
    "\n",
    "    # fit single\n",
    "    for i, row_i in df_p.iterrows():\n",
    "        p0=[row_i.peak_pos, \n",
    "            row_i.widths/np.sqrt(2*np.log(2))/2,\n",
    "            row_i.peak_heights]\n",
    "        d_left = row_i.peak_pos - row_i.left_ips\n",
    "        d_right = row_i.right_ips - row_i.peak_pos\n",
    "        mask_data = (x>=row_i.peak_pos-+d_right*1.2) & (x<=row_i.peak_pos+d_right*1.2)\n",
    "        if mask_data.sum()<=len(p0):\n",
    "            ind = np.argwhere(x==row_i.peak_pos)[0]\n",
    "            mask_data = (x>=x[ind-len(p0)]) & (x<=x[ind+len(p0)])\n",
    "        try:\n",
    "            # use relative error -> absolute_sigma=False, to concentrate on the peak\n",
    "            popt, pcov = scipy.optimize.curve_fit(gauss, x[mask_data], y[mask_data], p0=p0)\n",
    "\n",
    "            df_p.loc[i, 'x0'] = popt[0]\n",
    "            df_p.loc[i, 'sigma'] = np.abs(popt[1])\n",
    "            df_p.loc[i, 'scale'] = popt[2]\n",
    "            if verbose<1:\n",
    "                print(popt)\n",
    "        except Exception as a:\n",
    "            if verbose<2:\n",
    "                print(i, a)\n",
    "\n",
    "    # fit all together\n",
    "    p0 = np.concatenate([df_p.peak_pos, \n",
    "                         df_p.widths/np.sqrt(2*np.log(2))/2,\n",
    "                         df_p.peak_heights]).reshape(3,-1).T\n",
    "    \n",
    "    if min_peaks is not None and len(p0) <= min_peaks:\n",
    "        p0 = np.append(p0, [0,1,1]*(min_peaks-len(p0)))\n",
    "\n",
    "    # use absolute error -> absolute_sigma=True+sigma, to NOT concentrate on the peaks\n",
    "    popt, pcov = scipy.optimize.curve_fit(gauss, x, y, \n",
    "                                          p0=p0.flatten(),\n",
    "                                          absolute_sigma=True, \n",
    "                                          sigma=np.sqrt(np.abs(counts))+1,\n",
    "                                         )\n",
    "\n",
    "    # merg the two dataframes\n",
    "    df_full = pandas.DataFrame(columns=['x0', 'sigma', 'scale'], \n",
    "                     data= popt.reshape(-1,3))\n",
    "    df_full.sort_values('x0', inplace=True, ignore_index=True)\n",
    "    df_p = df_p.merge(df_full, how='outer', left_index=True, right_index=True, suffixes=['_single', None])\n",
    "\n",
    "    return df_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = fit_peaks_gauss(x, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scintillator_unique = np.sort(df_double.scintillator.unique())\n",
    "\n",
    "nrows, ncols, ax_active = get_nrows_ncols(len(scintillator_unique), ncols=3)\n",
    "fig, ax = plt.subplots(ncols=ncols, nrows=nrows, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=True, \n",
    "                       figsize=(10,3*nrows),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax_shape = ax.shape\n",
    "\n",
    "ax_shape = ax.shape\n",
    "ax = ax.flatten()\n",
    "\n",
    "bins = np.arange(-df_double.time_ns_label.max(), df_double.time_ns_label.max(), .5e-9)\n",
    "print(f'Bins: 0 to {df_double.time_ns_label.max()}, length: {len(bins)}')\n",
    "\n",
    "list_fits = []\n",
    "for i, s_i in enumerate(scintillator_unique):\n",
    "    mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "    ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "    t_0 = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "    t_1 = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "    dt = t_1 - t_0\n",
    "\n",
    "    channels = np.sort(df_double[mask_scintillator].channel.unique())\n",
    "        \n",
    "    dt[ch_first==channels[0]] *= -1\n",
    "    counts, edges = np.histogram(dt, bins=bins)\n",
    "    ax[i].stairs(counts, edges=edges*1e9,label=f'dt: ch{channels[1]} - ch{channels[0]}',)\n",
    "    \n",
    "    # fit peaks\n",
    "    x_fit = strawb.tools.cal_middle(edges)*1e9\n",
    "    df_p = fit_peaks_gauss(x_fit, counts, distance=3, height_min=counts.max()/10, min_peaks=2)\n",
    "    df_p['scintillator'] = s_i\n",
    "    list_fits.append(df_p)\n",
    "    x_plot = np.linspace(x_fit.min(), x_fit.max(), 1000)\n",
    "    popt = df_p[['x0', 'sigma', 'scale']]\n",
    "    lin, = ax[i].plot(x_plot, gauss(x_plot, *popt.to_numpy().flatten()), '-', label='fit')\n",
    "    for j, row_j in df_p[['x0', 'sigma', 'scale']].iterrows():\n",
    "        ax[i].plot(x_plot, gauss(x_plot, row_j.x0, row_j.sigma, row_j.scale), '--', zorder=0,\n",
    "#                    color=lin.get_color()\n",
    "                  )\n",
    "\n",
    "#     popt = df_p[['x0_single', 'sigma_single', 'scale_single']]\n",
    "#     popt = popt[~popt.isna().any(axis=1)]  # exclude missing values\n",
    "#     lin, = ax[i].plot(x_plot, gauss(x_plot, *popt.to_numpy().flatten()), '--', label='fit single')\n",
    "#     for i, row_i in popt.iterrows():\n",
    "#         ax[i].plot(x_plot, gauss(x_plot, row_i.x0_single, row_i.sigma_single, row_i.scale_single), ':', color=lin.get_color())\n",
    "\n",
    "        \n",
    "    ax[i].legend(loc='upper left', ncol=2, title=f'scintillator {s_i}')\n",
    "    ax[i].grid()\n",
    "    \n",
    "ax = ax.reshape(ax_shape)\n",
    "[axi.set_ylabel('counts') for axi in ax[:,0]]\n",
    "[axi.set_xlabel('$\\Delta$ t [ns]') for axi in ax[-1,:]]\n",
    "\n",
    "for axi in ax.flatten()[~ax_active]:\n",
    "#     axi.set_axis_off()\n",
    "    axi.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# combine all fit df's and take only the columns of interest\n",
    "columns = ['scintillator', \n",
    "           'x0', 'sigma', 'scale', \n",
    "           'x0_single', 'sigma_single', 'scale_single', \n",
    "           'peak_heights', 'peak_pos']\n",
    "df_fits = pandas.concat(list_fits, ignore_index=True)[columns]\n",
    "\n",
    "df_fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(dt.min(), dt.max(), .5e-9)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(2e3)\n",
    "signal2noise = .9\n",
    "n_signal = int(n*signal2noise)\n",
    "ch_ratio = 1\n",
    "n_signal_2 = int(ch_ratio*n_signal)\n",
    "\n",
    "dt_channel = 6\n",
    "dt_signal = 2\n",
    "\n",
    "sigma_channel = .05\n",
    "sigma_noise = 1.\n",
    "\n",
    "dt_channel - dt_signal, dt_channel + dt_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_i=8\n",
    "df_s = df_fits[df_fits.scintillator==s_i]\n",
    "df_s=df_s.sort_values('peak_heights', ascending=False).iloc[:2]\n",
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_s = np.arange(-df_double.time_ns_label.max(), df_double.time_ns_label.max(), .5e-9)\n",
    "\n",
    "n = int(1e3)\n",
    "signal2noise = 1\n",
    "n_signal = int(df_s.scale.iloc[0]*df_s.sigma.iloc[0]*np.sqrt(2*np.pi)*2)  #int(n*signal2noise)\n",
    "ch_ratio = 0.9\n",
    "n_signal_2 = int(df_s.scale.iloc[1]*df_s.sigma.iloc[1]*np.sqrt(2*np.pi)*2)  #int(ch_ratio*n_signal)\n",
    "\n",
    "t_0 = np.array([])\n",
    "t_1 = np.array([])\n",
    "\n",
    "# gaussian offset in the channel timing\n",
    "# t_0 = np.random.normal(loc=0.0, scale=sigma_channel, size=n)\n",
    "# t_1 = np.random.normal(loc=dt_channel, scale=sigma_channel, size=n)\n",
    "\n",
    "# gaussian signal first hit channel 0\n",
    "t_0 = np.append(t_0, np.random.normal(loc=df_s.x0.iloc[0], scale=df_s.sigma.iloc[0], size=n_signal))\n",
    "t_0 = np.append(t_0, np.random.normal(loc=df_s.x0.iloc[1], scale=df_s.sigma.iloc[1], size=n_signal_2))\n",
    "\n",
    "t_0 += np.random.normal(loc=0, scale=1, size=len(t_0))\n",
    "\n",
    "counts, edges = np.histogram(t_0, bins=bins_s*1e9)\n",
    "x = strawb.tools.cal_middle(edges)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=2, #layout=\"constrained\", \n",
    "                       squeeze=False, sharex=False, \n",
    "                       figsize=(6,4),\n",
    "#                        gridspec_kw=dict(height_ratios=[5,1])\n",
    "                      )\n",
    "ax = ax.flatten()\n",
    "\n",
    "# plot signal\n",
    "if True:\n",
    "    bins_s = np.arange(-df_double.time_ns_label.max(), df_double.time_ns_label.max(), .5e-9)\n",
    "    mask_scintillator = df_double.scintillator_double & (df_double.scintillator==s_i)\n",
    "    ch_first = df_double[mask_scintillator].groupby(['label'])['channel'].first()\n",
    "    t_0_s = df_double[mask_scintillator].groupby(['label'])['time_ns'].min()\n",
    "    t_1_s = df_double[mask_scintillator].groupby(['label'])['time_ns'].max()\n",
    "    dt_s = t_1_s - t_0_s\n",
    "    channels = np.sort(df_double[mask_scintillator].channel.unique())\n",
    "    dt_s[ch_first==channels[0]] *= -1\n",
    "    counts_s, edges_s = np.histogram(dt_s, bins=bins_s)\n",
    "    ax[0].stairs(counts_s, edges=edges_s*1e9,label=f'dt: ch{channels[1]} - ch{channels[0]}',)\n",
    "    \n",
    "\n",
    "counts, edges = np.histogram(t_0, bins=bins_s*1e9)\n",
    "ax[0].stairs(counts, edges=edges)\n",
    "# counts, edges = np.histogram(t_1, bins=bins)\n",
    "# ax[0].stairs(counts, edges=edges)\n",
    "\n",
    "\n",
    "ax[1].stairs(counts, edges=edges)\n",
    "\n",
    "# fit peaks\n",
    "x_fit = strawb.tools.cal_middle(edges)\n",
    "df_p = fit_peaks_gauss(x_fit, counts, distance=3, height_min=counts.max()/10, min_peaks=2)\n",
    "\n",
    "x_plot = np.linspace(x_fit.min(), x_fit.max(), 1000)\n",
    "popt = df_p[['x0', 'sigma', 'scale']]\n",
    "lin, = ax[1].plot(x_plot, gauss(x_plot, *popt.to_numpy().flatten()), '-', label='fit')\n",
    "for j, row_j in df_p[['x0', 'sigma', 'scale']].iterrows():\n",
    "    ax[1].plot(x_plot, gauss(x_plot, row_j.x0, row_j.sigma, row_j.scale), '--', zorder=0,\n",
    "#                    color=lin.get_color()\n",
    "              )\n",
    "    \n",
    "df_p[['x0','sigma','scale','x0_single','sigma_single','scale_single','peak_heights','peak_pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
